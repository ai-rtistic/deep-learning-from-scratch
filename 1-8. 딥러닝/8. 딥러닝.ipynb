{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.1 더 깊게\n",
    "## 8.1.1 더 깊은 신경망으로\n",
    "- [그림 8-1]의 깊은 신경망을 구현한 소스입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "\n",
    "\n",
    "class DeepConvNet:\n",
    "    \"\"\"정확도 99% 이상의 고정밀 합성곱 신경망\n",
    "    네트워크 구성은 아래와 같음\n",
    "        conv - relu - conv- relu - pool -\n",
    "        conv - relu - conv- relu - pool -\n",
    "        conv - relu - conv- relu - pool -\n",
    "        affine - relu - dropout - affine - dropout - softmax\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28),\n",
    "                 conv_param_1 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_2 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_3 = {'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_4 = {'filter_num':32, 'filter_size':3, 'pad':2, 'stride':1},\n",
    "                 conv_param_5 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_6 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 hidden_size=50, output_size=10):\n",
    "        # 가중치 초기화===========\n",
    "        # 각 층의 뉴런 하나당 앞 층의 몇 개 뉴런과 연결되는가（TODO: 자동 계산되게 바꿀 것）\n",
    "        pre_node_nums = np.array([1*3*3, 16*3*3, 16*3*3, 32*3*3, 32*3*3, 64*3*3, 64*4*4, hidden_size])\n",
    "        wight_init_scales = np.sqrt(2.0 / pre_node_nums)  # ReLU를 사용할 때의 권장 초깃값\n",
    "        \n",
    "        self.params = {}\n",
    "        pre_channel_num = input_dim[0]\n",
    "        for idx, conv_param in enumerate([conv_param_1, conv_param_2, conv_param_3, conv_param_4, conv_param_5, conv_param_6]):\n",
    "            self.params['W' + str(idx+1)] = wight_init_scales[idx] * np.random.randn(conv_param['filter_num'], pre_channel_num, conv_param['filter_size'], conv_param['filter_size'])\n",
    "            self.params['b' + str(idx+1)] = np.zeros(conv_param['filter_num'])\n",
    "            pre_channel_num = conv_param['filter_num']\n",
    "        self.params['W7'] = wight_init_scales[6] * np.random.randn(64*4*4, hidden_size)\n",
    "        self.params['b7'] = np.zeros(hidden_size)\n",
    "        self.params['W8'] = wight_init_scales[7] * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b8'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성===========\n",
    "        self.layers = []\n",
    "        self.layers.append(Convolution(self.params['W1'], self.params['b1'], \n",
    "                           conv_param_1['stride'], conv_param_1['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W2'], self.params['b2'], \n",
    "                           conv_param_2['stride'], conv_param_2['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Convolution(self.params['W3'], self.params['b3'], \n",
    "                           conv_param_3['stride'], conv_param_3['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W4'], self.params['b4'],\n",
    "                           conv_param_4['stride'], conv_param_4['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Convolution(self.params['W5'], self.params['b5'],\n",
    "                           conv_param_5['stride'], conv_param_5['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W6'], self.params['b6'],\n",
    "                           conv_param_6['stride'], conv_param_6['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Affine(self.params['W7'], self.params['b7']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        self.layers.append(Affine(self.params['W8'], self.params['b8']))\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x, train_flg=False):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Dropout):\n",
    "                x = layer.forward(x, train_flg)\n",
    "            else:\n",
    "                x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x, train_flg=True)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "\n",
    "        acc = 0.0\n",
    "\n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx, train_flg=False)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt)\n",
    "\n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        tmp_layers = self.layers.copy()\n",
    "        tmp_layers.reverse()\n",
    "        for layer in tmp_layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            grads['W' + str(i+1)] = self.layers[layer_idx].dW\n",
    "            grads['b' + str(i+1)] = self.layers[layer_idx].db\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            self.layers[layer_idx].W = self.params['W' + str(i+1)]\n",
    "            self.layers[layer_idx].b = self.params['b' + str(i+1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1.1 더 깊은 신경망으로\n",
    "- deep_convnet.py의 신경망을 학습시킵니다. 몇 시간은 걸리기 때문에 다른 코드에서는 미리 학습된 가중치인 deep_convnet_params.pkl을 읽어서 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3363959814959445\n",
      "=== epoch:1, train acc:0.082, test acc:0.066 ===\n",
      "train loss:2.4129371553139745\n",
      "train loss:2.3394878489939313\n",
      "train loss:2.27156238681327\n",
      "train loss:2.295853660980856\n",
      "train loss:2.3249246488126816\n",
      "train loss:2.2648711413225193\n",
      "train loss:2.3018855144932364\n",
      "train loss:2.2645375454740955\n",
      "train loss:2.2818686283634886\n",
      "train loss:2.2823343830040677\n",
      "train loss:2.262282802995926\n",
      "train loss:2.2759977751037446\n",
      "train loss:2.2478917080032157\n",
      "train loss:2.2343430724839592\n",
      "train loss:2.2722796087608508\n",
      "train loss:2.2372356162783658\n",
      "train loss:2.2593945062500684\n",
      "train loss:2.2329500651926177\n",
      "train loss:2.2347347428313666\n",
      "train loss:2.2240602457392016\n",
      "train loss:2.216162162150976\n",
      "train loss:2.1598895960848967\n",
      "train loss:2.1909111948242366\n",
      "train loss:2.208790374697362\n",
      "train loss:2.1689405634388823\n",
      "train loss:2.160561420802693\n",
      "train loss:2.1123492322627873\n",
      "train loss:2.1715309849315996\n",
      "train loss:2.122716844013968\n",
      "train loss:2.110109446220753\n",
      "train loss:2.0605550756356963\n",
      "train loss:2.028640726568564\n",
      "train loss:2.1011248311954067\n",
      "train loss:2.060915866839875\n",
      "train loss:2.1032756798808263\n",
      "train loss:1.935951055015433\n",
      "train loss:2.0363804678243853\n",
      "train loss:2.0242540381192775\n",
      "train loss:1.9696166063080267\n",
      "train loss:1.9689214937267892\n",
      "train loss:2.062413627531289\n",
      "train loss:2.029238736599359\n",
      "train loss:2.09359103271603\n",
      "train loss:1.9130727826343235\n",
      "train loss:2.067796117035833\n",
      "train loss:1.967700172863936\n",
      "train loss:1.9936356320699833\n",
      "train loss:1.9087513339577524\n",
      "train loss:2.069689021496284\n",
      "train loss:1.9624397974886265\n",
      "train loss:2.0265285823196852\n",
      "train loss:1.868771655006068\n",
      "train loss:1.927995168289912\n",
      "train loss:1.9834884022550108\n",
      "train loss:1.6767970412907667\n",
      "train loss:1.9939480944234118\n",
      "train loss:2.0144638549079597\n",
      "train loss:2.0720716981097644\n",
      "train loss:1.988599216901054\n",
      "train loss:1.8457697342458537\n",
      "train loss:1.866137712180655\n",
      "train loss:1.9455438750385878\n",
      "train loss:1.905664190089742\n",
      "train loss:1.8736301960912636\n",
      "train loss:1.9211466774238088\n",
      "train loss:1.9155616086881069\n",
      "train loss:1.8296859800735141\n",
      "train loss:1.9406092292527968\n",
      "train loss:2.0760746110076833\n",
      "train loss:2.0601862504397603\n",
      "train loss:1.918210404989794\n",
      "train loss:1.9983875799439306\n",
      "train loss:2.020929740691666\n",
      "train loss:1.929772065514409\n",
      "train loss:1.9442158220419714\n",
      "train loss:1.8544293241734757\n",
      "train loss:1.798369821575601\n",
      "train loss:1.9603449953263155\n",
      "train loss:1.8752602020131623\n",
      "train loss:1.8722099829814531\n",
      "train loss:1.8449378354184975\n",
      "train loss:1.751435030457956\n",
      "train loss:1.8162037905486565\n",
      "train loss:1.6327919525972825\n",
      "train loss:1.9561595482514493\n",
      "train loss:1.8524555585160751\n",
      "train loss:1.6661512403565728\n",
      "train loss:1.6782848142437152\n",
      "train loss:1.7578012574597155\n",
      "train loss:1.7467853296594429\n",
      "train loss:1.7860000688486124\n",
      "train loss:1.7341931423642234\n",
      "train loss:1.890368785055017\n",
      "train loss:2.0110991905173496\n",
      "train loss:1.8801192389844992\n",
      "train loss:1.7948928468032372\n",
      "train loss:1.7532397527480656\n",
      "train loss:1.8878058533627424\n",
      "train loss:1.6915780951007928\n",
      "train loss:1.7723528100847452\n",
      "train loss:1.8074041807027974\n",
      "train loss:1.7112352894737666\n",
      "train loss:1.6697555314867853\n",
      "train loss:1.9183388560716301\n",
      "train loss:1.614248487882563\n",
      "train loss:1.731925854469939\n",
      "train loss:1.5946757609436863\n",
      "train loss:1.6388824880060877\n",
      "train loss:1.606997644160424\n",
      "train loss:1.695507574698956\n",
      "train loss:1.618098100702121\n",
      "train loss:1.553950203026986\n",
      "train loss:1.7195300420984105\n",
      "train loss:1.7041111762304164\n",
      "train loss:1.5412950749972407\n",
      "train loss:1.7258548666326892\n",
      "train loss:1.6770209443723272\n",
      "train loss:1.5203577362204186\n",
      "train loss:1.6638071050125152\n",
      "train loss:1.735905401282839\n",
      "train loss:1.5119301568691936\n",
      "train loss:1.7100802443871157\n",
      "train loss:1.666731031469237\n",
      "train loss:1.4536940646279581\n",
      "train loss:1.6079003878858849\n",
      "train loss:1.539399942001812\n",
      "train loss:1.7041751391003657\n",
      "train loss:1.6303435803050228\n",
      "train loss:1.6984294924632959\n",
      "train loss:1.5573789359154873\n",
      "train loss:1.617198643474196\n",
      "train loss:1.732893901584525\n",
      "train loss:1.5741415704912547\n",
      "train loss:1.788088107273618\n",
      "train loss:1.5491625936213769\n",
      "train loss:1.5992898075217394\n",
      "train loss:1.5255406881235758\n",
      "train loss:1.5676280856982339\n",
      "train loss:1.5139338927570147\n",
      "train loss:1.6825281101697132\n",
      "train loss:1.4731858968816502\n",
      "train loss:1.6970025350632434\n",
      "train loss:1.5249231099241425\n",
      "train loss:1.6056185389519502\n",
      "train loss:1.7693430782384434\n",
      "train loss:1.5128187666049644\n",
      "train loss:1.538402969009907\n",
      "train loss:1.586697003041116\n",
      "train loss:1.7062563615788195\n",
      "train loss:1.495925016186073\n",
      "train loss:1.4995140936455622\n",
      "train loss:1.6727735718790067\n",
      "train loss:1.6765029878702216\n",
      "train loss:1.487155412171897\n",
      "train loss:1.5498511305341907\n",
      "train loss:1.5395816426847377\n",
      "train loss:1.5385251374933193\n",
      "train loss:1.5979422259640665\n",
      "train loss:1.6670615700029172\n",
      "train loss:1.6539048129979768\n",
      "train loss:1.4979763077065675\n",
      "train loss:1.3729954344243185\n",
      "train loss:1.5941492177891248\n",
      "train loss:1.5816011167391806\n",
      "train loss:1.4734804690558108\n",
      "train loss:1.6219424831605758\n",
      "train loss:1.4533369355032248\n",
      "train loss:1.652772647028257\n",
      "train loss:1.5451292197760207\n",
      "train loss:1.611979172964254\n",
      "train loss:1.6403790640632119\n",
      "train loss:1.2973554091742292\n",
      "train loss:1.4297171784095102\n",
      "train loss:1.4608915965253697\n",
      "train loss:1.6094841693020492\n",
      "train loss:1.4404536177440397\n",
      "train loss:1.424398558856259\n",
      "train loss:1.7807096350416776\n",
      "train loss:1.3364443378289548\n",
      "train loss:1.5235493293640132\n",
      "train loss:1.3863287239272706\n",
      "train loss:1.553450038703121\n",
      "train loss:1.666301281592238\n",
      "train loss:1.4267730129870448\n",
      "train loss:1.2783770640209307\n",
      "train loss:1.3406613133728087\n",
      "train loss:1.3801260954582109\n",
      "train loss:1.499194030849131\n",
      "train loss:1.5113811852386179\n",
      "train loss:1.4693802212537215\n",
      "train loss:1.3936216372481602\n",
      "train loss:1.3301917878532674\n",
      "train loss:1.269269619730121\n",
      "train loss:1.4134884405566261\n",
      "train loss:1.3546975069875677\n",
      "train loss:1.4334572305589635\n",
      "train loss:1.6655438887674618\n",
      "train loss:1.5064647822162396\n",
      "train loss:1.4470309770803058\n",
      "train loss:1.422076227899541\n",
      "train loss:1.3090123628336068\n",
      "train loss:1.3226719401001226\n",
      "train loss:1.3217083310368098\n",
      "train loss:1.482458777908699\n",
      "train loss:1.4489561684446763\n",
      "train loss:1.3431938144065632\n",
      "train loss:1.3568988391345065\n",
      "train loss:1.2649616869418367\n",
      "train loss:1.1948512841493137\n",
      "train loss:1.2505786961642418\n",
      "train loss:1.3361828437997674\n",
      "train loss:1.3792715572860734\n",
      "train loss:1.3840261015910955\n",
      "train loss:1.3384957770279227\n",
      "train loss:1.3914413434578912\n",
      "train loss:1.3758749719321215\n",
      "train loss:1.3849967276267414\n",
      "train loss:1.2861296120227603\n",
      "train loss:1.1505491555267893\n",
      "train loss:1.397098040370966\n",
      "train loss:1.2444533615152895\n",
      "train loss:1.386842695628581\n",
      "train loss:1.1681080608365833\n",
      "train loss:1.5293323901169384\n",
      "train loss:1.2308442065693364\n",
      "train loss:1.4484576920690158\n",
      "train loss:1.423963165090283\n",
      "train loss:1.5217569536561784\n",
      "train loss:1.4100643821599161\n",
      "train loss:1.3852179671954863\n",
      "train loss:1.344478784221038\n",
      "train loss:1.334689487211794\n",
      "train loss:1.4143883937998225\n",
      "train loss:1.485339616984513\n",
      "train loss:1.5215407191274934\n",
      "train loss:1.4236263900717894\n",
      "train loss:1.3749558884246533\n",
      "train loss:1.2851056026754137\n",
      "train loss:1.1933844772670363\n",
      "train loss:1.3145313878195928\n",
      "train loss:1.344636399756585\n",
      "train loss:1.304937495682081\n",
      "train loss:1.394193488412053\n",
      "train loss:1.3965683835161082\n",
      "train loss:1.504886620818377\n",
      "train loss:1.5060034728988831\n",
      "train loss:1.2927447823826679\n",
      "train loss:1.6009082060817144\n",
      "train loss:1.2030196050713338\n",
      "train loss:1.3951950544172467\n",
      "train loss:1.3195944600912028\n",
      "train loss:1.216333956300186\n",
      "train loss:1.2162054372324185\n",
      "train loss:1.3251372186265815\n",
      "train loss:1.2624051631361868\n",
      "train loss:1.1666425098983408\n",
      "train loss:1.3348245568681298\n",
      "train loss:1.4494286351239247\n",
      "train loss:1.354292354610387\n",
      "train loss:1.2949830871962795\n",
      "train loss:1.6583293674131563\n",
      "train loss:1.266957319981751\n",
      "train loss:1.4940735591513075\n",
      "train loss:1.2758767748808373\n",
      "train loss:1.2002863478577783\n",
      "train loss:1.2461420673783925\n",
      "train loss:1.2007857637048602\n",
      "train loss:1.0605072436143201\n",
      "train loss:1.2980635075473375\n",
      "train loss:1.2021736939743668\n",
      "train loss:1.2671391010028885\n",
      "train loss:1.237527028462641\n",
      "train loss:1.3912092643634626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.298744638409825\n",
      "train loss:1.5391139828095617\n",
      "train loss:1.465298894422502\n",
      "train loss:1.1630204854502382\n",
      "train loss:1.2998144232006883\n",
      "train loss:1.1337438416371308\n",
      "train loss:1.2666917060690874\n",
      "train loss:1.17043690723662\n",
      "train loss:1.1465363685971548\n",
      "train loss:1.3856473086188814\n",
      "train loss:1.4403196266806222\n",
      "train loss:1.4896473547975915\n",
      "train loss:1.2703446132291305\n",
      "train loss:0.9700291255342673\n",
      "train loss:1.2932726074220815\n",
      "train loss:1.2047957623242906\n",
      "train loss:1.0961654449799143\n",
      "train loss:1.1744380396297156\n",
      "train loss:1.390928595524977\n",
      "train loss:1.2915762926509644\n",
      "train loss:1.2413794582625404\n",
      "train loss:1.2216667291276795\n",
      "train loss:1.175659220227847\n",
      "train loss:1.4952222691278285\n",
      "train loss:1.2206591807360334\n",
      "train loss:1.2748810893216278\n",
      "train loss:1.31149804117333\n",
      "train loss:1.2152915894002414\n",
      "train loss:1.1949089412996892\n",
      "train loss:1.2222491012543832\n",
      "train loss:1.2163168875849015\n",
      "train loss:1.2176397537489938\n",
      "train loss:1.2569449162467055\n",
      "train loss:1.3369652935931564\n",
      "train loss:1.344773500290673\n",
      "train loss:1.333830759690442\n",
      "train loss:1.1592820645175288\n",
      "train loss:1.362351038986359\n",
      "train loss:1.2548167823491763\n",
      "train loss:1.0659630741790656\n",
      "train loss:1.3240876878384227\n",
      "train loss:1.1826199280028633\n",
      "train loss:1.1718531030982178\n",
      "train loss:1.2819948092372142\n",
      "train loss:1.2208048740731696\n",
      "train loss:1.1932088918569819\n",
      "train loss:1.1998789992426724\n",
      "train loss:1.167987350522558\n",
      "train loss:1.1724050276186575\n",
      "train loss:1.3751252418059698\n",
      "train loss:1.461318409712326\n",
      "train loss:1.2093588830215816\n",
      "train loss:1.4307159064045445\n",
      "train loss:1.348630607254489\n",
      "train loss:1.216393228398624\n",
      "train loss:1.2567196955940094\n",
      "train loss:1.121362194083592\n",
      "train loss:1.228487473323405\n",
      "train loss:1.355026826767803\n",
      "train loss:1.2153127646038486\n",
      "train loss:1.263580551010497\n",
      "train loss:1.3293701931148874\n",
      "train loss:1.1769184303045046\n",
      "train loss:1.0929998532364937\n",
      "train loss:1.3851156881150843\n",
      "train loss:1.0201733833586337\n",
      "train loss:1.2904778303424522\n",
      "train loss:1.02282490461983\n",
      "train loss:1.025579735524199\n",
      "train loss:1.1317359557532733\n",
      "train loss:1.215215737817422\n",
      "train loss:1.2633542213225017\n",
      "train loss:1.3835512699269674\n",
      "train loss:1.283676262126604\n",
      "train loss:1.2142338027271733\n",
      "train loss:1.1668665974332282\n",
      "train loss:1.1128338836781846\n",
      "train loss:1.0938868794379726\n",
      "train loss:1.157191661928369\n",
      "train loss:1.2553237544966533\n",
      "train loss:1.2152643500746054\n",
      "train loss:1.0943673841955965\n",
      "train loss:1.3157448743769036\n",
      "train loss:1.249784785582707\n",
      "train loss:1.1742265091879043\n",
      "train loss:1.0914085156053033\n",
      "train loss:1.205494561528673\n",
      "train loss:1.3010150368884639\n",
      "train loss:1.251900439995941\n",
      "train loss:1.1985404681163725\n",
      "train loss:1.272721614547081\n",
      "train loss:1.1610100234272742\n",
      "train loss:1.2543536855093846\n",
      "train loss:1.2390099082642627\n",
      "train loss:1.2233411286821039\n",
      "train loss:1.1317325494643533\n",
      "train loss:1.2051658958930869\n",
      "train loss:1.063278880283081\n",
      "train loss:1.339688712948087\n",
      "train loss:1.1223245536604913\n",
      "train loss:1.1658432810747008\n",
      "train loss:1.2305485615685958\n",
      "train loss:1.230105974653945\n",
      "train loss:1.0558265384237426\n",
      "train loss:1.395468018927333\n",
      "train loss:1.3870275869067326\n",
      "train loss:1.1026731218980108\n",
      "train loss:1.3495847203872764\n",
      "train loss:1.0952246746310046\n",
      "train loss:1.3416576473507809\n",
      "train loss:1.3116919454513083\n",
      "train loss:1.1085370438816162\n",
      "train loss:1.2030441758439394\n",
      "train loss:1.1111098474742525\n",
      "train loss:1.1930953662310244\n",
      "train loss:1.3881206990212798\n",
      "train loss:1.1896895560232041\n",
      "train loss:1.2818237549564286\n",
      "train loss:1.089515877083802\n",
      "train loss:1.2546542198756776\n",
      "train loss:1.1541237784157559\n",
      "train loss:1.1357364907141632\n",
      "train loss:1.0964246867071432\n",
      "train loss:1.2344413854149954\n",
      "train loss:1.2616708468775375\n",
      "train loss:1.2090389005596822\n",
      "train loss:1.32545860055772\n",
      "train loss:1.2019387172225702\n",
      "train loss:1.237012016327865\n",
      "train loss:1.0762484463412505\n",
      "train loss:1.0344908051184454\n",
      "train loss:1.2031024042556901\n",
      "train loss:1.2521401119785092\n",
      "train loss:1.293089687139438\n",
      "train loss:1.2396541590039711\n",
      "train loss:1.4452364206660309\n",
      "train loss:1.0797897742136453\n",
      "train loss:1.054651975177404\n",
      "train loss:1.1510782468594618\n",
      "train loss:1.050132844994919\n",
      "train loss:1.1423981356577642\n",
      "train loss:1.4521532021805288\n",
      "train loss:1.2484334079655819\n",
      "train loss:1.1347500752988635\n",
      "train loss:1.1641253406145695\n",
      "train loss:1.0467561371175509\n",
      "train loss:1.4683977328531703\n",
      "train loss:1.225373927614654\n",
      "train loss:1.0772211140913095\n",
      "train loss:1.3865960942382793\n",
      "train loss:1.1873216189596156\n",
      "train loss:1.049319187256699\n",
      "train loss:1.0368958410679547\n",
      "train loss:1.2081841651657224\n",
      "train loss:1.136975474962886\n",
      "train loss:1.3252750606932113\n",
      "train loss:1.1896387172804284\n",
      "train loss:1.4047488513482276\n",
      "train loss:1.2794985807980463\n",
      "train loss:1.1491568679498152\n",
      "train loss:1.2803521104610684\n",
      "train loss:1.1730934887780016\n",
      "train loss:1.1550571372981038\n",
      "train loss:1.0293685114609334\n",
      "train loss:0.890457336730055\n",
      "train loss:1.2470715330678361\n",
      "train loss:1.217182536582637\n",
      "train loss:1.471076461324129\n",
      "train loss:1.0991468599322376\n",
      "train loss:1.1929840757207557\n",
      "train loss:1.1363613972663829\n",
      "train loss:1.3990237081540582\n",
      "train loss:1.1448901729037357\n",
      "train loss:1.0775133390000795\n",
      "train loss:1.0664280291560728\n",
      "train loss:1.3876259111745721\n",
      "train loss:1.1830123993425976\n",
      "train loss:1.2184700094367797\n",
      "train loss:1.2986379740071206\n",
      "train loss:1.005288520173312\n",
      "train loss:1.063748728589529\n",
      "train loss:1.2168490983146198\n",
      "train loss:1.0550200313034426\n",
      "train loss:1.1324609402334473\n",
      "train loss:1.0891599557753338\n",
      "train loss:1.143025663799866\n",
      "train loss:1.1386913508293768\n",
      "train loss:1.2578997321247163\n",
      "train loss:1.248949813179937\n",
      "train loss:1.125970774708399\n",
      "train loss:1.2775599522468177\n",
      "train loss:1.0708340052784993\n",
      "train loss:1.1738018793048248\n",
      "train loss:1.1020622809957192\n",
      "train loss:1.0394290135873845\n",
      "train loss:1.0501492765594085\n",
      "train loss:1.3475061559246402\n",
      "train loss:1.3369708061338903\n",
      "train loss:1.0432264087527683\n",
      "train loss:1.137016081575694\n",
      "train loss:1.1369751663784875\n",
      "train loss:1.3403762061844386\n",
      "train loss:1.333733946388434\n",
      "train loss:1.0416468568259534\n",
      "train loss:1.1477606359894406\n",
      "train loss:1.2339584837982982\n",
      "train loss:1.0908922884616756\n",
      "train loss:1.077936578017017\n",
      "train loss:1.139074055503049\n",
      "train loss:1.1204615432136231\n",
      "train loss:1.309610669946981\n",
      "train loss:1.355806595770952\n",
      "train loss:1.3495257961440696\n",
      "train loss:1.2902888028239932\n",
      "train loss:1.3602046099974723\n",
      "train loss:1.1931947653605421\n",
      "train loss:0.9990400832848421\n",
      "train loss:1.2132357073530957\n",
      "train loss:1.2619380026379021\n",
      "train loss:1.2084859456491086\n",
      "train loss:1.0494848196966167\n",
      "train loss:1.2754104899946013\n",
      "train loss:1.1049448926293506\n",
      "train loss:1.036615852292249\n",
      "train loss:1.0509089074523923\n",
      "train loss:1.1119504578391197\n",
      "train loss:1.1154327132267627\n",
      "train loss:1.1076515754346667\n",
      "train loss:1.0407001260930386\n",
      "train loss:1.1975332846472029\n",
      "train loss:1.0777724786094838\n",
      "train loss:0.9965810381020346\n",
      "train loss:1.2245894058797797\n",
      "train loss:1.2155506100777729\n",
      "train loss:1.2095810756712198\n",
      "train loss:0.9975974659074529\n",
      "train loss:1.254462347038237\n",
      "train loss:1.1158492914581741\n",
      "train loss:1.032121687640661\n",
      "train loss:1.1405740941321827\n",
      "train loss:1.1658413223159794\n",
      "train loss:1.2057198405732596\n",
      "train loss:1.1300054576409742\n",
      "train loss:1.1077694402656726\n",
      "train loss:1.1939289970530036\n",
      "train loss:0.9241527094239403\n",
      "train loss:1.2136658008055237\n",
      "train loss:0.9650480700592093\n",
      "train loss:1.3078542606206367\n",
      "train loss:1.1326963895424291\n",
      "train loss:1.0350815425718656\n",
      "train loss:1.0018139003872986\n",
      "train loss:1.1905869638969255\n",
      "train loss:0.9846029553062742\n",
      "train loss:1.0527829811312115\n",
      "train loss:1.0350028149631376\n",
      "train loss:1.1399263555945283\n",
      "train loss:1.2364427483923652\n",
      "train loss:0.975879983183956\n",
      "train loss:1.2688525387444605\n",
      "train loss:1.1252166858321504\n",
      "train loss:1.1200158946950838\n",
      "train loss:1.5498323152922335\n",
      "train loss:1.0321611683042726\n",
      "train loss:1.106341505232806\n",
      "train loss:1.1423732634404828\n",
      "train loss:1.1183473324037623\n",
      "train loss:1.1437442478063617\n",
      "train loss:1.064939106259023\n",
      "train loss:1.2910994219737564\n",
      "train loss:1.1092343406821128\n",
      "train loss:1.0957028066446926\n",
      "train loss:1.0992596729872137\n",
      "train loss:1.2132779897574943\n",
      "train loss:0.8335408132875926\n",
      "train loss:1.2970217312421541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.252308521165453\n",
      "train loss:1.0543458318872316\n",
      "train loss:1.0900264303834202\n",
      "train loss:0.9311004416613816\n",
      "train loss:1.2130927552406363\n",
      "train loss:1.1705290578082612\n",
      "train loss:0.9979986221580833\n",
      "train loss:1.028668944994033\n",
      "train loss:1.256286863443591\n",
      "train loss:0.9802030754990919\n",
      "train loss:1.1519752539299635\n",
      "train loss:1.1635042497344323\n",
      "train loss:1.011959455353718\n",
      "train loss:0.99406246106335\n",
      "train loss:1.1060958885379117\n",
      "train loss:0.9684280122903312\n",
      "train loss:1.1449858848577978\n",
      "train loss:1.1070265129440258\n",
      "train loss:1.1650441153310667\n",
      "train loss:1.1190776469828096\n",
      "train loss:1.1823938685597783\n",
      "train loss:0.9881097156643236\n",
      "train loss:1.1091732677415582\n",
      "train loss:1.124849054370746\n",
      "train loss:0.9550458040206119\n",
      "train loss:1.1306749905605282\n",
      "train loss:1.0567538022437908\n",
      "train loss:1.2122462819579476\n",
      "train loss:1.183674429253508\n",
      "train loss:0.9520338656360876\n",
      "train loss:1.1593682386804225\n",
      "train loss:1.0688822071407107\n",
      "train loss:1.050399261008386\n",
      "train loss:1.0977930556700841\n",
      "train loss:1.0864610379124513\n",
      "train loss:1.0937082461883172\n",
      "train loss:0.9758208097771518\n",
      "train loss:1.1857720671651788\n",
      "train loss:1.2612228972877246\n",
      "train loss:1.0531225800820305\n",
      "train loss:0.9904307783761067\n",
      "train loss:0.8333279302913423\n",
      "train loss:1.0597098236631803\n",
      "train loss:1.0604666155910791\n",
      "train loss:0.8728137285375425\n",
      "train loss:1.0532730049440229\n",
      "train loss:1.1307176476251914\n",
      "train loss:1.2906965000011912\n",
      "train loss:1.29005969886111\n",
      "train loss:1.0441636663745175\n",
      "train loss:1.2199666231297304\n",
      "=== epoch:2, train acc:0.973, test acc:0.978 ===\n",
      "train loss:1.1255952159674878\n",
      "train loss:0.9308533605402309\n",
      "train loss:1.0990564129776599\n",
      "train loss:1.0784641885540474\n",
      "train loss:1.003661079103445\n",
      "train loss:1.1286453183597802\n",
      "train loss:1.1837500657289406\n",
      "train loss:0.9573871603355775\n",
      "train loss:1.040396229073953\n",
      "train loss:1.0791179670462128\n",
      "train loss:0.8709575984312501\n",
      "train loss:1.3931086106679242\n",
      "train loss:0.9692597308789263\n",
      "train loss:1.2648163488019963\n",
      "train loss:1.1111236181421258\n",
      "train loss:1.1032285933382482\n",
      "train loss:0.9922816199826364\n",
      "train loss:0.8835162180997174\n",
      "train loss:0.980083209222668\n",
      "train loss:0.9342246315986444\n",
      "train loss:0.9994453270547429\n",
      "train loss:0.9977753148130207\n",
      "train loss:1.2166652634298263\n",
      "train loss:1.1416173534207612\n",
      "train loss:0.8146249032201304\n",
      "train loss:1.1592366092438864\n",
      "train loss:1.0803578919271835\n",
      "train loss:1.0008311157472347\n",
      "train loss:1.1808377696119248\n",
      "train loss:1.0121420066496734\n",
      "train loss:1.0488676161517148\n",
      "train loss:1.1166222068067462\n",
      "train loss:1.195497414131411\n",
      "train loss:0.9951009266280001\n",
      "train loss:1.1297297743509185\n",
      "train loss:1.1220381774691186\n",
      "train loss:1.0567443241940966\n",
      "train loss:1.1449913494703983\n",
      "train loss:1.1072890535296331\n",
      "train loss:1.0951132450711691\n",
      "train loss:0.9664142645664836\n",
      "train loss:1.0643571060672385\n",
      "train loss:1.2570956910924118\n",
      "train loss:1.0055369050018579\n",
      "train loss:1.1088087525757155\n",
      "train loss:1.183765267988683\n",
      "train loss:1.1669981491814823\n",
      "train loss:1.0354636636661276\n",
      "train loss:1.1396778985946723\n",
      "train loss:1.1161893470856665\n",
      "train loss:1.0779019800852883\n",
      "train loss:1.0038762691459717\n",
      "train loss:0.927615877115999\n",
      "train loss:1.114733677281356\n",
      "train loss:1.183329184930018\n",
      "train loss:1.030676905756222\n",
      "train loss:1.1983491223179825\n",
      "train loss:0.9864201100059669\n",
      "train loss:1.0297619697284652\n",
      "train loss:0.9837222522277888\n",
      "train loss:1.1024181811382672\n",
      "train loss:1.1728844095207875\n",
      "train loss:1.1745782093642583\n",
      "train loss:1.0077916212923956\n",
      "train loss:0.9940096690228577\n",
      "train loss:1.1391846580563574\n",
      "train loss:1.2075489001312794\n",
      "train loss:0.9815749926142999\n",
      "train loss:1.2096324895232713\n",
      "train loss:1.2794511713177306\n",
      "train loss:1.1978545852258744\n",
      "train loss:1.069841617105387\n",
      "train loss:1.0429401425962652\n",
      "train loss:1.1499735822558055\n",
      "train loss:1.05457970762947\n",
      "train loss:1.1268692856314342\n",
      "train loss:1.0288546409698764\n",
      "train loss:1.0466595458655206\n",
      "train loss:1.1656002097215252\n",
      "train loss:1.0202463826390125\n",
      "train loss:1.0001207699579617\n",
      "train loss:1.1141612981269882\n",
      "train loss:1.0700588551186434\n",
      "train loss:1.0333007220519006\n",
      "train loss:0.9907288336642488\n",
      "train loss:1.0516414575246564\n",
      "train loss:0.9834600129618306\n",
      "train loss:0.9357730125839835\n",
      "train loss:0.8833684910717029\n",
      "train loss:1.0207149759707634\n",
      "train loss:1.0557767532210116\n",
      "train loss:1.234060051559321\n",
      "train loss:0.928932055723892\n",
      "train loss:0.8251718909192185\n",
      "train loss:0.9130786386912239\n",
      "train loss:0.98580250851207\n",
      "train loss:1.0517334501686388\n",
      "train loss:1.121907728843389\n",
      "train loss:1.1297841933214803\n",
      "train loss:1.0495811949718188\n",
      "train loss:1.1062452441116806\n",
      "train loss:1.216736973533046\n",
      "train loss:1.0194560886742605\n",
      "train loss:1.1436139870985023\n",
      "train loss:0.9733562653304889\n",
      "train loss:1.1860963818294288\n",
      "train loss:0.9400246548318526\n",
      "train loss:1.085706478723142\n",
      "train loss:1.1808516623095173\n",
      "train loss:1.1271580873083318\n",
      "train loss:1.0486562952338105\n",
      "train loss:1.2137446107943644\n",
      "train loss:0.9925418842283069\n",
      "train loss:1.2092900849573065\n",
      "train loss:0.961397673434514\n",
      "train loss:1.0677109768776751\n",
      "train loss:1.2436494051992835\n",
      "train loss:1.0881720324684672\n",
      "train loss:1.0729462732564292\n",
      "train loss:1.221822863771986\n",
      "train loss:1.0541119760885465\n",
      "train loss:1.0114493881714104\n",
      "train loss:1.2230914602885463\n",
      "train loss:1.1314483413308396\n",
      "train loss:1.221716134652171\n",
      "train loss:0.9194090632293508\n",
      "train loss:1.2242630078545964\n",
      "train loss:0.9473141036191803\n",
      "train loss:1.102464184988986\n",
      "train loss:1.0595098875573137\n",
      "train loss:1.0501022603515289\n",
      "train loss:1.0987496280463733\n",
      "train loss:1.0065312380981455\n",
      "train loss:1.0387762509378347\n",
      "train loss:1.169945382733051\n",
      "train loss:1.0581209490196202\n",
      "train loss:1.1182346249772674\n",
      "train loss:0.9167069110982211\n",
      "train loss:1.1143539042181738\n",
      "train loss:1.1814403201293617\n",
      "train loss:1.1934544846286117\n",
      "train loss:1.068961980756484\n",
      "train loss:0.8640342612191926\n",
      "train loss:1.039436564787887\n",
      "train loss:1.1491271420456244\n",
      "train loss:1.087978272074582\n",
      "train loss:1.0837519625091645\n",
      "train loss:1.0266038056648579\n",
      "train loss:1.1424761776624515\n",
      "train loss:1.192138681403686\n",
      "train loss:0.9168486693527224\n",
      "train loss:1.00228757911372\n",
      "train loss:1.0450559479819639\n",
      "train loss:1.059616009807713\n",
      "train loss:0.9899944893207089\n",
      "train loss:1.0103291945524906\n",
      "train loss:1.083079113066936\n",
      "train loss:0.9772994387554804\n",
      "train loss:0.8543965493372696\n",
      "train loss:1.060471450331422\n",
      "train loss:0.9927647125284236\n",
      "train loss:1.015417711260329\n",
      "train loss:0.9897517820472695\n",
      "train loss:1.01234502062489\n",
      "train loss:0.8525392058000401\n",
      "train loss:1.0578961031793375\n",
      "train loss:0.9868850343090956\n",
      "train loss:1.2417875520997346\n",
      "train loss:1.134360141015821\n",
      "train loss:1.0442793522082885\n",
      "train loss:1.2804095561713478\n",
      "train loss:1.0008082576034496\n",
      "train loss:1.212137218703158\n",
      "train loss:1.056234712278165\n",
      "train loss:1.0421359761102058\n",
      "train loss:0.8907338241989163\n",
      "train loss:1.1482104419960555\n",
      "train loss:0.9754206263541996\n",
      "train loss:1.0948842108401342\n",
      "train loss:1.0528475400152062\n",
      "train loss:1.034369224099639\n",
      "train loss:0.8259212729692195\n",
      "train loss:0.9515051326128336\n",
      "train loss:0.989049637104648\n",
      "train loss:0.9806984298553789\n",
      "train loss:1.0763961341611417\n",
      "train loss:1.0664524764915833\n",
      "train loss:0.9756607770734846\n",
      "train loss:1.061346299482558\n",
      "train loss:1.086252599279043\n",
      "train loss:1.0869284531031769\n",
      "train loss:1.1821090118248712\n",
      "train loss:1.0828530368477265\n",
      "train loss:1.0885580165894901\n",
      "train loss:1.1397096067369\n",
      "train loss:0.9404486168982521\n",
      "train loss:0.9462229891104179\n",
      "train loss:1.2679627423930773\n",
      "train loss:1.207552322329313\n",
      "train loss:1.1308269890407852\n",
      "train loss:1.058915869287932\n",
      "train loss:1.0855364256079663\n",
      "train loss:0.8665614387386148\n",
      "train loss:0.9834175204895579\n",
      "train loss:1.146034149910341\n",
      "train loss:0.9502064977120903\n",
      "train loss:1.0174886631235445\n",
      "train loss:1.0093100706428566\n",
      "train loss:1.068894235190935\n",
      "train loss:0.9146929962008521\n",
      "train loss:1.0911728089740103\n",
      "train loss:1.0486200005469661\n",
      "train loss:0.8675884113437856\n",
      "train loss:1.0994985264042687\n",
      "train loss:1.0965199654351796\n",
      "train loss:1.0868168253630597\n",
      "train loss:1.0372105848517237\n",
      "train loss:0.9996526419216925\n",
      "train loss:0.9393597388127707\n",
      "train loss:1.1026348732603135\n",
      "train loss:0.9688922588679898\n",
      "train loss:1.1188401327738584\n",
      "train loss:1.1025500127694157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.1755147781625015\n",
      "train loss:1.1638926519008066\n",
      "train loss:1.1108513332453764\n",
      "train loss:1.0911184808005685\n",
      "train loss:1.0840586035906372\n",
      "train loss:1.1460711894790112\n",
      "train loss:1.0685820240612178\n",
      "train loss:0.9449598455878939\n",
      "train loss:1.0247674564669742\n",
      "train loss:0.9778934797333345\n",
      "train loss:1.0114417481072189\n",
      "train loss:1.0667970659927883\n",
      "train loss:1.0611780830471291\n",
      "train loss:0.9069617381376225\n",
      "train loss:0.9799111410046173\n",
      "train loss:1.0875086327054762\n",
      "train loss:1.0118617393458067\n",
      "train loss:1.0055394282468932\n",
      "train loss:1.0156714762593155\n",
      "train loss:1.079149565000923\n",
      "train loss:1.0999129620964652\n",
      "train loss:1.1317060004866748\n",
      "train loss:1.0231122582832421\n",
      "train loss:1.062908238929473\n",
      "train loss:1.0329234918064834\n",
      "train loss:1.0568319444851897\n",
      "train loss:1.189539545220216\n",
      "train loss:0.998393836514421\n",
      "train loss:1.06925502011883\n",
      "train loss:1.0180325633036371\n",
      "train loss:0.9326657375178954\n",
      "train loss:0.9707075734741976\n",
      "train loss:1.1924291219224337\n",
      "train loss:0.9543312469924955\n",
      "train loss:0.9627294299866339\n",
      "train loss:0.9783314387429941\n",
      "train loss:1.0583948917479544\n",
      "train loss:0.847980379913214\n",
      "train loss:1.0031171247613746\n",
      "train loss:0.9761858921687245\n",
      "train loss:1.0337386761865854\n",
      "train loss:1.1828877871477672\n",
      "train loss:1.0438089680463192\n",
      "train loss:1.2188889885043295\n",
      "train loss:0.9735897897571849\n",
      "train loss:1.3009365116483766\n",
      "train loss:0.9853428533109795\n",
      "train loss:1.1012761159575377\n",
      "train loss:1.211738770483593\n",
      "train loss:0.9434375389750628\n",
      "train loss:0.9838583589437299\n",
      "train loss:1.1324171148260214\n",
      "train loss:1.0336198927523967\n",
      "train loss:0.8479136280292147\n",
      "train loss:1.135077636578535\n",
      "train loss:1.1772177343078862\n",
      "train loss:1.0040398688135697\n",
      "train loss:0.9211381517343146\n",
      "train loss:1.0556220639178315\n",
      "train loss:0.8861018085322259\n",
      "train loss:1.1190439568659736\n",
      "train loss:0.9981259603798053\n",
      "train loss:1.0362360142699725\n",
      "train loss:1.1068276127713896\n",
      "train loss:1.1504645087908085\n",
      "train loss:1.0077988491448757\n",
      "train loss:1.3151750219838934\n",
      "train loss:1.066669982120334\n",
      "train loss:0.9254722585699411\n",
      "train loss:0.8898853069310675\n",
      "train loss:0.8904699378078813\n",
      "train loss:1.1761412765976784\n",
      "train loss:1.1678433467645006\n",
      "train loss:0.9420617105940146\n",
      "train loss:0.864645821838332\n",
      "train loss:0.9276264052446398\n",
      "train loss:0.8418138644761186\n",
      "train loss:0.8622995593886386\n",
      "train loss:1.0483571005101273\n",
      "train loss:0.9920056101157312\n",
      "train loss:1.0396659048407866\n",
      "train loss:1.0182234063096065\n",
      "train loss:1.124207350497428\n",
      "train loss:1.0501936371989538\n",
      "train loss:0.9631192159772746\n",
      "train loss:0.988281531430646\n",
      "train loss:0.8482641354086878\n",
      "train loss:1.0053851911715825\n",
      "train loss:0.9779391216748915\n",
      "train loss:0.9379903573013009\n",
      "train loss:0.91327076630913\n",
      "train loss:1.089702472419795\n",
      "train loss:0.9148580602580556\n",
      "train loss:1.139883417541434\n",
      "train loss:1.0553143413255128\n",
      "train loss:0.9829714538434946\n",
      "train loss:1.0438367481624053\n",
      "train loss:1.0782303875421788\n",
      "train loss:1.0581870712414057\n",
      "train loss:1.0556654303486879\n",
      "train loss:1.0263927589363437\n",
      "train loss:1.022826036981485\n",
      "train loss:1.0091646948548383\n",
      "train loss:0.994426075560108\n",
      "train loss:1.2452560588311594\n",
      "train loss:0.8523043412864278\n",
      "train loss:1.1210704112492045\n",
      "train loss:1.0520709612164203\n",
      "train loss:1.101851726923487\n",
      "train loss:0.9993833919685027\n",
      "train loss:1.0753705427295712\n",
      "train loss:0.9507903462318338\n",
      "train loss:0.8897684718130313\n",
      "train loss:1.0810353988700578\n",
      "train loss:0.9647157427054421\n",
      "train loss:0.9421105380399802\n",
      "train loss:0.9433460296642336\n",
      "train loss:1.0996370498427706\n",
      "train loss:0.9539396295094792\n",
      "train loss:1.1268518922997903\n",
      "train loss:1.0957201685830418\n",
      "train loss:1.0349784380110227\n",
      "train loss:0.9900898326108709\n",
      "train loss:1.0667408312968845\n",
      "train loss:1.0179424198281204\n",
      "train loss:1.032010990747163\n",
      "train loss:1.018619421877856\n",
      "train loss:0.9507220286960777\n",
      "train loss:0.9230506667206947\n",
      "train loss:1.0539697100990155\n",
      "train loss:1.0606901565408742\n",
      "train loss:0.9359163229956968\n",
      "train loss:1.097539273237554\n",
      "train loss:0.8731297680756842\n",
      "train loss:0.856263579830822\n",
      "train loss:1.0749193267541093\n",
      "train loss:1.1497942176797902\n",
      "train loss:0.9264251210550752\n",
      "train loss:0.9804066993179292\n",
      "train loss:0.9342768736548734\n",
      "train loss:1.1809611826846578\n",
      "train loss:0.9706350209340715\n",
      "train loss:1.0611300180286571\n",
      "train loss:1.0749853976417627\n",
      "train loss:1.025739198629476\n",
      "train loss:1.1849293268376637\n",
      "train loss:0.8520503524573294\n",
      "train loss:0.9896709512083963\n",
      "train loss:0.9371589829028472\n",
      "train loss:1.0669674992764149\n",
      "train loss:0.9340581176222471\n",
      "train loss:1.0290316362768512\n",
      "train loss:0.8722832926074584\n",
      "train loss:1.1251802640741821\n",
      "train loss:0.778282244608759\n",
      "train loss:1.1113823760021393\n",
      "train loss:0.9569906251535152\n",
      "train loss:0.7543106055558035\n",
      "train loss:1.0703194093986188\n",
      "train loss:1.2011083216782363\n",
      "train loss:1.0377032835117337\n",
      "train loss:0.8910215196547411\n",
      "train loss:0.8770069506309991\n",
      "train loss:0.916483173196954\n",
      "train loss:1.036829134529484\n",
      "train loss:0.938615431300094\n",
      "train loss:1.0777919830298728\n",
      "train loss:1.1990442385105573\n",
      "train loss:1.105407074319636\n",
      "train loss:0.7617272338798567\n",
      "train loss:1.0476317549783507\n",
      "train loss:1.0342740208721592\n",
      "train loss:1.1145347528029543\n",
      "train loss:1.0323426172224257\n",
      "train loss:0.8675434540259573\n",
      "train loss:1.0112055216019271\n",
      "train loss:0.8219318625874595\n",
      "train loss:0.9907083234102809\n",
      "train loss:0.8748496552099136\n",
      "train loss:0.9006636002834253\n",
      "train loss:1.0459045673837557\n",
      "train loss:0.9746079816403221\n",
      "train loss:1.0326900900470577\n",
      "train loss:0.9708462230549373\n",
      "train loss:0.7966775349744383\n",
      "train loss:1.0307541997234504\n",
      "train loss:1.0475557403931472\n",
      "train loss:0.8559037322474198\n",
      "train loss:0.989143566831315\n",
      "train loss:1.0440426669478606\n",
      "train loss:0.9564480471741931\n",
      "train loss:0.8895412918543897\n",
      "train loss:1.0184750294082503\n",
      "train loss:0.9386310651453307\n",
      "train loss:0.9982621984025425\n",
      "train loss:0.8672804236400481\n",
      "train loss:1.076155248868421\n",
      "train loss:0.9596599748396112\n",
      "train loss:0.917182564351839\n",
      "train loss:0.978507055759525\n",
      "train loss:1.0803271064123294\n",
      "train loss:1.0201146924158848\n",
      "train loss:0.9946502379892921\n",
      "train loss:1.2254346811521104\n",
      "train loss:1.1010724427059544\n",
      "train loss:0.7959243825105632\n",
      "train loss:0.9712639609365469\n",
      "train loss:1.0135810707803026\n",
      "train loss:0.9415971870897633\n",
      "train loss:0.8931781107269804\n",
      "train loss:1.117317244449898\n",
      "train loss:0.9980134615804821\n",
      "train loss:0.9991616656100847\n",
      "train loss:1.0109239633831495\n",
      "train loss:1.1791266057643215\n",
      "train loss:0.9921787861844055\n",
      "train loss:1.2633124283932995\n",
      "train loss:1.0044542746202836\n",
      "train loss:0.8885551486606811\n",
      "train loss:1.1728215656697736\n",
      "train loss:0.9327079798395188\n",
      "train loss:1.0077004947331816\n",
      "train loss:0.8780450893437554\n",
      "train loss:1.158097122041552\n",
      "train loss:0.9095086548654772\n",
      "train loss:1.146439912639633\n",
      "train loss:0.8740215306012122\n",
      "train loss:0.9533834317288759\n",
      "train loss:1.0452107952163514\n",
      "train loss:0.9807646979585587\n",
      "train loss:1.070615602107888\n",
      "train loss:1.038751548480258\n",
      "train loss:1.0164619320865216\n",
      "train loss:0.8555664955796055\n",
      "train loss:0.9854239078732202\n",
      "train loss:0.8806570437131513\n",
      "train loss:1.0629060483493113\n",
      "train loss:1.0294859845804079\n",
      "train loss:1.0147522535531086\n",
      "train loss:0.9115071807132678\n",
      "train loss:1.0294451321225468\n",
      "train loss:1.0385677081995575\n",
      "train loss:1.0488091319364263\n",
      "train loss:0.9856209140575498\n",
      "train loss:1.0457493381161291\n",
      "train loss:1.0518933212715695\n",
      "train loss:1.1003004649031007\n",
      "train loss:1.0614163261338219\n",
      "train loss:1.0862605474212823\n",
      "train loss:0.8386584602148076\n",
      "train loss:1.1990976895563348\n",
      "train loss:0.9832320266206456\n",
      "train loss:0.9351729297465216\n",
      "train loss:0.8536619912530452\n",
      "train loss:0.8578062597929244\n",
      "train loss:1.0002889482500696\n",
      "train loss:0.9718865053738862\n",
      "train loss:1.0190638776115848\n",
      "train loss:1.0768310155618668\n",
      "train loss:0.9205341801807134\n",
      "train loss:0.963677032687895\n",
      "train loss:0.9300713459246528\n",
      "train loss:1.0377897266349132\n",
      "train loss:0.9454524027905051\n",
      "train loss:0.959735236583539\n",
      "train loss:0.990434593551282\n",
      "train loss:1.0668790626575437\n",
      "train loss:1.1013298638402385\n",
      "train loss:0.8060723823715099\n",
      "train loss:0.9421440243949035\n",
      "train loss:1.008716813501726\n",
      "train loss:1.0301783886770852\n",
      "train loss:0.9177930992794084\n",
      "train loss:1.1201746977738753\n",
      "train loss:1.046250570630149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.1199498030402095\n",
      "train loss:1.1086578951804902\n",
      "train loss:0.9037709328975089\n",
      "train loss:1.1685349262268205\n",
      "train loss:1.0465898704819125\n",
      "train loss:1.0500255437864758\n",
      "train loss:1.086856286167124\n",
      "train loss:1.0293793413201024\n",
      "train loss:1.0583927794081975\n",
      "train loss:1.104532736815368\n",
      "train loss:1.013324585522154\n",
      "train loss:1.1192413794556821\n",
      "train loss:1.0273996270545769\n",
      "train loss:1.0019838508520125\n",
      "train loss:1.0605178231542658\n",
      "train loss:0.9718928144398987\n",
      "train loss:0.8647888368945946\n",
      "train loss:0.879352972429777\n",
      "train loss:1.1653963634002726\n",
      "train loss:1.0257798945880792\n",
      "train loss:0.8339433030879178\n",
      "train loss:1.0368535348244337\n",
      "train loss:1.0285661121803775\n",
      "train loss:1.230213575533777\n",
      "train loss:1.1695183016156192\n",
      "train loss:0.9208403704260401\n",
      "train loss:1.0014802001946272\n",
      "train loss:1.0238376302663752\n",
      "train loss:1.047025480258955\n",
      "train loss:0.9374287397576979\n",
      "train loss:1.163994113855507\n",
      "train loss:1.0097032676291284\n",
      "train loss:1.1763272778448794\n",
      "train loss:1.057475262742373\n",
      "train loss:1.0645175199381938\n",
      "train loss:1.0366596613738124\n",
      "train loss:0.8599828773967654\n",
      "train loss:0.7678736167759235\n",
      "train loss:0.9126540764624808\n",
      "train loss:1.043884352364047\n",
      "train loss:1.0924531421659127\n",
      "train loss:0.9718479340328818\n",
      "train loss:1.1036801788441029\n",
      "train loss:0.9730368748236552\n",
      "train loss:0.8639615593178283\n",
      "train loss:0.954250828870281\n",
      "train loss:0.9814444284036798\n",
      "train loss:1.0245988540129671\n",
      "train loss:1.1344688841569353\n",
      "train loss:1.1880198180521433\n",
      "train loss:0.9612500088311465\n",
      "train loss:1.0013192235576822\n",
      "train loss:0.8422141047902848\n",
      "train loss:1.012583969199784\n",
      "train loss:0.886440790673792\n",
      "train loss:1.2142835298061794\n",
      "train loss:1.0190682650772203\n",
      "train loss:1.0643237459464832\n",
      "train loss:0.9621014794825468\n",
      "train loss:0.8219489481680032\n",
      "train loss:0.9743961673376974\n",
      "train loss:1.3094285937070476\n",
      "train loss:0.9127994332026859\n",
      "train loss:0.9543459517822823\n",
      "train loss:1.1096403532978965\n",
      "train loss:0.8738341949571136\n",
      "train loss:1.2277380424559083\n",
      "train loss:1.1295896438272957\n",
      "train loss:0.9988760123720103\n",
      "train loss:0.936012902382069\n",
      "train loss:0.8307553334932014\n",
      "train loss:1.0657926766989363\n",
      "train loss:1.0843413671911832\n",
      "train loss:1.1017126084591353\n",
      "train loss:1.0211942562418057\n",
      "train loss:1.0676124534779852\n",
      "train loss:0.9217243073963841\n",
      "train loss:1.0021582730312721\n",
      "train loss:0.9052096426557287\n",
      "train loss:1.18053292908997\n",
      "train loss:0.9354992876495182\n",
      "train loss:0.9505656543370634\n",
      "train loss:0.9773388811955797\n",
      "train loss:0.9886464434444616\n",
      "train loss:1.0087678976287355\n",
      "train loss:0.9807340213370962\n",
      "train loss:1.1601893023852012\n",
      "train loss:0.9554112707925033\n",
      "train loss:1.1120958738029514\n",
      "train loss:1.0278876653614686\n",
      "train loss:1.1477046549428567\n",
      "train loss:1.2958377387501594\n",
      "train loss:1.1390374936359011\n",
      "train loss:1.1198607717651132\n",
      "train loss:0.9463254415584034\n",
      "train loss:0.8502330935625672\n",
      "train loss:1.11528045475388\n",
      "train loss:1.1227107039270445\n",
      "train loss:1.1717307282619942\n",
      "train loss:0.9723203418302915\n",
      "train loss:0.8674460813729682\n",
      "train loss:1.068050727217816\n",
      "=== epoch:3, train acc:0.982, test acc:0.983 ===\n",
      "train loss:0.9263275031718189\n",
      "train loss:0.9515758587927948\n",
      "train loss:1.0670758714373354\n",
      "train loss:0.8962831135414622\n",
      "train loss:0.928001662294475\n",
      "train loss:0.9262207959686525\n",
      "train loss:0.8515933605979117\n",
      "train loss:0.7561899199356791\n",
      "train loss:0.8484308992122322\n",
      "train loss:1.0360351997040373\n",
      "train loss:1.0814021591311083\n",
      "train loss:1.041115797045562\n",
      "train loss:1.1488023124887088\n",
      "train loss:0.8117434314337711\n",
      "train loss:0.8033787172883899\n",
      "train loss:0.996451887065891\n",
      "train loss:0.8964845353965214\n",
      "train loss:1.003300974366733\n",
      "train loss:1.0378318069017642\n",
      "train loss:1.191691748429897\n",
      "train loss:1.1113124968705754\n",
      "train loss:1.1579556454741233\n",
      "train loss:1.1093606660999251\n",
      "train loss:0.8882277537792126\n",
      "train loss:0.7414326853491323\n",
      "train loss:1.1088953467247398\n",
      "train loss:1.1406342603367958\n",
      "train loss:1.1375408236352182\n",
      "train loss:0.8455584592763379\n",
      "train loss:0.99176090703263\n",
      "train loss:1.0606872395255078\n",
      "train loss:1.0876004126372907\n",
      "train loss:1.0516204162521008\n",
      "train loss:1.0413390490978736\n",
      "train loss:0.9965269168680454\n",
      "train loss:1.077511379700346\n",
      "train loss:0.9838435956785214\n",
      "train loss:1.0556285186397094\n",
      "train loss:0.8639068030850124\n",
      "train loss:0.9479024820665027\n",
      "train loss:0.958392623188617\n",
      "train loss:0.9785312213223795\n",
      "train loss:1.0989690059044108\n",
      "train loss:0.9742034630687361\n",
      "train loss:0.931891276197716\n",
      "train loss:0.8943229608442707\n",
      "train loss:0.9066879398837863\n",
      "train loss:1.0726486818808139\n",
      "train loss:1.1767428602424586\n",
      "train loss:0.8521473332636235\n",
      "train loss:0.8945551913404879\n",
      "train loss:0.9747072752644914\n",
      "train loss:0.9435669214102801\n",
      "train loss:1.0308924797577625\n",
      "train loss:1.1555274970751044\n",
      "train loss:0.9892669660685562\n",
      "train loss:1.1754866817581238\n",
      "train loss:1.1341645238958507\n",
      "train loss:1.0327364626514888\n",
      "train loss:0.953184294075309\n",
      "train loss:1.0866834469424234\n",
      "train loss:0.9010709759705116\n",
      "train loss:0.9637893169074987\n",
      "train loss:1.060805695694767\n",
      "train loss:1.0347126585525128\n",
      "train loss:1.1091427846429938\n",
      "train loss:0.9802256561125818\n",
      "train loss:0.8079369727148678\n",
      "train loss:1.06496093662128\n",
      "train loss:1.1421961316165563\n",
      "train loss:0.9654493768414913\n",
      "train loss:0.822099439012932\n",
      "train loss:1.093795825548638\n",
      "train loss:1.044924385172236\n",
      "train loss:0.9382887498714454\n",
      "train loss:1.0587898054917557\n",
      "train loss:1.0432665858724501\n",
      "train loss:1.1889931565265714\n",
      "train loss:1.0875727852235562\n",
      "train loss:1.0991837951692047\n",
      "train loss:1.0649998766564817\n",
      "train loss:0.9872068382527321\n",
      "train loss:0.911458281762459\n",
      "train loss:0.9740281812958479\n",
      "train loss:1.101696096528349\n",
      "train loss:1.0656147281176258\n",
      "train loss:0.9320594683094607\n",
      "train loss:0.955773789418962\n",
      "train loss:1.0043127621608015\n",
      "train loss:0.7332111108646925\n",
      "train loss:0.8446199403122674\n",
      "train loss:0.9472002532508482\n",
      "train loss:0.9823424562472652\n",
      "train loss:0.9345747703230332\n",
      "train loss:0.9482965854475244\n",
      "train loss:0.9233691517201789\n",
      "train loss:0.8898042331005328\n",
      "train loss:1.0139002854844448\n",
      "train loss:1.0690641435979584\n",
      "train loss:0.9952333796274023\n",
      "train loss:1.0129962224894056\n",
      "train loss:0.952286711266376\n",
      "train loss:1.0740320252652404\n",
      "train loss:0.9932069759713336\n",
      "train loss:0.9954009141440571\n",
      "train loss:1.0765511263200729\n",
      "train loss:0.9684815027430765\n",
      "train loss:0.9598299382120729\n",
      "train loss:0.8342984833721974\n",
      "train loss:1.001686523401679\n",
      "train loss:1.1111273575908225\n",
      "train loss:0.9779730077797341\n",
      "train loss:1.0000111048044367\n",
      "train loss:1.0034877946970484\n",
      "train loss:1.0835891423055082\n",
      "train loss:1.1298983199338848\n",
      "train loss:1.048311868259662\n",
      "train loss:0.8921382010489017\n",
      "train loss:1.050045270589659\n",
      "train loss:0.9926837004216756\n",
      "train loss:0.9033235006775701\n",
      "train loss:1.132453729739788\n",
      "train loss:1.0255867174280149\n",
      "train loss:1.0502889118787808\n",
      "train loss:1.0860287488496763\n",
      "train loss:1.0478147788269316\n",
      "train loss:0.9903776704892837\n",
      "train loss:1.1760347175454609\n",
      "train loss:0.9781156288810685\n",
      "train loss:0.8940722555966039\n",
      "train loss:1.0807671632245897\n",
      "train loss:0.9926784940332809\n",
      "train loss:1.022057414102945\n",
      "train loss:0.9137462261447196\n",
      "train loss:0.9978281106799056\n",
      "train loss:0.9004740861802548\n",
      "train loss:1.0283746634727151\n",
      "train loss:1.0639551666175608\n",
      "train loss:1.012356057753757\n",
      "train loss:1.0293491180201588\n",
      "train loss:0.8981429979932609\n",
      "train loss:0.9457394653790726\n",
      "train loss:0.902466945788629\n",
      "train loss:0.9522130023248626\n",
      "train loss:1.0786725067560168\n",
      "train loss:0.9951394677672034\n",
      "train loss:1.0191789459534615\n",
      "train loss:0.9401883591335278\n",
      "train loss:1.0019016187131111\n",
      "train loss:1.0471027796377246\n",
      "train loss:0.9866553689717462\n",
      "train loss:1.0196055866307434\n",
      "train loss:0.9168913315031172\n",
      "train loss:1.0721914326537785\n",
      "train loss:0.9575023449360855\n",
      "train loss:0.8408680337740339\n",
      "train loss:0.9550248620464578\n",
      "train loss:0.965893893228685\n",
      "train loss:0.9865706109998665\n",
      "train loss:1.1186987047733985\n",
      "train loss:1.130959096980079\n",
      "train loss:1.107921383955685\n",
      "train loss:0.8764282201899029\n",
      "train loss:0.9532403774292465\n",
      "train loss:1.0801808038181209\n",
      "train loss:1.0009158211791438\n",
      "train loss:0.9614868967098208\n",
      "train loss:0.9523271733758244\n",
      "train loss:0.9261231897887935\n",
      "train loss:1.0773129957320828\n",
      "train loss:0.960737355699022\n",
      "train loss:1.109196024979908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9292212086930212\n",
      "train loss:1.0538511346927473\n",
      "train loss:0.9153515067787804\n",
      "train loss:0.9824180927393052\n",
      "train loss:0.9799497095212644\n",
      "train loss:1.0332747839018643\n",
      "train loss:0.9247648110959874\n",
      "train loss:0.9642202693404814\n",
      "train loss:1.0869225648375542\n",
      "train loss:1.0324592301166242\n",
      "train loss:1.1098599886402427\n",
      "train loss:1.0213449665203718\n",
      "train loss:1.1277142887372986\n",
      "train loss:1.0678750541352027\n",
      "train loss:1.1255651385642764\n",
      "train loss:0.9859260216427643\n",
      "train loss:1.0012506723594063\n",
      "train loss:0.9792193888538937\n",
      "train loss:0.8688898151151011\n",
      "train loss:0.9051123366930038\n",
      "train loss:0.9588282193385922\n",
      "train loss:1.0065707720652757\n",
      "train loss:0.9504167239233151\n",
      "train loss:0.9873573255459189\n",
      "train loss:1.0853495072049908\n",
      "train loss:1.0181386742590968\n",
      "train loss:0.9573088026697423\n",
      "train loss:1.0461953010458434\n",
      "train loss:0.9265568744940669\n",
      "train loss:0.7221648974827195\n",
      "train loss:0.9563759085331668\n",
      "train loss:0.9325406662150371\n",
      "train loss:0.9997802192560878\n",
      "train loss:0.8885992036014081\n",
      "train loss:1.1483284663181168\n",
      "train loss:0.9229079569011128\n",
      "train loss:1.1920869329200499\n",
      "train loss:0.96664127323888\n",
      "train loss:0.9192141114413144\n",
      "train loss:0.8494583030810365\n",
      "train loss:0.9977838818675043\n",
      "train loss:1.0164893915236979\n",
      "train loss:0.8023933440319065\n",
      "train loss:0.9774889878355026\n",
      "train loss:0.9909686483817006\n",
      "train loss:1.0862452698845924\n",
      "train loss:0.9564780268553835\n",
      "train loss:0.8871686314547064\n",
      "train loss:1.081976175582892\n",
      "train loss:0.876505692302615\n",
      "train loss:0.9918940299051764\n",
      "train loss:0.9475982270141173\n",
      "train loss:1.0492133164110078\n",
      "train loss:1.012580014751104\n",
      "train loss:0.9087849953080513\n",
      "train loss:1.0322880364533018\n",
      "train loss:0.778209714225017\n",
      "train loss:0.9959474560368404\n",
      "train loss:0.9676102708701971\n",
      "train loss:1.0275785901730894\n",
      "train loss:1.0118085466147138\n",
      "train loss:0.8874477275861062\n",
      "train loss:0.9604287098605542\n",
      "train loss:0.8801994831896767\n",
      "train loss:1.0404736281121938\n",
      "train loss:1.0345004760982288\n",
      "train loss:1.0406893443400669\n",
      "train loss:0.9758043960504349\n",
      "train loss:0.969509605495637\n",
      "train loss:1.2303047438405645\n",
      "train loss:0.9724039300347215\n",
      "train loss:1.0210264433127054\n",
      "train loss:1.093084069989624\n",
      "train loss:1.123705947022304\n",
      "train loss:1.0099668475691201\n",
      "train loss:1.17208586254781\n",
      "train loss:0.8475395123791877\n",
      "train loss:0.8987507794714585\n",
      "train loss:1.085833838437553\n",
      "train loss:0.8900488906493926\n",
      "train loss:0.9177622831378733\n",
      "train loss:1.066278168175007\n",
      "train loss:1.0777456274349118\n",
      "train loss:1.174883702173235\n",
      "train loss:1.219604299913786\n",
      "train loss:1.080832859984925\n",
      "train loss:1.0061221399203064\n",
      "train loss:0.9764633613308146\n",
      "train loss:1.0018701044663343\n",
      "train loss:0.9594416630506941\n",
      "train loss:0.9607248453332546\n",
      "train loss:0.9735035904569205\n",
      "train loss:0.9510694662866755\n",
      "train loss:0.9672734790136027\n",
      "train loss:0.8783145022061853\n",
      "train loss:1.0136050252213114\n",
      "train loss:1.0653581290077188\n",
      "train loss:0.8587899656635565\n",
      "train loss:0.951148800308668\n",
      "train loss:1.0304187676797958\n",
      "train loss:0.9947722213706538\n",
      "train loss:0.8017831898300106\n",
      "train loss:0.8887796553513364\n",
      "train loss:0.9320067305708721\n",
      "train loss:1.2288999261365274\n",
      "train loss:1.0693210101266688\n",
      "train loss:0.9340898517340497\n",
      "train loss:0.903921293239777\n",
      "train loss:0.9430260229776998\n",
      "train loss:0.9715053736248557\n",
      "train loss:0.9709883484041079\n",
      "train loss:1.1519904708942135\n",
      "train loss:1.1500587641245574\n",
      "train loss:0.9659222830077513\n",
      "train loss:1.1524503536162118\n",
      "train loss:1.1293542998830026\n",
      "train loss:1.1400515696394187\n",
      "train loss:1.0709235034038274\n",
      "train loss:1.1502158296827827\n",
      "train loss:0.9606883247129718\n",
      "train loss:0.9368680582320266\n",
      "train loss:0.9897226254838956\n",
      "train loss:0.9099063233457315\n",
      "train loss:0.9703938355713488\n",
      "train loss:0.8661192734421178\n",
      "train loss:1.0319014287697452\n",
      "train loss:1.0812042174440355\n",
      "train loss:0.8660488936952704\n",
      "train loss:1.1653852619971279\n",
      "train loss:1.1609245400327843\n",
      "train loss:1.1524634224486179\n",
      "train loss:0.8431974827465212\n",
      "train loss:0.9719233734339007\n",
      "train loss:1.0329839596596107\n",
      "train loss:0.8842345862990254\n",
      "train loss:0.8786594567421524\n",
      "train loss:1.0763916231677175\n",
      "train loss:1.0135173095478889\n",
      "train loss:1.071763615000329\n",
      "train loss:0.9452355371303338\n",
      "train loss:1.10720742554757\n",
      "train loss:0.9455708049983774\n",
      "train loss:0.9459133390788474\n",
      "train loss:1.058357798008377\n",
      "train loss:1.1219593460956887\n",
      "train loss:0.9469307585124708\n",
      "train loss:0.9939820607072934\n",
      "train loss:1.0495190038685684\n",
      "train loss:0.9621597344750389\n",
      "train loss:0.9585808821532171\n",
      "train loss:1.0222942207294468\n",
      "train loss:0.8686477477407298\n",
      "train loss:1.1602648237379736\n",
      "train loss:0.9409258451101539\n",
      "train loss:0.8764193699804628\n",
      "train loss:0.9457885905388735\n",
      "train loss:0.8384214974188731\n",
      "train loss:0.8734507272313405\n",
      "train loss:0.7106553184293949\n",
      "train loss:1.0783804452140309\n",
      "train loss:0.9398090353469694\n",
      "train loss:1.0456272792521528\n",
      "train loss:1.0013579432048558\n",
      "train loss:0.9544858541090505\n",
      "train loss:1.0028403856213357\n",
      "train loss:0.9492366761347438\n",
      "train loss:0.8627832228523292\n",
      "train loss:0.8304809120443398\n",
      "train loss:0.8057257450610287\n",
      "train loss:0.9795958081341708\n",
      "train loss:1.07468397033296\n",
      "train loss:1.1481470566953356\n",
      "train loss:1.0944049296491583\n",
      "train loss:0.8405041074457441\n",
      "train loss:1.1682782389486306\n",
      "train loss:0.9319522670544673\n",
      "train loss:0.866240111332957\n",
      "train loss:1.172252964950137\n",
      "train loss:1.1090633568518833\n",
      "train loss:1.027476294990319\n",
      "train loss:1.0321516811010585\n",
      "train loss:1.0330044730657633\n",
      "train loss:1.1445740308142442\n",
      "train loss:1.058985590827711\n",
      "train loss:1.0356672098319795\n",
      "train loss:0.932214470564531\n",
      "train loss:1.0541641209467603\n",
      "train loss:1.045081184838952\n",
      "train loss:1.0584180612235994\n",
      "train loss:1.1040486252377097\n",
      "train loss:0.7805929957571182\n",
      "train loss:0.9959470381984167\n",
      "train loss:0.872889018000008\n",
      "train loss:1.0730527785294786\n",
      "train loss:0.8722103212038681\n",
      "train loss:1.0144513122578775\n",
      "train loss:0.8960545407445092\n",
      "train loss:0.8640056248858692\n",
      "train loss:0.9487786436136523\n",
      "train loss:1.0780458854171846\n",
      "train loss:1.0687212824760923\n",
      "train loss:0.7706680113020137\n",
      "train loss:1.0260999381389533\n",
      "train loss:1.1099243461814798\n",
      "train loss:1.0612409216931395\n",
      "train loss:1.1556093573586137\n",
      "train loss:0.9867621664202821\n",
      "train loss:0.9402655436031848\n",
      "train loss:1.0352343702602596\n",
      "train loss:1.0156871134212617\n",
      "train loss:1.0539917398695542\n",
      "train loss:1.132095385790845\n",
      "train loss:0.7935287157274266\n",
      "train loss:0.8977245031510208\n",
      "train loss:0.8468390734292267\n",
      "train loss:0.7780599953141996\n",
      "train loss:0.8830658539389699\n",
      "train loss:0.906231831038143\n",
      "train loss:1.0701226307892246\n",
      "train loss:1.0259585256766681\n",
      "train loss:1.0188268767324762\n",
      "train loss:1.1252782880389989\n",
      "train loss:1.0875054948959195\n",
      "train loss:1.0147493657181306\n",
      "train loss:0.981126553706286\n",
      "train loss:1.1106615410283829\n",
      "train loss:0.9922643534075053\n",
      "train loss:0.8805473285955239\n",
      "train loss:1.0651461373249569\n",
      "train loss:0.8989973604852959\n",
      "train loss:0.9543262561893988\n",
      "train loss:0.964317078832792\n",
      "train loss:1.0010242898157575\n",
      "train loss:0.938964660264141\n",
      "train loss:0.9488952617137714\n",
      "train loss:1.152348864270491\n",
      "train loss:0.9868931944523931\n",
      "train loss:0.9924956162821489\n",
      "train loss:1.1337668039009552\n",
      "train loss:0.9002241870559847\n",
      "train loss:0.7460057659994302\n",
      "train loss:1.0044838577737911\n",
      "train loss:1.0342422501422583\n",
      "train loss:0.9496866670710865\n",
      "train loss:0.9670184061779462\n",
      "train loss:1.2242097758845798\n",
      "train loss:1.0025229611785575\n",
      "train loss:0.9554421688312387\n",
      "train loss:0.9972996279979003\n",
      "train loss:1.0851786866397124\n",
      "train loss:0.9257792628687163\n",
      "train loss:0.912503687687611\n",
      "train loss:0.9870426412692717\n",
      "train loss:1.02365267448914\n",
      "train loss:0.9694694223003899\n",
      "train loss:0.8989070738365065\n",
      "train loss:0.9302443070138857\n",
      "train loss:0.810889439770862\n",
      "train loss:1.0146308280354155\n",
      "train loss:0.8765251648205477\n",
      "train loss:0.8492981367147641\n",
      "train loss:1.0082804874445137\n",
      "train loss:0.940731195933607\n",
      "train loss:1.0179681057069645\n",
      "train loss:0.8757963400819138\n",
      "train loss:1.02042813656227\n",
      "train loss:1.0227245662360398\n",
      "train loss:0.925718575014441\n",
      "train loss:0.9335341966426374\n",
      "train loss:1.0664580486197843\n",
      "train loss:0.9337377943152444\n",
      "train loss:1.0296030969999046\n",
      "train loss:1.1791696935713603\n",
      "train loss:1.0008444908853165\n",
      "train loss:0.9702300067904713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.017124972479146\n",
      "train loss:1.045685217755374\n",
      "train loss:0.9290927347387629\n",
      "train loss:1.0433758358480913\n",
      "train loss:0.95651209705561\n",
      "train loss:1.129138090801368\n",
      "train loss:0.9231210662775711\n",
      "train loss:1.0489930450224196\n",
      "train loss:0.9260942907362778\n",
      "train loss:1.0669740048151242\n",
      "train loss:0.8776490917033871\n",
      "train loss:1.0376985766672293\n",
      "train loss:0.9084364270577409\n",
      "train loss:0.8936361745700802\n",
      "train loss:1.011541103979796\n",
      "train loss:1.0231901138360964\n",
      "train loss:1.228147809995433\n",
      "train loss:1.008475080117874\n",
      "train loss:0.9469967417422328\n",
      "train loss:1.0699191334059621\n",
      "train loss:0.8938986631331857\n",
      "train loss:1.0721938763418886\n",
      "train loss:1.0468729806938102\n",
      "train loss:1.0410503083719378\n",
      "train loss:1.1011958382848568\n",
      "train loss:0.8181973023146591\n",
      "train loss:0.924101819871579\n",
      "train loss:1.06906924292875\n",
      "train loss:0.9201939678077351\n",
      "train loss:1.0476653027348721\n",
      "train loss:1.067093975174566\n",
      "train loss:0.8699745101845832\n",
      "train loss:1.0133226875441415\n",
      "train loss:1.0321040062669677\n",
      "train loss:0.9376752501773933\n",
      "train loss:1.0061757260078619\n",
      "train loss:0.9686692591822522\n",
      "train loss:0.8845513376746894\n",
      "train loss:1.0093538717500117\n",
      "train loss:1.1439409544015473\n",
      "train loss:0.9708751566592029\n",
      "train loss:0.8984616624556163\n",
      "train loss:0.9326627956756524\n",
      "train loss:1.0398164080849635\n",
      "train loss:1.0242904617506843\n",
      "train loss:1.0547220274800662\n",
      "train loss:1.0373161195114642\n",
      "train loss:1.3444056373388287\n",
      "train loss:0.9746715119363951\n",
      "train loss:0.9314563572138589\n",
      "train loss:0.8371990582637094\n",
      "train loss:1.0693387423003622\n",
      "train loss:0.9654859247866238\n",
      "train loss:0.9719981196796469\n",
      "train loss:0.828415780692553\n",
      "train loss:1.0627993295700362\n",
      "train loss:1.2486293366573407\n",
      "train loss:0.9338906574963686\n",
      "train loss:0.9576754361960397\n",
      "train loss:1.1119908312374795\n",
      "train loss:0.9760558461196404\n",
      "train loss:1.0049365586480352\n",
      "train loss:0.99602076867942\n",
      "train loss:0.965425378613118\n",
      "train loss:1.0008931447425145\n",
      "train loss:0.8363472474945874\n",
      "train loss:1.0862461909617358\n",
      "train loss:0.8694311482744773\n",
      "train loss:1.0041498763281835\n",
      "train loss:0.9645469181586488\n",
      "train loss:0.8671085857317908\n",
      "train loss:1.0737171156533345\n",
      "train loss:1.241504349386703\n",
      "train loss:0.959332391150404\n",
      "train loss:0.9826688504835849\n",
      "train loss:0.893452731374934\n",
      "train loss:0.9738452656035996\n",
      "train loss:1.031858062101428\n",
      "train loss:0.9135664268166837\n",
      "train loss:0.781654859169749\n",
      "train loss:0.9978449452207785\n",
      "train loss:1.0452685304550255\n",
      "train loss:1.0726498763172376\n",
      "train loss:1.119183959675202\n",
      "train loss:1.0509769698707756\n",
      "train loss:1.0304570562192787\n",
      "train loss:0.8063442360330286\n",
      "train loss:0.9626653297791357\n",
      "train loss:0.9010534592355625\n",
      "train loss:0.8454236478708026\n",
      "train loss:1.0635417238666145\n",
      "train loss:1.0840610675922988\n",
      "train loss:1.0071412415139973\n",
      "train loss:1.0881227406644696\n",
      "train loss:0.8257709240937174\n",
      "train loss:1.131939366538922\n",
      "train loss:0.9512248368204987\n",
      "train loss:1.0371115775236657\n",
      "train loss:0.9833211469790709\n",
      "train loss:0.9801047163161438\n",
      "train loss:0.8673789910151541\n",
      "train loss:1.0006288413498279\n",
      "train loss:0.8431446892156826\n",
      "train loss:0.9415244748096769\n",
      "train loss:1.0447712770482946\n",
      "train loss:0.7463631490435526\n",
      "train loss:1.0758890442727571\n",
      "train loss:1.095437823023638\n",
      "train loss:0.9002952011560323\n",
      "train loss:0.9423491224414379\n",
      "train loss:0.9625125024681719\n",
      "train loss:0.9224979981799142\n",
      "train loss:1.0545793960093126\n",
      "train loss:0.9760814122426449\n",
      "train loss:1.070480669754518\n",
      "train loss:1.1511841582284585\n",
      "train loss:1.0661851378481897\n",
      "train loss:0.8385373389617442\n",
      "train loss:0.9711454535390126\n",
      "train loss:1.0624725158197745\n",
      "train loss:0.9173727187581991\n",
      "train loss:1.083250889187539\n",
      "train loss:0.9379619181164561\n",
      "train loss:0.9530188995657878\n",
      "train loss:1.028404605996253\n",
      "train loss:0.9181116700126973\n",
      "train loss:1.0153889297273564\n",
      "train loss:1.0741145807230734\n",
      "train loss:0.9946290512591273\n",
      "train loss:0.9816258883288811\n",
      "train loss:1.006491051714608\n",
      "train loss:1.0103671623046235\n",
      "train loss:0.938449149915457\n",
      "train loss:0.9313897016640474\n",
      "train loss:1.0121522368678801\n",
      "train loss:0.9976126747356456\n",
      "train loss:0.9931906726273589\n",
      "train loss:1.055448071199053\n",
      "train loss:1.0900836974695085\n",
      "train loss:0.9233373712252856\n",
      "train loss:1.1365430881045884\n",
      "train loss:0.9695009289694201\n",
      "train loss:0.8056435503496624\n",
      "train loss:1.0020648697621612\n",
      "train loss:0.9906318329601201\n",
      "train loss:1.1798607259276512\n",
      "train loss:0.9642216352625226\n",
      "train loss:0.8725409535947927\n",
      "train loss:0.7266827904217874\n",
      "train loss:1.0986081750244319\n",
      "train loss:1.1391769638902023\n",
      "train loss:1.0205991726786645\n",
      "train loss:0.9378769817875039\n",
      "=== epoch:4, train acc:0.986, test acc:0.981 ===\n",
      "train loss:1.0802717456035926\n",
      "train loss:0.7721469730807684\n",
      "train loss:1.0342368005004507\n",
      "train loss:0.9992515653755492\n",
      "train loss:1.1650068883010847\n",
      "train loss:0.9400131154061384\n",
      "train loss:0.9527949413063037\n",
      "train loss:1.0178533599133417\n",
      "train loss:0.8964870908221065\n",
      "train loss:1.0570918286222577\n",
      "train loss:0.9684181753920719\n",
      "train loss:1.007723867179601\n",
      "train loss:0.9364804565236996\n",
      "train loss:0.9693924592267887\n",
      "train loss:1.0176614198725498\n",
      "train loss:0.8439802218204643\n",
      "train loss:0.903168882584384\n",
      "train loss:1.0039912627866152\n",
      "train loss:1.021303408538537\n",
      "train loss:1.016918756228474\n",
      "train loss:1.1747401435846425\n",
      "train loss:1.0227789785218966\n",
      "train loss:0.834452029876776\n",
      "train loss:0.8360506336836339\n",
      "train loss:0.8811814662507744\n",
      "train loss:0.9674765298330447\n",
      "train loss:0.8502539397599107\n",
      "train loss:0.8460554862684275\n",
      "train loss:0.9845310214122572\n",
      "train loss:0.857301774099485\n",
      "train loss:0.9061050137176326\n",
      "train loss:0.922919123048303\n",
      "train loss:0.9545079964470774\n",
      "train loss:1.208224388805642\n",
      "train loss:1.0446139691174858\n",
      "train loss:0.8970215247339351\n",
      "train loss:1.0281454441323001\n",
      "train loss:0.9507000729311467\n",
      "train loss:0.9671523850837772\n",
      "train loss:0.859617255088878\n",
      "train loss:0.8706638376242292\n",
      "train loss:0.8900085923832036\n",
      "train loss:0.967650790210891\n",
      "train loss:0.8239090680921085\n",
      "train loss:1.0525092754845575\n",
      "train loss:0.8059750929606045\n",
      "train loss:0.8530032203867587\n",
      "train loss:0.9502835737598176\n",
      "train loss:0.9490556767980975\n",
      "train loss:0.9526920663010776\n",
      "train loss:1.2165584773714857\n",
      "train loss:0.9475199739309424\n",
      "train loss:1.0762840767044741\n",
      "train loss:1.001488241999231\n",
      "train loss:0.8475316040251254\n",
      "train loss:1.0178496934124517\n",
      "train loss:0.9348005046060598\n",
      "train loss:1.0549468660730916\n",
      "train loss:1.0960557845649272\n",
      "train loss:0.8338976360904904\n",
      "train loss:0.9633019874808284\n",
      "train loss:1.109492298564069\n",
      "train loss:0.8411604814783119\n",
      "train loss:0.9259186807819164\n",
      "train loss:1.0239042408012249\n",
      "train loss:0.9023341882488093\n",
      "train loss:0.8014935362982105\n",
      "train loss:0.8982726471367086\n",
      "train loss:1.1435166808466757\n",
      "train loss:0.9076839071334688\n",
      "train loss:1.1104369283102808\n",
      "train loss:1.0494291071479172\n",
      "train loss:1.0799458374642885\n",
      "train loss:1.0366856857732856\n",
      "train loss:0.9704442051001431\n",
      "train loss:0.9138249105646646\n",
      "train loss:1.1633710937824286\n",
      "train loss:0.900072045935831\n",
      "train loss:0.9111150787156228\n",
      "train loss:1.0255848225378645\n",
      "train loss:0.9071847246936686\n",
      "train loss:0.7529613686087397\n",
      "train loss:0.884610073624023\n",
      "train loss:1.025114597416307\n",
      "train loss:0.838059488564721\n",
      "train loss:1.0625196034284878\n",
      "train loss:0.8451451263744656\n",
      "train loss:0.9432743752700012\n",
      "train loss:0.9387424473883118\n",
      "train loss:0.9457960221246728\n",
      "train loss:0.8771324297232277\n",
      "train loss:1.0637797636507518\n",
      "train loss:0.9892259484138427\n",
      "train loss:0.9147596922548843\n",
      "train loss:1.0442296026231628\n",
      "train loss:1.048336088494217\n",
      "train loss:0.9914385016947344\n",
      "train loss:0.9114844629416452\n",
      "train loss:1.041124118816146\n",
      "train loss:1.0130327530218601\n",
      "train loss:0.8734222900255433\n",
      "train loss:0.879347039684318\n",
      "train loss:1.0454622028947256\n",
      "train loss:0.9548948625766571\n",
      "train loss:0.9294068910224496\n",
      "train loss:1.111800808880296\n",
      "train loss:1.1204026593372562\n",
      "train loss:0.932340457995826\n",
      "train loss:0.8322877644370282\n",
      "train loss:0.98666198301231\n",
      "train loss:0.8090971415571091\n",
      "train loss:0.8961756610037943\n",
      "train loss:1.0571065736321659\n",
      "train loss:1.0101339241387022\n",
      "train loss:0.8238754630630598\n",
      "train loss:0.9200182753642341\n",
      "train loss:1.1126058885047763\n",
      "train loss:0.9047218813287544\n",
      "train loss:1.0088600573544446\n",
      "train loss:0.9907234634469217\n",
      "train loss:0.9036743760929007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8940439290632789\n",
      "train loss:0.9986990427736379\n",
      "train loss:0.8440985762998982\n",
      "train loss:0.9940150299998544\n",
      "train loss:0.9774229733064782\n",
      "train loss:0.7712222494316687\n",
      "train loss:1.0065734436673723\n",
      "train loss:1.0722311690366881\n",
      "train loss:0.9655430276984377\n",
      "train loss:0.7151219301786088\n",
      "train loss:0.8855022464523585\n",
      "train loss:0.8959219895677103\n",
      "train loss:1.0367094461496535\n",
      "train loss:1.061490179913784\n",
      "train loss:1.105180623500693\n",
      "train loss:0.8828178014720856\n",
      "train loss:1.0330044346927982\n",
      "train loss:1.0205444947920281\n",
      "train loss:0.958926278761636\n",
      "train loss:1.0338261441248684\n",
      "train loss:0.8803382772326109\n",
      "train loss:1.061627119582391\n",
      "train loss:0.8864957850209919\n",
      "train loss:1.025314855878136\n",
      "train loss:0.9188713567529538\n",
      "train loss:1.0159026351898301\n",
      "train loss:1.0294251589192582\n",
      "train loss:0.9990517630914433\n",
      "train loss:0.8906619976868965\n",
      "train loss:0.9832382812879423\n",
      "train loss:0.8108119015423416\n",
      "train loss:0.8412793903059794\n",
      "train loss:0.9768367338796825\n",
      "train loss:0.8771677593831122\n",
      "train loss:1.0738459469106578\n",
      "train loss:0.9748487734354753\n",
      "train loss:0.8405809765621961\n",
      "train loss:0.9343255607420646\n",
      "train loss:0.8683697908959453\n",
      "train loss:1.1123643943025774\n",
      "train loss:0.9205689919518718\n",
      "train loss:0.9585649919857072\n",
      "train loss:0.997899219427158\n",
      "train loss:1.084278490186461\n",
      "train loss:0.8528858300265039\n",
      "train loss:0.856117237710809\n",
      "train loss:0.8937458364698081\n",
      "train loss:1.2036045171536531\n",
      "train loss:0.9138961160924437\n",
      "train loss:1.0885168049057432\n",
      "train loss:0.9418462197323803\n",
      "train loss:0.9814434066775415\n",
      "train loss:0.8181906243725223\n",
      "train loss:0.8739353304275584\n",
      "train loss:0.9417301200121233\n",
      "train loss:0.9325052589989697\n",
      "train loss:0.9477318887995565\n",
      "train loss:0.9924034101842196\n",
      "train loss:1.0241940284085829\n",
      "train loss:0.9914909173028004\n",
      "train loss:0.9837903857764703\n",
      "train loss:1.0558719787926283\n",
      "train loss:0.9476012158931282\n",
      "train loss:1.0193603479896036\n",
      "train loss:0.9394047591974234\n",
      "train loss:1.0138317803794938\n",
      "train loss:0.9576088448265878\n",
      "train loss:1.1750651450167537\n",
      "train loss:1.0584850249497244\n",
      "train loss:0.9262441542779718\n",
      "train loss:1.0160108471099638\n",
      "train loss:0.9978956342650693\n",
      "train loss:0.9214728466412281\n",
      "train loss:0.9293107773257409\n",
      "train loss:1.0319891631152769\n",
      "train loss:0.8719764174082185\n",
      "train loss:0.9861538267480463\n",
      "train loss:0.9079805904632043\n",
      "train loss:0.8397025355002116\n",
      "train loss:0.9889837365916886\n",
      "train loss:0.9111463944114361\n",
      "train loss:0.8080938441228855\n",
      "train loss:1.1566340282700025\n",
      "train loss:1.1312861338542046\n",
      "train loss:0.924078453059885\n",
      "train loss:0.9732743952146456\n",
      "train loss:0.9620176026055123\n",
      "train loss:1.043968846340794\n",
      "train loss:1.1206923343850175\n",
      "train loss:0.7768751698334075\n",
      "train loss:0.9253339965851078\n",
      "train loss:0.9814267243520761\n",
      "train loss:0.9278268416087221\n",
      "train loss:1.0407961839299893\n",
      "train loss:1.0414231959592803\n",
      "train loss:1.031831874776929\n",
      "train loss:1.0541748085283227\n",
      "train loss:0.9775884418255915\n",
      "train loss:0.8149065737443063\n",
      "train loss:0.8482207044967719\n",
      "train loss:1.0645850394078733\n",
      "train loss:0.8966105850471509\n",
      "train loss:0.8073958061192341\n",
      "train loss:0.9948097167768479\n",
      "train loss:0.9660497549840008\n",
      "train loss:0.9345870883456633\n",
      "train loss:0.8376073593924049\n",
      "train loss:1.0150003895599478\n",
      "train loss:0.9556738648315489\n",
      "train loss:0.8441716304087997\n",
      "train loss:1.0172162780848606\n",
      "train loss:0.862769197144734\n",
      "train loss:1.0503620612577633\n",
      "train loss:1.008126719888113\n",
      "train loss:1.1407447697604096\n",
      "train loss:1.1785920221768824\n",
      "train loss:0.9183433662070587\n",
      "train loss:1.0620367819498302\n",
      "train loss:0.7989300842071714\n",
      "train loss:0.9600138736622327\n",
      "train loss:0.8756435118418959\n",
      "train loss:1.0568162510464658\n",
      "train loss:0.9288764623833049\n",
      "train loss:1.0076853701953135\n",
      "train loss:0.9315685721236655\n",
      "train loss:0.9082765213793335\n",
      "train loss:1.1862848245579094\n",
      "train loss:1.061669601809604\n",
      "train loss:1.07285640852417\n",
      "train loss:1.0530065325804179\n",
      "train loss:0.9524700396668869\n",
      "train loss:0.9283389683833504\n",
      "train loss:0.8797120435491682\n",
      "train loss:0.9420152776196531\n",
      "train loss:1.0365899088501198\n",
      "train loss:1.0622327319086924\n",
      "train loss:0.923121504092366\n",
      "train loss:1.0652658572901426\n",
      "train loss:1.0172682791756456\n",
      "train loss:1.0257737898421104\n",
      "train loss:0.8963344689064412\n",
      "train loss:0.9867455967054576\n",
      "train loss:1.1869957092506158\n",
      "train loss:0.8419818885822393\n",
      "train loss:0.9672800444511559\n",
      "train loss:0.9430220095085105\n",
      "train loss:0.9656145177069371\n",
      "train loss:1.0764277769521593\n",
      "train loss:1.0668971790111137\n",
      "train loss:1.0538427480362926\n",
      "train loss:0.9362711680153312\n",
      "train loss:1.0916070640087783\n",
      "train loss:1.0190116444981492\n",
      "train loss:0.999224862319977\n",
      "train loss:1.0271868895105942\n",
      "train loss:1.1591039576799647\n",
      "train loss:0.8883738642941027\n",
      "train loss:0.9981098821147245\n",
      "train loss:0.8198400082746811\n",
      "train loss:0.9963243882840643\n",
      "train loss:0.9844808497875651\n",
      "train loss:1.035290006201988\n",
      "train loss:0.9946535716466611\n",
      "train loss:0.8970653782255943\n",
      "train loss:0.9369773500581455\n",
      "train loss:1.0055160720923613\n",
      "train loss:0.9907048508294687\n",
      "train loss:1.0344802910141377\n",
      "train loss:0.996380546963408\n",
      "train loss:1.020872447363357\n",
      "train loss:1.0455041853801592\n",
      "train loss:0.9520562191916804\n",
      "train loss:0.884069044854054\n",
      "train loss:0.7734012532854604\n",
      "train loss:0.9569394760610898\n",
      "train loss:0.8820626623333174\n",
      "train loss:0.9434691039150713\n",
      "train loss:1.0736889677587786\n",
      "train loss:0.9308859937331668\n",
      "train loss:1.058818219837635\n",
      "train loss:1.0317747356123523\n",
      "train loss:1.0098661938014726\n",
      "train loss:0.9159899329424386\n",
      "train loss:0.997944503499457\n",
      "train loss:0.951626758718293\n",
      "train loss:1.0351619489194526\n",
      "train loss:1.0222060720978208\n",
      "train loss:0.9954806147617629\n",
      "train loss:1.0775837418293104\n",
      "train loss:1.2363951559659396\n",
      "train loss:0.8594265913032304\n",
      "train loss:0.8001746447890202\n",
      "train loss:0.9095839113971271\n",
      "train loss:1.0740483628520605\n",
      "train loss:0.9755965146818617\n",
      "train loss:0.9499490251928673\n",
      "train loss:0.9344476108983839\n",
      "train loss:0.951454167996441\n",
      "train loss:0.8945504797500553\n",
      "train loss:0.9448682715021005\n",
      "train loss:0.9951156254474683\n",
      "train loss:0.9568723968303395\n",
      "train loss:0.9430654574467155\n",
      "train loss:0.9644207811739247\n",
      "train loss:0.8993081644593556\n",
      "train loss:0.9706547819176863\n",
      "train loss:0.8301543811027235\n",
      "train loss:0.8563472756073961\n",
      "train loss:0.9068263858329805\n",
      "train loss:0.9479791333078391\n",
      "train loss:0.8817951608992578\n",
      "train loss:0.9296616275285945\n",
      "train loss:0.9096866898273399\n",
      "train loss:1.148166224028254\n",
      "train loss:1.0122569792278344\n",
      "train loss:1.0328886243692146\n",
      "train loss:1.0474081408419207\n",
      "train loss:0.9197198320617943\n",
      "train loss:0.9252758583793311\n",
      "train loss:1.0680658650666985\n",
      "train loss:0.9368206524163538\n",
      "train loss:0.7534480019524645\n",
      "train loss:0.9039299251827592\n",
      "train loss:0.8657482565444065\n",
      "train loss:1.1467439220006326\n",
      "train loss:0.9496925974858805\n",
      "train loss:1.0083512521012736\n",
      "train loss:0.949245135263766\n",
      "train loss:0.9684881404898666\n",
      "train loss:0.9631190972441084\n",
      "train loss:1.1329565901936507\n",
      "train loss:1.1454843488921929\n",
      "train loss:1.0034482733288204\n",
      "train loss:1.0587391381579319\n",
      "train loss:0.9935335718867085\n",
      "train loss:0.9266015060491085\n",
      "train loss:1.0336950273348742\n",
      "train loss:1.0414081908896358\n",
      "train loss:1.1868468151881881\n",
      "train loss:1.0231944481572979\n",
      "train loss:1.039437605890563\n",
      "train loss:0.9619298808365823\n",
      "train loss:0.8928229762845664\n",
      "train loss:1.0557248210858439\n",
      "train loss:0.868764316475704\n",
      "train loss:1.0100183222047752\n",
      "train loss:0.8227097711018447\n",
      "train loss:0.9809407439113633\n",
      "train loss:0.9394374872501473\n",
      "train loss:0.9393387618416427\n",
      "train loss:1.002206227649323\n",
      "train loss:1.042922294876078\n",
      "train loss:1.0328143876557063\n",
      "train loss:0.8303499752968048\n",
      "train loss:0.8633710108777958\n",
      "train loss:0.9335794613082874\n",
      "train loss:0.9043622644480018\n",
      "train loss:1.1101471025245928\n",
      "train loss:0.8368972437961132\n",
      "train loss:0.8679644451629103\n",
      "train loss:1.123763372409384\n",
      "train loss:0.8977191026406675\n",
      "train loss:0.939217338051901\n",
      "train loss:0.9503255792547265\n",
      "train loss:0.8241828028813376\n",
      "train loss:0.9159533669269502\n",
      "train loss:0.9391338972495181\n",
      "train loss:0.8859920865015806\n",
      "train loss:0.9177067825203133\n",
      "train loss:0.9378360732979654\n",
      "train loss:0.8221342553888255\n",
      "train loss:1.0938290597562\n",
      "train loss:0.9790955430430286\n",
      "train loss:1.1868765129895709\n",
      "train loss:0.857514116150737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7699064302131953\n",
      "train loss:0.8886972341423264\n",
      "train loss:0.8479455126371132\n",
      "train loss:0.9987231100605334\n",
      "train loss:0.910014756273537\n",
      "train loss:0.8703204234485376\n",
      "train loss:0.9737901395922518\n",
      "train loss:0.8762223504781084\n",
      "train loss:1.019769239806032\n",
      "train loss:1.1352285545390624\n",
      "train loss:0.8655741624892979\n",
      "train loss:0.9502637253719162\n",
      "train loss:1.0092707069852611\n",
      "train loss:1.0869713270235908\n",
      "train loss:0.8885490972826589\n",
      "train loss:0.9726089620620667\n",
      "train loss:0.9218265661428603\n",
      "train loss:0.8684357635673348\n",
      "train loss:1.0512306903538624\n",
      "train loss:1.0613934573206327\n",
      "train loss:0.7298574911074303\n",
      "train loss:1.0895331209684824\n",
      "train loss:0.7723193411820419\n",
      "train loss:0.9479195302876962\n",
      "train loss:0.8915059470124714\n",
      "train loss:0.8448860859665398\n",
      "train loss:0.9829681027529574\n",
      "train loss:0.9327999130466185\n",
      "train loss:0.9945920716371297\n",
      "train loss:0.9766720038138333\n",
      "train loss:1.0717283932306638\n",
      "train loss:1.0014965736365355\n",
      "train loss:0.9634739942919367\n",
      "train loss:0.8844247581432184\n",
      "train loss:0.8645366046567433\n",
      "train loss:0.821755803158983\n",
      "train loss:0.969463200550765\n",
      "train loss:1.2088252968609228\n",
      "train loss:1.115837207157663\n",
      "train loss:0.9195170085275653\n",
      "train loss:0.9331802167071754\n",
      "train loss:0.9677572578887919\n",
      "train loss:0.9984870895098281\n",
      "train loss:1.0005043404273082\n",
      "train loss:0.9383196120191789\n",
      "train loss:0.8835738540591369\n",
      "train loss:0.6659518792493451\n",
      "train loss:0.8118755576696671\n",
      "train loss:0.9164766227605802\n",
      "train loss:0.9118383632870731\n",
      "train loss:0.9017464780807029\n",
      "train loss:1.0737808299551377\n",
      "train loss:0.8819245787944672\n",
      "train loss:0.8172678039493896\n",
      "train loss:0.8331975256810464\n",
      "train loss:0.9098863022001256\n",
      "train loss:0.9120566426308219\n",
      "train loss:0.9266832522660777\n",
      "train loss:0.7587585673058189\n",
      "train loss:0.9409780541709654\n",
      "train loss:0.90217448727693\n",
      "train loss:0.9208071011840407\n",
      "train loss:0.8869007546543131\n",
      "train loss:0.9229653690474778\n",
      "train loss:0.8293175387187177\n",
      "train loss:0.8072523981627758\n",
      "train loss:0.8737842336615111\n",
      "train loss:0.9234278566823693\n",
      "train loss:0.9242941845185442\n",
      "train loss:0.8981125230057642\n",
      "train loss:0.9332631592661399\n",
      "train loss:0.8892941600074531\n",
      "train loss:0.9420780557807399\n",
      "train loss:0.9422483601350499\n",
      "train loss:1.1239337652151702\n",
      "train loss:0.9400363694611619\n",
      "train loss:1.0039889984027857\n",
      "train loss:0.8890044054826923\n",
      "train loss:1.2283748704244901\n",
      "train loss:0.9859892455458771\n",
      "train loss:0.8562761190507676\n",
      "train loss:0.9431633864480053\n",
      "train loss:0.8631734125594217\n",
      "train loss:1.027975817590535\n",
      "train loss:0.7633205080979721\n",
      "train loss:1.020175285815698\n",
      "train loss:0.7856348310079672\n",
      "train loss:0.841220902006203\n",
      "train loss:1.0821318042672496\n",
      "train loss:1.0082057782400413\n",
      "train loss:1.0823544300812875\n",
      "train loss:1.0583071664120678\n",
      "train loss:1.0067723445685883\n",
      "train loss:1.0101905722682571\n",
      "train loss:0.8810637881969562\n",
      "train loss:0.8619439442173161\n",
      "train loss:0.8143219595957131\n",
      "train loss:0.850267079642603\n",
      "train loss:1.062247232524826\n",
      "train loss:0.7535983996014198\n",
      "train loss:1.028577972240398\n",
      "train loss:0.8127644480924445\n",
      "train loss:0.8572196347489879\n",
      "train loss:0.8657107142453762\n",
      "train loss:0.9772679428085415\n",
      "train loss:1.0096716001928068\n",
      "train loss:0.9274221213136252\n",
      "train loss:1.1609356796714323\n",
      "train loss:1.052339653214515\n",
      "train loss:1.1825076586484833\n",
      "train loss:1.1369377382682142\n",
      "train loss:0.9476289134114724\n",
      "train loss:0.7677151237492843\n",
      "train loss:0.8411499684374573\n",
      "train loss:1.0269209438517584\n",
      "train loss:1.0394559435101463\n",
      "train loss:0.9336058710776708\n",
      "train loss:0.9010731802664457\n",
      "train loss:1.1121036860172886\n",
      "train loss:0.937653019556995\n",
      "train loss:0.8895137277013728\n",
      "train loss:0.9374852423915548\n",
      "train loss:0.7881888746331736\n",
      "train loss:0.8102861552627839\n",
      "train loss:1.0081651635272124\n",
      "train loss:1.1219860454009734\n",
      "train loss:1.1390459973792877\n",
      "train loss:1.0162563217874019\n",
      "train loss:0.8830412869631574\n",
      "train loss:0.902618508321014\n",
      "train loss:0.9739318898999387\n",
      "train loss:1.027892310004187\n",
      "train loss:0.8611954746589849\n",
      "train loss:1.0319382655639084\n",
      "train loss:1.0356798428535863\n",
      "train loss:1.0233943907585432\n",
      "train loss:0.9503810057611959\n",
      "train loss:0.8129862057433661\n",
      "train loss:0.9784108061800381\n",
      "train loss:0.9783168302869256\n",
      "train loss:0.9532049515199122\n",
      "train loss:0.9302994398866096\n",
      "train loss:1.1368926820862548\n",
      "train loss:0.9499509227722865\n",
      "train loss:1.0450760228358489\n",
      "train loss:0.9358871907743328\n",
      "train loss:0.9518046866551928\n",
      "train loss:0.6649975859243566\n",
      "train loss:0.9897952347696968\n",
      "train loss:0.8754748440759913\n",
      "train loss:0.8835725404217708\n",
      "train loss:1.1328559961106401\n",
      "train loss:0.8683357295693951\n",
      "train loss:0.9534775871062254\n",
      "train loss:0.8818216624248236\n",
      "train loss:0.9709540874466129\n",
      "train loss:0.9101411229144378\n",
      "train loss:0.863141278881776\n",
      "train loss:0.9654370395119656\n",
      "train loss:1.1428628863822055\n",
      "train loss:1.0775827608056505\n",
      "train loss:0.9728368472367063\n",
      "train loss:0.9116763984393943\n",
      "train loss:0.8827355334185648\n",
      "train loss:0.909783307015442\n",
      "train loss:0.9406462855208616\n",
      "train loss:0.8546581235809093\n",
      "train loss:0.8663233113946882\n",
      "train loss:0.8884882716432172\n",
      "train loss:0.9446798508108333\n",
      "train loss:0.9105577323082676\n",
      "train loss:0.8728198564901432\n",
      "train loss:0.805497992216504\n",
      "train loss:0.9295551773872083\n",
      "train loss:0.9109755121030794\n",
      "train loss:0.8851702257691101\n",
      "train loss:0.9418077799122238\n",
      "train loss:1.1024250009028302\n",
      "train loss:0.8447422015274966\n",
      "train loss:0.8829789587161929\n",
      "train loss:0.7735008743435345\n",
      "train loss:1.029795652996356\n",
      "train loss:1.0590048841470143\n",
      "train loss:0.8156388602981831\n",
      "train loss:1.0131853995451268\n",
      "train loss:1.0888832189032491\n",
      "train loss:1.014870383596285\n",
      "train loss:0.9010783884448175\n",
      "train loss:0.9969201140559583\n",
      "train loss:1.0654929344424482\n",
      "train loss:0.9212084583357616\n",
      "train loss:1.0100107082418326\n",
      "train loss:1.0011464577884128\n",
      "train loss:1.0333081205017118\n",
      "train loss:1.009518893039364\n",
      "train loss:0.9860827285004842\n",
      "train loss:0.8577734305808531\n",
      "train loss:0.9783731648932641\n",
      "train loss:1.0545303546130977\n",
      "train loss:1.0802462469491874\n",
      "train loss:1.00032326967944\n",
      "train loss:0.9283907572532053\n",
      "train loss:0.7877710818405096\n",
      "train loss:0.9825912879081115\n",
      "=== epoch:5, train acc:0.989, test acc:0.988 ===\n",
      "train loss:1.0178796822760663\n",
      "train loss:0.9784230161487063\n",
      "train loss:0.9336454527759563\n",
      "train loss:0.980170083505952\n",
      "train loss:1.1034769836383673\n",
      "train loss:0.9680705046641819\n",
      "train loss:0.8558594805933849\n",
      "train loss:0.9300658679044076\n",
      "train loss:0.9444562982308257\n",
      "train loss:0.8117780714207893\n",
      "train loss:0.863937964611243\n",
      "train loss:1.1980891807167156\n",
      "train loss:0.9797793622059945\n",
      "train loss:0.9128707119181808\n",
      "train loss:0.887094197528413\n",
      "train loss:0.9955369872259674\n",
      "train loss:0.993574718396563\n",
      "train loss:0.9288524920754859\n",
      "train loss:0.937919398264408\n",
      "train loss:1.066986270931178\n",
      "train loss:0.9490391190062027\n",
      "train loss:0.8918193892708847\n",
      "train loss:1.054816093600016\n",
      "train loss:0.9932263734861491\n",
      "train loss:0.8731723134396142\n",
      "train loss:0.8693769319034186\n",
      "train loss:0.7773911958487634\n",
      "train loss:0.9639278760781267\n",
      "train loss:0.8416309222390366\n",
      "train loss:0.868297045360497\n",
      "train loss:0.8542633642824852\n",
      "train loss:0.8932177307840079\n",
      "train loss:0.9170286204811507\n",
      "train loss:0.8247153626102863\n",
      "train loss:1.1840253198026607\n",
      "train loss:1.0238219645099635\n",
      "train loss:0.8960198912624309\n",
      "train loss:0.989802011640238\n",
      "train loss:0.9278621772938451\n",
      "train loss:0.894375171603746\n",
      "train loss:0.922075371534342\n",
      "train loss:0.7275995513697194\n",
      "train loss:0.9346753763503902\n",
      "train loss:1.052582201962502\n",
      "train loss:0.8969524171252004\n",
      "train loss:0.7821429514990206\n",
      "train loss:0.9122799378293104\n",
      "train loss:0.9620308425551375\n",
      "train loss:0.8273056892297014\n",
      "train loss:0.8942775895977827\n",
      "train loss:0.8598691283226223\n",
      "train loss:0.8916521189204403\n",
      "train loss:1.051897092382926\n",
      "train loss:0.9503106778282557\n",
      "train loss:1.0050640727261593\n",
      "train loss:1.0215268532245196\n",
      "train loss:0.7796232718093268\n",
      "train loss:0.6795519635539803\n",
      "train loss:0.9359684616129678\n",
      "train loss:0.9157923660168489\n",
      "train loss:0.8729422118802797\n",
      "train loss:0.9573054342728312\n",
      "train loss:1.0105771186349448\n",
      "train loss:0.8883526971821923\n",
      "train loss:0.979858910957787\n",
      "train loss:1.0625667650542334\n",
      "train loss:0.8953774899432427\n",
      "train loss:0.8603461627554669\n",
      "train loss:1.1356912658406848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.0121014408231523\n",
      "train loss:0.9439354863474866\n",
      "train loss:0.9777150166941102\n",
      "train loss:0.9823782392685441\n",
      "train loss:0.8962684369822125\n",
      "train loss:0.8782703582474284\n",
      "train loss:0.8301457170075344\n",
      "train loss:1.0083586281221617\n",
      "train loss:1.0032446479049741\n",
      "train loss:0.8186228174572804\n",
      "train loss:0.9280468757625759\n",
      "train loss:0.9665482535046263\n",
      "train loss:0.8091281126644526\n",
      "train loss:1.0693129453126056\n",
      "train loss:0.9641190599191114\n",
      "train loss:1.0687806068982741\n",
      "train loss:0.9160173379924015\n",
      "train loss:0.9493576241444083\n",
      "train loss:0.9676506368585639\n",
      "train loss:0.8991339364763761\n",
      "train loss:0.8961224143760752\n",
      "train loss:0.7860635750379973\n",
      "train loss:0.9687340757788447\n",
      "train loss:1.0268771174532774\n",
      "train loss:0.855544222266918\n",
      "train loss:0.8141447468020258\n",
      "train loss:0.810253338837024\n",
      "train loss:1.011452930557387\n",
      "train loss:0.8128026196040546\n",
      "train loss:1.0006550411966704\n",
      "train loss:0.7587505847184801\n",
      "train loss:1.0834982625327156\n",
      "train loss:0.8187755857071828\n",
      "train loss:0.9192471293121633\n",
      "train loss:1.0089920611273626\n",
      "train loss:0.8833510797554222\n",
      "train loss:0.8998782484106604\n",
      "train loss:1.0330227204155646\n",
      "train loss:0.9225839756543788\n",
      "train loss:0.9549786314819448\n",
      "train loss:0.9650081745060903\n",
      "train loss:0.9518767801379585\n",
      "train loss:1.13557072214782\n",
      "train loss:1.134338839411468\n",
      "train loss:0.8430770318808473\n",
      "train loss:1.0134319113315433\n",
      "train loss:1.0460183105500942\n",
      "train loss:1.044558228899311\n",
      "train loss:0.9519369002154303\n",
      "train loss:0.9586220114545957\n",
      "train loss:1.0121351686347977\n",
      "train loss:0.8062580656414501\n",
      "train loss:0.9575881463639374\n",
      "train loss:0.8607696827489042\n",
      "train loss:0.9436165717990411\n",
      "train loss:0.9943249125547766\n",
      "train loss:1.0400880429461519\n",
      "train loss:0.8452638325800628\n",
      "train loss:0.9364085978217374\n",
      "train loss:1.0028809855925622\n",
      "train loss:0.946326569205186\n",
      "train loss:1.0893547083893254\n",
      "train loss:0.9918302033490687\n",
      "train loss:0.8936228634351435\n",
      "train loss:0.8773730892032938\n",
      "train loss:0.8584636847043814\n",
      "train loss:0.9700614861569893\n",
      "train loss:0.9933306361340027\n",
      "train loss:0.9851102142326716\n",
      "train loss:0.9389673787768209\n",
      "train loss:0.9734564712213265\n",
      "train loss:0.8469131851061097\n",
      "train loss:0.9693762390649162\n",
      "train loss:0.9393551171929682\n",
      "train loss:0.7539974339608589\n",
      "train loss:1.023686981887974\n",
      "train loss:0.9746654321428448\n",
      "train loss:1.0553414391386053\n",
      "train loss:0.9531578853086364\n",
      "train loss:1.0114709173108025\n",
      "train loss:0.911478503534401\n",
      "train loss:0.8761576096086121\n",
      "train loss:1.0499879190587103\n",
      "train loss:0.8947971134426567\n",
      "train loss:1.0051440002618837\n",
      "train loss:1.0067550129589589\n",
      "train loss:0.9077859791079897\n",
      "train loss:0.8705643559355921\n",
      "train loss:0.9005662982818013\n",
      "train loss:0.9530449994829233\n",
      "train loss:0.9606164481461792\n",
      "train loss:0.9551271025696394\n",
      "train loss:0.8215026932994666\n",
      "train loss:0.8420986326177874\n",
      "train loss:1.0122333333509028\n",
      "train loss:0.8782656695477031\n",
      "train loss:0.9745901386243869\n",
      "train loss:0.9766615196385691\n",
      "train loss:0.922404659397888\n",
      "train loss:0.9267113200817109\n",
      "train loss:1.0682568192256268\n",
      "train loss:0.8211201697667329\n",
      "train loss:1.0933744957987945\n",
      "train loss:1.0352782348520944\n",
      "train loss:0.9444329817870687\n",
      "train loss:1.0025117674269979\n",
      "train loss:1.0315421258496458\n",
      "train loss:1.0224922012149984\n",
      "train loss:1.0267277595116566\n",
      "train loss:0.9840485349062321\n",
      "train loss:1.0975972408644672\n",
      "train loss:1.0108081294237845\n",
      "train loss:1.1299456014249614\n",
      "train loss:1.221135447981635\n",
      "train loss:0.9333636313895585\n",
      "train loss:1.036515390831752\n",
      "train loss:0.8056834975991164\n",
      "train loss:0.8352642974106865\n",
      "train loss:0.9193314747588265\n",
      "train loss:0.8547371826274046\n",
      "train loss:1.0715496023199043\n",
      "train loss:0.8848553952252131\n",
      "train loss:0.9171666805735061\n",
      "train loss:1.0009532001835943\n",
      "train loss:0.93564847875645\n",
      "train loss:1.0162411404132283\n",
      "train loss:0.7719286713729088\n",
      "train loss:0.9631077443571519\n",
      "train loss:1.1537135864634551\n",
      "train loss:1.0512909553487093\n",
      "train loss:1.0744415428311131\n",
      "train loss:1.0280135899586405\n",
      "train loss:0.8775974400811419\n",
      "train loss:0.9028625590294322\n",
      "train loss:0.8481037256475384\n",
      "train loss:0.9636102158726679\n",
      "train loss:1.0264128516261741\n",
      "train loss:0.9738002878709158\n",
      "train loss:1.0333077557987176\n",
      "train loss:1.0292428702516105\n",
      "train loss:0.8751110614642802\n",
      "train loss:0.9759078868234212\n",
      "train loss:0.8563875984102127\n",
      "train loss:1.2649808659453747\n",
      "train loss:1.0642582310572064\n",
      "train loss:0.8075474394625924\n",
      "train loss:0.9331284056887985\n",
      "train loss:1.0481429275103953\n",
      "train loss:0.8214129915737342\n",
      "train loss:1.0221683959959444\n",
      "train loss:0.7900004615912618\n",
      "train loss:0.7945206704711802\n",
      "train loss:0.8894698201852138\n",
      "train loss:0.8302165121154398\n",
      "train loss:0.9419895849400717\n",
      "train loss:0.8357972150963464\n",
      "train loss:1.0115262647463514\n",
      "train loss:0.9016947879491639\n",
      "train loss:0.975490178038541\n",
      "train loss:0.8130621467319243\n",
      "train loss:1.0595621082581543\n",
      "train loss:1.0126998437568568\n",
      "train loss:0.9890122557026676\n",
      "train loss:0.9123081221070077\n",
      "train loss:0.9286388054468862\n",
      "train loss:0.8347710547190207\n",
      "train loss:1.1026673318063622\n",
      "train loss:0.9420989039480798\n",
      "train loss:0.8383103579763929\n",
      "train loss:0.9425489399035862\n",
      "train loss:0.9846358018971205\n",
      "train loss:0.8234304921834318\n",
      "train loss:0.8254911079987849\n",
      "train loss:1.1988779045690365\n",
      "train loss:1.0726552332776533\n",
      "train loss:0.998504563717279\n",
      "train loss:0.9849401978823831\n",
      "train loss:0.8714135480664267\n",
      "train loss:0.9698955393059375\n",
      "train loss:0.9572627655847625\n",
      "train loss:0.8310054175551557\n",
      "train loss:0.9083263075963928\n",
      "train loss:0.9563558621146254\n",
      "train loss:0.8843484389561662\n",
      "train loss:0.9409132355570479\n",
      "train loss:0.9592268356447095\n",
      "train loss:0.9210774730636438\n",
      "train loss:1.067738497538889\n",
      "train loss:0.9749636874500454\n",
      "train loss:0.9278800579511837\n",
      "train loss:0.751355529392454\n",
      "train loss:0.9221793665863258\n",
      "train loss:1.06292983306469\n",
      "train loss:0.9727775196495775\n",
      "train loss:0.9698461322100671\n",
      "train loss:0.9253237113336558\n",
      "train loss:1.0106402739216336\n",
      "train loss:0.9834358970554298\n",
      "train loss:0.9123519700816446\n",
      "train loss:0.8739503500300557\n",
      "train loss:0.9406872243583639\n",
      "train loss:0.9549491782687238\n",
      "train loss:0.9570287365999759\n",
      "train loss:0.9907967956641015\n",
      "train loss:0.9629727949126706\n",
      "train loss:0.87211457716952\n",
      "train loss:1.0195802505424694\n",
      "train loss:0.9236033681981045\n",
      "train loss:0.9393880437090832\n",
      "train loss:0.924432031259801\n",
      "train loss:0.9293490612891869\n",
      "train loss:0.8284801332607924\n",
      "train loss:0.9252210422040654\n",
      "train loss:0.9765763328138817\n",
      "train loss:0.9881342925968144\n",
      "train loss:1.0511753642284727\n",
      "train loss:1.0504098888228215\n",
      "train loss:0.9777132445622188\n",
      "train loss:1.0363178573880027\n",
      "train loss:0.8871108171509112\n",
      "train loss:0.9649822997301278\n",
      "train loss:1.0271232134138122\n",
      "train loss:0.8157610096948944\n",
      "train loss:1.0356475132345755\n",
      "train loss:1.0979604775280785\n",
      "train loss:0.9201813653836315\n",
      "train loss:0.8495909598773145\n",
      "train loss:0.9267528528163913\n",
      "train loss:0.9936018837504847\n",
      "train loss:0.9710278577458662\n",
      "train loss:1.021367836867805\n",
      "train loss:1.1654527372746513\n",
      "train loss:0.797267992064601\n",
      "train loss:1.0620981881610547\n",
      "train loss:0.791124752607823\n",
      "train loss:1.0087075756471093\n",
      "train loss:1.1077530772905302\n",
      "train loss:1.0272492188485616\n",
      "train loss:0.9380493896743373\n",
      "train loss:0.9351585550849475\n",
      "train loss:0.9545662720253012\n",
      "train loss:1.000514861866869\n",
      "train loss:0.8823002983455883\n",
      "train loss:0.8655874788107115\n",
      "train loss:0.8924051473143835\n",
      "train loss:0.8912742185269904\n",
      "train loss:0.9159849616709405\n",
      "train loss:0.8363412340839741\n",
      "train loss:0.8847892113988814\n",
      "train loss:0.8310064717551987\n",
      "train loss:0.880427935027339\n",
      "train loss:1.004018786696617\n",
      "train loss:0.94380245630385\n",
      "train loss:0.9722130124789023\n",
      "train loss:1.094092043962149\n",
      "train loss:0.9352916943193195\n",
      "train loss:0.8883308702854913\n",
      "train loss:0.8235675668966219\n",
      "train loss:0.92167270726403\n",
      "train loss:0.974274257100816\n",
      "train loss:1.1049387317129749\n",
      "train loss:0.9294022907821902\n",
      "train loss:1.017001272961905\n",
      "train loss:0.9251068727684334\n",
      "train loss:0.901211813026233\n",
      "train loss:0.8738562496758929\n",
      "train loss:0.8788827834020705\n",
      "train loss:0.7826162540257997\n",
      "train loss:0.8013822635033598\n",
      "train loss:0.8901471065525487\n",
      "train loss:0.8647397054719893\n",
      "train loss:0.8945964821473327\n",
      "train loss:0.937294256959873\n",
      "train loss:1.164007277207636\n",
      "train loss:0.9062309622764652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8623719123276895\n",
      "train loss:1.0850170805732384\n",
      "train loss:1.0511987076937077\n",
      "train loss:0.8900531457980567\n",
      "train loss:0.7753133297478132\n",
      "train loss:1.1495233391323132\n",
      "train loss:1.0429079565716528\n",
      "train loss:0.8408948462404515\n",
      "train loss:0.7556617137704498\n",
      "train loss:0.8853298969140272\n",
      "train loss:0.9678288871691697\n",
      "train loss:1.0082450306465673\n",
      "train loss:1.2225061603797267\n",
      "train loss:0.9633269649054031\n",
      "train loss:0.8490011321202072\n",
      "train loss:1.0978359083555305\n",
      "train loss:0.9826667491214575\n",
      "train loss:1.001283272409632\n",
      "train loss:1.1110349984874581\n",
      "train loss:1.0439307671988796\n",
      "train loss:1.0686616615985516\n",
      "train loss:0.8382971661306746\n",
      "train loss:0.8720383156909066\n",
      "train loss:0.9345383291018932\n",
      "train loss:0.8598027266530888\n",
      "train loss:1.038046543772423\n",
      "train loss:1.1609481228246772\n",
      "train loss:0.9679079546444028\n",
      "train loss:1.0536409304811658\n",
      "train loss:0.8900176309204604\n",
      "train loss:0.9956804810234843\n",
      "train loss:0.9279788425525725\n",
      "train loss:0.8013133869300562\n",
      "train loss:0.8569521905047853\n",
      "train loss:0.9287932800022657\n",
      "train loss:0.9204345694562156\n",
      "train loss:0.8961223158805376\n",
      "train loss:0.8797501641665205\n",
      "train loss:0.7892770078012173\n",
      "train loss:0.8821962765762288\n",
      "train loss:0.9155282886844235\n",
      "train loss:1.0082415426493616\n",
      "train loss:0.9011363680010572\n",
      "train loss:0.8905455030888525\n",
      "train loss:0.9022716442015003\n",
      "train loss:0.8739401105016147\n",
      "train loss:1.0413133063842301\n",
      "train loss:0.9411742023494104\n",
      "train loss:0.9584579889866021\n",
      "train loss:0.8453692417804879\n",
      "train loss:1.0959510150444507\n",
      "train loss:0.7797169530748964\n",
      "train loss:1.1630512195531673\n",
      "train loss:0.9717671958124312\n",
      "train loss:0.969463886475151\n",
      "train loss:1.0694821899306104\n",
      "train loss:0.7970243101981002\n",
      "train loss:0.8778693040093377\n",
      "train loss:1.0507669549866632\n",
      "train loss:0.965825006492501\n",
      "train loss:1.0705478559561552\n",
      "train loss:0.963444664891562\n",
      "train loss:1.1129987571890763\n",
      "train loss:0.7584939619903376\n",
      "train loss:0.7280343080735335\n",
      "train loss:0.9455231921382379\n",
      "train loss:0.7880551979365324\n",
      "train loss:1.1394867515945506\n",
      "train loss:0.9731573885970771\n",
      "train loss:0.9673996086035711\n",
      "train loss:1.024573063242707\n",
      "train loss:1.0770020852886482\n",
      "train loss:1.0469651816525982\n",
      "train loss:0.9190864998343323\n",
      "train loss:0.7763284614022811\n",
      "train loss:0.8596578590467179\n",
      "train loss:0.8139441983641774\n",
      "train loss:1.003691927764432\n",
      "train loss:0.9381307087593087\n",
      "train loss:1.006022614404957\n",
      "train loss:1.011617046609506\n",
      "train loss:0.9354818471553746\n",
      "train loss:1.0815665412442879\n",
      "train loss:0.9479069069910593\n",
      "train loss:1.045412853044201\n",
      "train loss:0.7949628194249019\n",
      "train loss:0.9695837337424197\n",
      "train loss:0.8915599370830023\n",
      "train loss:1.035451516842529\n",
      "train loss:0.9374356368732853\n",
      "train loss:0.8237354942340386\n",
      "train loss:0.9708146417706445\n",
      "train loss:0.9045185401436179\n",
      "train loss:0.9740653944561162\n",
      "train loss:0.9700663901972636\n",
      "train loss:0.9127452201523322\n",
      "train loss:0.8979977211363639\n",
      "train loss:0.9288454971240431\n",
      "train loss:1.0087445604412686\n",
      "train loss:1.0134775185929197\n",
      "train loss:0.8969844544874215\n",
      "train loss:0.9106282941336308\n",
      "train loss:0.8206983890788258\n",
      "train loss:0.9163659386722313\n",
      "train loss:0.8597469917804003\n",
      "train loss:0.9462197918375002\n",
      "train loss:1.0456566187433558\n",
      "train loss:0.9168545695926135\n",
      "train loss:0.8768956835072876\n",
      "train loss:0.9263608916949383\n",
      "train loss:1.06334335086975\n",
      "train loss:0.7988377593555943\n",
      "train loss:0.9023047963067929\n",
      "train loss:0.8636545054530612\n",
      "train loss:0.9999434588943413\n",
      "train loss:1.0202833097014987\n",
      "train loss:0.9057507486603791\n",
      "train loss:0.9253184960178855\n",
      "train loss:0.8719094206519267\n",
      "train loss:1.1157665397728211\n",
      "train loss:0.7709751856227629\n",
      "train loss:0.8347075736436845\n",
      "train loss:0.9951999340734474\n",
      "train loss:0.9106217845932284\n",
      "train loss:0.8984199040794953\n",
      "train loss:0.9216131796539468\n",
      "train loss:1.1823922077554463\n",
      "train loss:0.9675573506148468\n",
      "train loss:0.9174904520041026\n",
      "train loss:0.9647156910891586\n",
      "train loss:0.9695031006023229\n",
      "train loss:0.8834365103058078\n",
      "train loss:1.019840435370184\n",
      "train loss:0.9526722775164329\n",
      "train loss:0.941856367807063\n",
      "train loss:0.8662564347794851\n",
      "train loss:0.9039025318515458\n",
      "train loss:0.99548092400732\n",
      "train loss:1.0440008904543638\n",
      "train loss:0.9347109266792689\n",
      "train loss:0.9937355873610791\n",
      "train loss:0.9384049484759196\n",
      "train loss:0.9837981707082345\n",
      "train loss:0.8812899097983491\n",
      "train loss:1.0607246931717513\n",
      "train loss:0.8137256184901454\n",
      "train loss:1.0126574297107895\n",
      "train loss:1.14566068071345\n",
      "train loss:0.9646891455951768\n",
      "train loss:0.9871367569694144\n",
      "train loss:0.8965030965961212\n",
      "train loss:1.097062023373032\n",
      "train loss:1.056706750324404\n",
      "train loss:0.980445056581274\n",
      "train loss:1.0234844835253838\n",
      "train loss:1.0557152388110904\n",
      "train loss:0.9733821114681582\n",
      "train loss:0.7715051276303047\n",
      "train loss:0.8769599694263418\n",
      "train loss:0.8528803875247085\n",
      "train loss:0.9456664832306113\n",
      "train loss:0.8526215220817881\n",
      "train loss:1.0382846961833698\n",
      "train loss:0.9990786659760471\n",
      "train loss:0.8250402191634703\n",
      "train loss:0.9161063711946978\n",
      "train loss:0.7463656133924366\n",
      "train loss:0.9590775003339848\n",
      "train loss:0.9298028387429423\n",
      "train loss:0.7551770928646531\n",
      "train loss:0.797448461899685\n",
      "train loss:0.9542879878694286\n",
      "train loss:0.87863352472357\n",
      "train loss:0.9209238048445687\n",
      "train loss:0.8110298735866666\n",
      "train loss:0.9675851027835969\n",
      "train loss:1.0682817866962369\n",
      "train loss:1.0009850765334514\n",
      "train loss:0.8501893316151632\n",
      "train loss:1.0705514122038435\n",
      "train loss:0.9267673841153544\n",
      "train loss:0.9195047676234673\n",
      "train loss:1.1047213723080522\n",
      "train loss:0.9588177348236547\n",
      "train loss:0.8991963066443178\n",
      "train loss:0.9368270239622754\n",
      "train loss:0.9156346593340463\n",
      "train loss:1.1349297911360325\n",
      "train loss:1.0568301644888392\n",
      "train loss:0.8043967983439768\n",
      "train loss:0.854059037115006\n",
      "train loss:0.8514761830247182\n",
      "train loss:0.9408921252796084\n",
      "train loss:0.8568368901325479\n",
      "train loss:0.7445063952432105\n",
      "train loss:0.8889142364047403\n",
      "train loss:1.0518789058388327\n",
      "train loss:1.0730299068380753\n",
      "train loss:0.9975424647148107\n",
      "train loss:0.9517448123891902\n",
      "train loss:0.9419251270635774\n",
      "train loss:0.9988568304790985\n",
      "train loss:0.9977178783157538\n",
      "train loss:0.8397214933178244\n",
      "train loss:0.880634273309251\n",
      "train loss:1.0243951587880522\n",
      "train loss:0.9452514129496825\n",
      "train loss:1.073865519966575\n",
      "train loss:0.9353844655560556\n",
      "train loss:0.9768323029994375\n",
      "train loss:0.9045652634346786\n",
      "train loss:0.9112360435292688\n",
      "train loss:0.8102826871806093\n",
      "train loss:1.123167592347035\n",
      "train loss:0.9419373610808082\n",
      "train loss:0.8303059983482683\n",
      "train loss:0.9427872271466791\n",
      "train loss:0.9642927743825358\n",
      "train loss:0.9865786864461625\n",
      "train loss:0.9312277102989727\n",
      "train loss:1.0016132842058427\n",
      "train loss:0.8168470534695328\n",
      "train loss:0.8758046256951257\n",
      "train loss:1.0460644034169833\n",
      "train loss:1.0906810502591564\n",
      "train loss:0.9377768472504019\n",
      "train loss:0.9644807273187841\n",
      "train loss:1.005352707244284\n",
      "train loss:1.199246701556872\n",
      "train loss:1.0096474089678482\n",
      "train loss:0.9895436465224262\n",
      "train loss:0.8357476487551849\n",
      "train loss:1.025559529023901\n",
      "train loss:0.9251248971812771\n",
      "train loss:1.1336212232851763\n",
      "train loss:0.9619383356978441\n",
      "train loss:1.0263909570720795\n",
      "train loss:0.9620879097891988\n",
      "train loss:0.7287025958325208\n",
      "train loss:0.7808788721542816\n",
      "train loss:0.8511368943582494\n",
      "train loss:0.90910124360071\n",
      "train loss:0.9312348581235323\n",
      "train loss:0.9973063814905525\n",
      "train loss:0.9639531483215578\n",
      "train loss:0.8762407287248692\n",
      "train loss:1.0041310005407125\n",
      "train loss:0.9239631534644249\n",
      "train loss:1.1745589177164666\n",
      "train loss:1.0084294614870686\n",
      "train loss:0.9958694973730188\n",
      "train loss:0.8514097129028139\n",
      "train loss:0.9900791668436751\n",
      "train loss:0.9528139865475782\n",
      "train loss:0.9478605290234584\n",
      "train loss:0.9320632851313428\n",
      "=== epoch:6, train acc:0.993, test acc:0.989 ===\n",
      "train loss:1.053305667218159\n",
      "train loss:0.920343802209807\n",
      "train loss:0.8806693186638586\n",
      "train loss:1.1184631494026644\n",
      "train loss:0.9239177255492745\n",
      "train loss:0.8744226034672811\n",
      "train loss:0.9768112813913564\n",
      "train loss:0.9229068385610417\n",
      "train loss:0.880909110945245\n",
      "train loss:0.9393191588494811\n",
      "train loss:1.0100132521973588\n",
      "train loss:0.9511287240610016\n",
      "train loss:0.8200778075273907\n",
      "train loss:0.8493630372129725\n",
      "train loss:0.9865085443999151\n",
      "train loss:0.984006861998989\n",
      "train loss:0.9773282131366391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7349475230386276\n",
      "train loss:1.0544709360558355\n",
      "train loss:0.9660021876742665\n",
      "train loss:0.8375699006994048\n",
      "train loss:1.0375941959955108\n",
      "train loss:0.9905377102671018\n",
      "train loss:1.2920860374960277\n",
      "train loss:1.036425535089765\n",
      "train loss:1.0527423376499747\n",
      "train loss:1.0159527625457847\n",
      "train loss:0.817029254205944\n",
      "train loss:1.0827702620294501\n",
      "train loss:0.8745740322433414\n",
      "train loss:0.8755876000138205\n",
      "train loss:1.1194860114974643\n",
      "train loss:0.8920406275823622\n",
      "train loss:1.0109890043345973\n",
      "train loss:1.0834079725044894\n",
      "train loss:0.9697963023068793\n",
      "train loss:0.984605121069427\n",
      "train loss:0.7759551175956919\n",
      "train loss:0.9892723101351055\n",
      "train loss:0.8602533524219115\n",
      "train loss:0.9833781056034205\n",
      "train loss:0.8996339728428514\n",
      "train loss:0.8821688744280766\n",
      "train loss:0.7473844923609981\n",
      "train loss:1.0232033067410162\n",
      "train loss:0.8771922490619842\n",
      "train loss:1.054136516084113\n",
      "train loss:0.9790439154009906\n",
      "train loss:0.8936379046561289\n",
      "train loss:0.9116542553091824\n",
      "train loss:0.9935358688107901\n",
      "train loss:0.8164870980523389\n",
      "train loss:0.9444548611264004\n",
      "train loss:1.0316047133877273\n",
      "train loss:1.0648147281715945\n",
      "train loss:0.941801157617182\n",
      "train loss:0.8218156605727438\n",
      "train loss:0.9360710503749483\n",
      "train loss:0.8720907672026016\n",
      "train loss:0.9132190047448385\n",
      "train loss:0.787674829745361\n",
      "train loss:0.8427080040594934\n",
      "train loss:1.0285534018070173\n",
      "train loss:1.0947506306114287\n",
      "train loss:0.935174179513006\n",
      "train loss:1.0971916497988676\n",
      "train loss:0.8361942088672002\n",
      "train loss:0.9404935076906442\n",
      "train loss:0.8926917890869145\n",
      "train loss:0.9307072002905492\n",
      "train loss:0.7923963738495832\n",
      "train loss:1.0253442317003012\n",
      "train loss:0.9593592803145669\n",
      "train loss:0.9493867047511378\n",
      "train loss:0.8537072954645799\n",
      "train loss:0.8648827908017289\n",
      "train loss:0.8679408489577076\n",
      "train loss:0.9686323130970085\n",
      "train loss:0.9029974694028694\n",
      "train loss:0.9221703273064515\n",
      "train loss:0.8316249091528773\n",
      "train loss:0.9133060190994461\n",
      "train loss:0.9386996395108947\n",
      "train loss:1.0948673340164812\n",
      "train loss:0.969330383258381\n",
      "train loss:0.8417925122195369\n",
      "train loss:0.9857800416539125\n",
      "train loss:0.8488778903724932\n",
      "train loss:0.8670653715513487\n",
      "train loss:0.7694582810821257\n",
      "train loss:0.9857215130639081\n",
      "train loss:0.9284946538173109\n",
      "train loss:0.9656517812664748\n",
      "train loss:0.9728641310773726\n",
      "train loss:0.9793321412156699\n",
      "train loss:0.9772263341740929\n",
      "train loss:1.0505182902854004\n",
      "train loss:0.940869806746691\n",
      "train loss:0.9185607691877219\n",
      "train loss:0.9123166229765777\n",
      "train loss:0.8075894184704672\n",
      "train loss:0.9256133161629632\n",
      "train loss:0.9724793730020538\n",
      "train loss:0.8738189816667408\n",
      "train loss:0.9891370635797481\n",
      "train loss:0.7835301172192866\n",
      "train loss:1.1457082666267768\n",
      "train loss:1.0773092796190904\n",
      "train loss:0.9784852157930507\n",
      "train loss:0.7667159018069234\n",
      "train loss:1.0765283784910216\n",
      "train loss:0.9592071497194175\n",
      "train loss:0.9693020581761713\n",
      "train loss:0.9357492313325296\n",
      "train loss:0.9616865149517655\n",
      "train loss:1.0595205822641043\n",
      "train loss:0.8273017119497346\n",
      "train loss:0.8766555897658415\n",
      "train loss:1.224351912759642\n",
      "train loss:0.8738425874044534\n",
      "train loss:0.8588021344307967\n",
      "train loss:0.9189559943314713\n",
      "train loss:1.0523997215552945\n",
      "train loss:1.0031352682996175\n",
      "train loss:0.8226895788134797\n",
      "train loss:1.1682062243095102\n",
      "train loss:1.138473542542593\n",
      "train loss:0.7795846848591882\n",
      "train loss:0.8541956051521337\n",
      "train loss:0.8276874546198286\n",
      "train loss:1.047099135135664\n",
      "train loss:0.8422978829966814\n",
      "train loss:1.1002715841785733\n",
      "train loss:0.8428839226331667\n",
      "train loss:0.9882620963860822\n",
      "train loss:0.7993378775948632\n",
      "train loss:0.7422565938676199\n",
      "train loss:0.6948360690699127\n",
      "train loss:1.066492577054904\n",
      "train loss:0.9782184307803246\n",
      "train loss:0.8575972054438081\n",
      "train loss:0.9435099805658196\n",
      "train loss:0.9882419927170727\n",
      "train loss:0.8851425617505406\n",
      "train loss:1.0878142554784858\n",
      "train loss:0.9782505944314426\n",
      "train loss:0.9564355155391813\n",
      "train loss:0.8845070665149118\n",
      "train loss:0.87863415286655\n",
      "train loss:1.0236471163498606\n",
      "train loss:0.9912359107940776\n",
      "train loss:0.9542498318638009\n",
      "train loss:1.189267569829874\n",
      "train loss:0.8890807792017053\n",
      "train loss:0.9462720760388562\n",
      "train loss:0.97006738749858\n",
      "train loss:1.0003300653407643\n",
      "train loss:0.862847920081977\n",
      "train loss:0.947634465610826\n",
      "train loss:0.9375800951277943\n",
      "train loss:1.1439801927648552\n",
      "train loss:0.926071263733007\n",
      "train loss:0.918153827017479\n",
      "train loss:1.0035234555703292\n",
      "train loss:1.0719256390000194\n",
      "train loss:0.8563299907865614\n",
      "train loss:0.8374901177328359\n",
      "train loss:0.8378242872898325\n",
      "train loss:1.0191704104551667\n",
      "train loss:0.9778191816079925\n",
      "train loss:1.0274079328230905\n",
      "train loss:0.81157442389954\n",
      "train loss:0.8555910730594166\n",
      "train loss:0.9562949116520513\n",
      "train loss:0.869235350421626\n",
      "train loss:0.9330604384627518\n",
      "train loss:0.8943594696734278\n",
      "train loss:0.9173084193426984\n",
      "train loss:0.899447786207798\n",
      "train loss:1.0360854977911405\n",
      "train loss:0.9928185750579505\n",
      "train loss:0.8792069181204887\n",
      "train loss:0.8941083028783168\n",
      "train loss:0.9795056531231507\n",
      "train loss:0.7882946458961758\n",
      "train loss:0.9958857939748005\n",
      "train loss:1.0238078644933715\n",
      "train loss:1.0261152439944872\n",
      "train loss:0.9899413519459948\n",
      "train loss:1.0575333391887132\n",
      "train loss:0.9586015977685336\n",
      "train loss:0.7747495890675262\n",
      "train loss:0.8953992164686742\n",
      "train loss:0.9467296446494465\n",
      "train loss:1.0551715610131662\n",
      "train loss:1.0101578850376274\n",
      "train loss:0.9348761466792981\n",
      "train loss:0.880924966101983\n",
      "train loss:0.9743744236232688\n",
      "train loss:0.8750700943207521\n",
      "train loss:0.9240242805993235\n",
      "train loss:0.9840356580495805\n",
      "train loss:1.0439937683934177\n",
      "train loss:0.9248953784823223\n",
      "train loss:0.9956185610394013\n",
      "train loss:0.8691143019616238\n",
      "train loss:0.8706247361409232\n",
      "train loss:0.9850334231886372\n",
      "train loss:0.9114421115853679\n",
      "train loss:0.9205017185601098\n",
      "train loss:1.0826063439325653\n",
      "train loss:0.9260882090455839\n",
      "train loss:1.0292134539164484\n",
      "train loss:0.9590628619250039\n",
      "train loss:0.9311617371048743\n",
      "train loss:0.9061174784785133\n",
      "train loss:0.8635662035911764\n",
      "train loss:0.980817070771848\n",
      "train loss:0.9251128946962244\n",
      "train loss:1.0115690013144742\n",
      "train loss:0.6959187283524736\n",
      "train loss:1.082679505090655\n",
      "train loss:0.9405681378397077\n",
      "train loss:1.0259068770620412\n",
      "train loss:0.8099548825877941\n",
      "train loss:0.929978809570528\n",
      "train loss:0.9192868982196387\n",
      "train loss:0.9843864642615071\n",
      "train loss:0.8173495151523911\n",
      "train loss:0.85441161249532\n",
      "train loss:1.018905114312981\n",
      "train loss:0.9643831190301968\n",
      "train loss:0.9627197581904603\n",
      "train loss:1.002754545071059\n",
      "train loss:0.8743272299449956\n",
      "train loss:0.940914531533865\n",
      "train loss:1.0008765483156552\n",
      "train loss:0.9998603176461139\n",
      "train loss:0.9680840060348851\n",
      "train loss:0.8053878616320076\n",
      "train loss:0.9868260833849617\n",
      "train loss:0.8295670695584882\n",
      "train loss:0.9084271541836175\n",
      "train loss:0.771825289945849\n",
      "train loss:0.9494980064978314\n",
      "train loss:0.817797138137158\n",
      "train loss:0.9511592657063421\n",
      "train loss:0.8693425427339797\n",
      "train loss:0.8873362858429686\n",
      "train loss:0.8720231979774665\n",
      "train loss:1.0086189935897039\n",
      "train loss:0.8545010139815119\n",
      "train loss:0.9470417065413258\n",
      "train loss:1.0518497115045613\n",
      "train loss:0.9802742657204112\n",
      "train loss:0.9386527481854892\n",
      "train loss:0.914837321322582\n",
      "train loss:1.0234068057299517\n",
      "train loss:0.8269484196545899\n",
      "train loss:0.9730780419138344\n",
      "train loss:0.910991046547148\n",
      "train loss:1.0337454485564204\n",
      "train loss:1.0289442381781206\n",
      "train loss:1.220817413185971\n",
      "train loss:1.1302094788252441\n",
      "train loss:0.848580854898458\n",
      "train loss:0.9024170436146981\n",
      "train loss:0.7626814903530831\n",
      "train loss:1.0065363546712423\n",
      "train loss:0.9481700735059122\n",
      "train loss:0.904894892555085\n",
      "train loss:0.8795332799281083\n",
      "train loss:0.9996371636806138\n",
      "train loss:0.9975108964580356\n",
      "train loss:0.7617076539959069\n",
      "train loss:0.8149115732080583\n",
      "train loss:0.9504715741816515\n",
      "train loss:0.7731133976097126\n",
      "train loss:1.0526753958148958\n",
      "train loss:1.0668785830005998\n",
      "train loss:0.926880982965201\n",
      "train loss:0.8475343977069366\n",
      "train loss:0.8949352876047172\n",
      "train loss:1.0177088813970863\n",
      "train loss:1.0211208489163577\n",
      "train loss:0.9798732953524482\n",
      "train loss:0.9162864937187866\n",
      "train loss:0.9461862185961115\n",
      "train loss:0.973169001551817\n",
      "train loss:0.9369490640397068\n",
      "train loss:0.8814590645289406\n",
      "train loss:1.0279286944874126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.981203756109896\n",
      "train loss:0.7626569938991038\n",
      "train loss:0.8462352229501253\n",
      "train loss:1.095245931587754\n",
      "train loss:0.7941128614912492\n",
      "train loss:1.0350985895431648\n",
      "train loss:0.8549417726335021\n",
      "train loss:0.8830985764715855\n",
      "train loss:0.9572388170402911\n",
      "train loss:1.0478551116158727\n",
      "train loss:0.8998538249729616\n",
      "train loss:0.86081680560453\n",
      "train loss:1.0465315829733384\n",
      "train loss:0.8029380392228473\n",
      "train loss:1.0125232469058236\n",
      "train loss:1.0206236955299568\n",
      "train loss:1.0016507563492114\n",
      "train loss:0.962418878112031\n",
      "train loss:0.9305707209473013\n",
      "train loss:0.8983166317404344\n",
      "train loss:0.7158563205137751\n",
      "train loss:1.0430613163172682\n",
      "train loss:0.9326622236720356\n",
      "train loss:0.9344017279950131\n",
      "train loss:1.1002421139883747\n",
      "train loss:0.8993509112630133\n",
      "train loss:1.1108818311264195\n",
      "train loss:0.9365318447787895\n",
      "train loss:1.0415218484353763\n",
      "train loss:0.936759494913221\n",
      "train loss:1.0416999658946822\n",
      "train loss:0.9792069999207632\n",
      "train loss:0.8657476018597737\n",
      "train loss:1.0740870878765454\n",
      "train loss:0.8623149567720819\n",
      "train loss:0.9773083923821575\n",
      "train loss:0.8572981278696616\n",
      "train loss:0.8969443853887473\n",
      "train loss:0.9457435988187224\n",
      "train loss:0.9054955016439024\n",
      "train loss:0.8434482628951119\n",
      "train loss:0.9215932740842301\n",
      "train loss:0.8912724340519841\n",
      "train loss:0.9599963507227016\n",
      "train loss:0.9149161935584254\n",
      "train loss:0.9200503048156535\n",
      "train loss:1.099354821971157\n",
      "train loss:0.7902808298324641\n",
      "train loss:0.844724709778857\n",
      "train loss:0.740882881905344\n",
      "train loss:0.9357546681679562\n",
      "train loss:0.7708745640088166\n",
      "train loss:0.9056504862046466\n",
      "train loss:0.86675901340041\n",
      "train loss:0.8636691163312749\n",
      "train loss:0.8315159171351777\n",
      "train loss:0.9337718627857277\n",
      "train loss:0.9454442742205508\n",
      "train loss:1.0217262359973056\n",
      "train loss:0.9709644788226105\n",
      "train loss:0.7561710063191802\n",
      "train loss:1.0386449808604314\n",
      "train loss:0.9097907671128291\n",
      "train loss:0.8770385122448654\n",
      "train loss:0.8688899094667248\n",
      "train loss:0.9759723233061817\n",
      "train loss:0.8174988531780527\n",
      "train loss:0.9183139021454368\n",
      "train loss:0.8682183308349289\n",
      "train loss:0.8323080551179217\n",
      "train loss:0.7550656273614623\n",
      "train loss:0.8931064106204027\n",
      "train loss:0.9201308548671596\n",
      "train loss:0.8393174542501969\n",
      "train loss:1.0270485540217833\n",
      "train loss:0.8295437758671877\n",
      "train loss:0.7914130103266267\n",
      "train loss:0.8636583678304713\n",
      "train loss:0.8320840821113729\n",
      "train loss:0.8056328748230283\n",
      "train loss:0.8274068650248825\n",
      "train loss:0.9337860759796329\n",
      "train loss:1.1490616063335828\n",
      "train loss:0.8560404326707984\n",
      "train loss:0.9533054904474595\n",
      "train loss:0.8542427134514403\n",
      "train loss:1.038519035379006\n",
      "train loss:0.9750891511766325\n",
      "train loss:0.9883603688492505\n",
      "train loss:0.855859207884277\n",
      "train loss:0.9884630879495663\n",
      "train loss:0.90365019702396\n",
      "train loss:0.7515861658066137\n",
      "train loss:0.9799905801776915\n",
      "train loss:0.8701815580744959\n",
      "train loss:1.0361207881904497\n",
      "train loss:0.9534258348774935\n",
      "train loss:1.10199278472881\n",
      "train loss:0.860094383396715\n",
      "train loss:0.8540462948487094\n",
      "train loss:0.8819171480805984\n",
      "train loss:0.834752020181337\n",
      "train loss:0.9675271635699301\n",
      "train loss:0.8270240598058725\n",
      "train loss:0.9666419535973567\n",
      "train loss:1.0882388693929523\n",
      "train loss:0.9176755569320076\n",
      "train loss:0.916074389231363\n",
      "train loss:1.002834877951646\n",
      "train loss:1.0222210129462255\n",
      "train loss:1.108561640074401\n",
      "train loss:0.8718507469533049\n",
      "train loss:0.7533749922622148\n",
      "train loss:0.8587831232184218\n",
      "train loss:0.9763839266497686\n",
      "train loss:0.9521438746996881\n",
      "train loss:1.146750581495972\n",
      "train loss:1.0071760448791702\n",
      "train loss:0.831102370503434\n",
      "train loss:0.8713188598951472\n",
      "train loss:1.0537231526123902\n",
      "train loss:0.9715110964269249\n",
      "train loss:0.7859831122391594\n",
      "train loss:1.0764040579181293\n",
      "train loss:1.0044572003084955\n",
      "train loss:0.7498156625163497\n",
      "train loss:0.8596221389457266\n",
      "train loss:0.8698475416620649\n",
      "train loss:1.0590880850919757\n",
      "train loss:0.9313185898666428\n",
      "train loss:0.904633658382064\n",
      "train loss:1.0213943012215116\n",
      "train loss:1.163193798395237\n",
      "train loss:0.9269417099873078\n",
      "train loss:0.9341991581767145\n",
      "train loss:1.074541618133635\n",
      "train loss:1.022340703043842\n",
      "train loss:0.9815752520005968\n",
      "train loss:0.9821080020898733\n",
      "train loss:1.0790638459062505\n",
      "train loss:0.9396132881503447\n",
      "train loss:0.9082596000174418\n",
      "train loss:0.8661812750575524\n",
      "train loss:0.9670120633154268\n",
      "train loss:1.08911016921662\n",
      "train loss:0.9314775422898035\n",
      "train loss:1.0308585562162422\n",
      "train loss:0.9400516770028026\n",
      "train loss:0.9506221062628302\n",
      "train loss:1.054376110973363\n",
      "train loss:1.0694000674866893\n",
      "train loss:0.8989602842454703\n",
      "train loss:0.9497109415307551\n",
      "train loss:0.9370026085414284\n",
      "train loss:1.087541822603812\n",
      "train loss:1.0068857176021004\n",
      "train loss:0.9170980236522965\n",
      "train loss:0.9032462796948344\n",
      "train loss:1.1031594765064652\n",
      "train loss:1.2097534572154176\n",
      "train loss:0.7533224167936524\n",
      "train loss:0.9769744642885356\n",
      "train loss:0.9022412637774992\n",
      "train loss:0.9280270550598633\n",
      "train loss:1.0141450211232348\n",
      "train loss:0.976632144699118\n",
      "train loss:0.9790999122522441\n",
      "train loss:0.9000920562223019\n",
      "train loss:0.8679406311103218\n",
      "train loss:0.8643263669995338\n",
      "train loss:0.9609954646653043\n",
      "train loss:1.0290051872263304\n",
      "train loss:0.771393468558821\n",
      "train loss:0.8524101282873774\n",
      "train loss:0.8837362217198077\n",
      "train loss:0.9722112560468023\n",
      "train loss:0.994295459539288\n",
      "train loss:0.8910020129153133\n",
      "train loss:0.9653001449887738\n",
      "train loss:1.010670053090528\n",
      "train loss:0.8989980028733616\n",
      "train loss:1.0990625965389107\n",
      "train loss:0.911173719552975\n",
      "train loss:0.900276322115123\n",
      "train loss:0.9582631112109027\n",
      "train loss:1.139136290112687\n",
      "train loss:1.0789310790649196\n",
      "train loss:0.7494139076209649\n",
      "train loss:0.9144684027127938\n",
      "train loss:1.0445723510677984\n",
      "train loss:0.7896646366417757\n",
      "train loss:0.8888861431932029\n",
      "train loss:0.8916837662184804\n",
      "train loss:0.7838495828918911\n",
      "train loss:0.8273525283118373\n",
      "train loss:0.9653357314347311\n",
      "train loss:0.9240013659926778\n",
      "train loss:0.9541905176404144\n",
      "train loss:0.8343914428086379\n",
      "train loss:0.9020534781539297\n",
      "train loss:0.9362523219428001\n",
      "train loss:0.9617435716611362\n",
      "train loss:0.8406508862116148\n",
      "train loss:1.1456304918317526\n",
      "train loss:1.1721483584294554\n",
      "train loss:0.7663046834771338\n",
      "train loss:0.7851088211932882\n",
      "train loss:1.0602510884582406\n",
      "train loss:0.9228132620198857\n",
      "train loss:0.9061124290093752\n",
      "train loss:0.9631256329556712\n",
      "train loss:0.9253170891619359\n",
      "train loss:0.8904851857396204\n",
      "train loss:0.8806492165280327\n",
      "train loss:0.9646201908473759\n",
      "train loss:0.9633849366994879\n",
      "train loss:0.9202281808008749\n",
      "train loss:0.9069737203792535\n",
      "train loss:0.8421963549750022\n",
      "train loss:0.8826079253226254\n",
      "train loss:0.9553466794586001\n",
      "train loss:1.044946408366528\n",
      "train loss:0.8086412056299594\n",
      "train loss:0.8303536073672975\n",
      "train loss:0.9901722663192865\n",
      "train loss:0.7979021769830628\n",
      "train loss:1.0034118509598122\n",
      "train loss:0.8603393786534089\n",
      "train loss:0.9633982862819552\n",
      "train loss:0.9788009925953546\n",
      "train loss:0.8172206904093074\n",
      "train loss:0.9342733793462498\n",
      "train loss:0.9279045952754054\n",
      "train loss:0.9678283019616225\n",
      "train loss:0.8532968823040241\n",
      "train loss:0.7731337329310968\n",
      "train loss:0.9664542274443866\n",
      "train loss:0.948475261676879\n",
      "train loss:1.1451294349237835\n",
      "train loss:0.9350165407197554\n",
      "train loss:0.9283656852917033\n",
      "train loss:0.8748478425978022\n",
      "train loss:0.908772600140616\n",
      "train loss:0.8377851739816167\n",
      "train loss:1.0303880976844741\n",
      "train loss:1.000391984968828\n",
      "train loss:0.8626088684936335\n",
      "train loss:0.964898523244543\n",
      "train loss:0.7814876918042796\n",
      "train loss:1.0451383203776201\n",
      "train loss:0.9830383631415487\n",
      "train loss:0.8554613172852684\n",
      "train loss:0.9870588261314915\n",
      "train loss:1.019101917414603\n",
      "train loss:0.8317528465207122\n",
      "train loss:0.7788519434783834\n",
      "train loss:0.9968701378163983\n",
      "train loss:0.9978023635307619\n",
      "train loss:0.949096358751176\n",
      "train loss:1.0356600674440777\n",
      "train loss:0.9897634647161148\n",
      "train loss:0.9894138197326804\n",
      "train loss:0.8210459012608111\n",
      "train loss:0.7416516595085478\n",
      "train loss:1.0261553535032024\n",
      "train loss:0.8426733284700941\n",
      "train loss:0.9815978957797309\n",
      "train loss:0.9910950008320714\n",
      "train loss:0.9577299878580053\n",
      "train loss:1.070940740506521\n",
      "train loss:1.0822887850851606\n",
      "train loss:1.0227126114358296\n",
      "train loss:0.8993315862948286\n",
      "train loss:1.0666789329685817\n",
      "train loss:0.8700730122163924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8023816066847974\n",
      "train loss:0.8058336108671525\n",
      "train loss:0.92351153798709\n",
      "train loss:0.9215563096005382\n",
      "train loss:0.8531193101993886\n",
      "train loss:0.9580330234458795\n",
      "train loss:0.7995809321857312\n",
      "train loss:0.844205895618173\n",
      "train loss:0.8257560423307068\n",
      "train loss:1.0199872182414906\n",
      "train loss:0.7755575040100051\n",
      "train loss:0.8820307577703868\n",
      "train loss:0.9741257114274444\n",
      "train loss:1.0269038559029227\n",
      "train loss:0.9814752917755031\n",
      "train loss:0.8838751711498739\n",
      "train loss:0.8540859642976603\n",
      "train loss:1.0121732628718467\n",
      "train loss:0.965028735972933\n",
      "train loss:0.9273454822600286\n",
      "train loss:1.0205200740214382\n",
      "train loss:1.1036668600605297\n",
      "train loss:0.8435092552164659\n",
      "train loss:0.8807389952775949\n",
      "train loss:0.944003930712152\n",
      "train loss:0.8584756421507689\n",
      "train loss:0.9281148809512945\n",
      "train loss:0.7891448030609728\n",
      "train loss:0.8715691226764788\n",
      "train loss:0.8548258829276298\n",
      "train loss:0.9189918970247498\n",
      "train loss:1.075430931763675\n",
      "train loss:0.8854580727323974\n",
      "=== epoch:7, train acc:0.992, test acc:0.992 ===\n",
      "train loss:0.9583228033913653\n",
      "train loss:1.017948141444516\n",
      "train loss:0.9162353885799626\n",
      "train loss:0.9432394092061638\n",
      "train loss:1.0145329234501397\n",
      "train loss:1.0349991834368881\n",
      "train loss:0.8623829925522274\n",
      "train loss:0.9544866837395172\n",
      "train loss:0.9151384270320159\n",
      "train loss:0.8979197470596371\n",
      "train loss:0.8448178884837305\n",
      "train loss:1.035977949866944\n",
      "train loss:0.8823445089523771\n",
      "train loss:0.8829371112340942\n",
      "train loss:0.8301172952167551\n",
      "train loss:1.0056744819976469\n",
      "train loss:1.154836701677295\n",
      "train loss:0.9172964516017535\n",
      "train loss:0.8674202797135309\n",
      "train loss:0.9923499632712356\n",
      "train loss:0.773412386771941\n",
      "train loss:0.8357428571361722\n",
      "train loss:0.8281865342116249\n",
      "train loss:0.873461080525436\n",
      "train loss:0.9303573599722158\n",
      "train loss:0.7354669018010545\n",
      "train loss:0.992479173626371\n",
      "train loss:0.8529489423012141\n",
      "train loss:0.8179926998553104\n",
      "train loss:1.0335586155250966\n",
      "train loss:0.8789400147338142\n",
      "train loss:0.8840594051957567\n",
      "train loss:0.9452638009404459\n",
      "train loss:1.1054106287566006\n",
      "train loss:0.9441694181474847\n",
      "train loss:0.9612422239477192\n",
      "train loss:1.023463117790047\n",
      "train loss:0.9996753425946733\n",
      "train loss:0.8819519431225469\n",
      "train loss:1.0918184642698114\n",
      "train loss:0.7803906618750824\n",
      "train loss:0.9592115083558581\n",
      "train loss:0.8483264222305698\n",
      "train loss:0.9388728146018921\n",
      "train loss:0.7802635962205958\n",
      "train loss:0.9511167401472375\n",
      "train loss:0.8789696973766015\n",
      "train loss:0.8414746714678556\n",
      "train loss:0.8803647370045783\n",
      "train loss:0.8706111884311831\n",
      "train loss:0.8288294403970738\n",
      "train loss:0.7989128701921604\n",
      "train loss:0.8408807354522884\n",
      "train loss:0.8078832242413282\n",
      "train loss:0.9806115604131399\n",
      "train loss:0.9156304938736655\n",
      "train loss:1.1191587873968292\n",
      "train loss:0.9775331632128587\n",
      "train loss:0.8196722838529855\n",
      "train loss:0.7495327458501221\n",
      "train loss:1.028873866117125\n",
      "train loss:0.8070528038670006\n",
      "train loss:0.8609810423068225\n",
      "train loss:0.9144436631583599\n",
      "train loss:0.8237018363211306\n",
      "train loss:0.956163447965888\n",
      "train loss:1.0109509274569823\n",
      "train loss:0.9801661387244757\n",
      "train loss:0.8351356623779502\n",
      "train loss:0.9234647810074827\n",
      "train loss:0.8827308443933652\n",
      "train loss:0.8707541885899676\n",
      "train loss:0.9181138347222203\n",
      "train loss:0.9608520399527493\n",
      "train loss:0.7062714373277384\n",
      "train loss:0.9075358235133654\n",
      "train loss:0.9661000869552465\n",
      "train loss:0.9576788498839993\n",
      "train loss:0.9035712097778679\n",
      "train loss:1.027323205300772\n",
      "train loss:0.7847389025767704\n",
      "train loss:0.8227715826494842\n",
      "train loss:0.9587128157815623\n",
      "train loss:0.9910265198832968\n",
      "train loss:0.9879962295846397\n",
      "train loss:0.9462168855914156\n",
      "train loss:0.7488742078433127\n",
      "train loss:0.9236387519722489\n",
      "train loss:1.0168127309437274\n",
      "train loss:0.9439013439805494\n",
      "train loss:0.9960349296125578\n",
      "train loss:0.848561197483682\n",
      "train loss:1.058946152873654\n",
      "train loss:0.9471114190059725\n",
      "train loss:0.859533893219181\n",
      "train loss:1.0042188442048057\n",
      "train loss:0.8079615726637381\n",
      "train loss:1.0625669641330417\n",
      "train loss:0.9811058272855557\n",
      "train loss:0.8660718848166181\n",
      "train loss:1.0685763636999739\n",
      "train loss:0.8795624238887849\n",
      "train loss:0.897480289199417\n",
      "train loss:0.9592787755222839\n",
      "train loss:0.9670247625267424\n",
      "train loss:0.7753789100225243\n",
      "train loss:0.9892618037307535\n",
      "train loss:1.0880277187007763\n",
      "train loss:1.047422112689803\n",
      "train loss:0.8980423764317794\n",
      "train loss:0.7816206929481976\n",
      "train loss:0.7527674605496771\n",
      "train loss:0.9728071921171736\n",
      "train loss:0.8715508866923869\n",
      "train loss:0.9621968899950774\n",
      "train loss:0.9320078554301304\n",
      "train loss:0.8836189778109457\n",
      "train loss:0.9102925312890211\n",
      "train loss:0.9307609474646438\n",
      "train loss:1.0173483068454794\n",
      "train loss:0.7521967661479456\n",
      "train loss:0.9726286012641441\n",
      "train loss:0.9460528712408974\n",
      "train loss:0.9025314783002281\n",
      "train loss:1.0133627918033203\n",
      "train loss:0.8991284850474668\n",
      "train loss:1.0719210218399933\n",
      "train loss:0.8236045337602641\n",
      "train loss:0.938997638879279\n",
      "train loss:0.8900442972709438\n",
      "train loss:0.8621214019374892\n",
      "train loss:1.1527851710939445\n",
      "train loss:0.9309307455901882\n",
      "train loss:1.081537605124027\n",
      "train loss:0.8507097547208788\n",
      "train loss:1.0494490703304198\n",
      "train loss:0.9330733126191245\n",
      "train loss:0.8930313044489314\n",
      "train loss:0.8498622456140926\n",
      "train loss:1.1181634386776\n",
      "train loss:0.8748635459186411\n",
      "train loss:0.8972569373042755\n",
      "train loss:0.8126043831012705\n",
      "train loss:1.1295483906471548\n",
      "train loss:0.862698976471883\n",
      "train loss:1.1013716455967142\n",
      "train loss:1.05796652507058\n",
      "train loss:0.8926552862182934\n",
      "train loss:1.2305453257932846\n",
      "train loss:0.8819812089171761\n",
      "train loss:0.9694359990532234\n",
      "train loss:0.9575424564868592\n",
      "train loss:0.8499075096486227\n",
      "train loss:0.9856319124347707\n",
      "train loss:0.8570968012871198\n",
      "train loss:0.908801748564181\n",
      "train loss:0.9750817211242494\n",
      "train loss:0.8936480279596105\n",
      "train loss:0.8925066948287917\n",
      "train loss:0.752489097662246\n",
      "train loss:1.0173064231849795\n",
      "train loss:0.9399791754597446\n",
      "train loss:1.1013267701634315\n",
      "train loss:0.8252575461857582\n",
      "train loss:0.9982634220853783\n",
      "train loss:0.8729717417903893\n",
      "train loss:0.9606305169964736\n",
      "train loss:0.8339157911503503\n",
      "train loss:0.999450421615341\n",
      "train loss:0.8886207033377116\n",
      "train loss:0.8639106472805135\n",
      "train loss:1.0183203626568575\n",
      "train loss:0.7761299531033591\n",
      "train loss:1.0066788604822712\n",
      "train loss:0.8646617259163718\n",
      "train loss:0.9211959633267388\n",
      "train loss:1.0033416121982919\n",
      "train loss:0.9518486915633712\n",
      "train loss:0.9533862341004472\n",
      "train loss:0.9354035603269958\n",
      "train loss:0.9193603588271586\n",
      "train loss:0.9472918797150137\n",
      "train loss:0.9025385593087804\n",
      "train loss:0.9611343667698782\n",
      "train loss:0.8514134795191657\n",
      "train loss:0.9078536416991593\n",
      "train loss:0.8911342008399413\n",
      "train loss:1.0960821634857891\n",
      "train loss:0.8313881839779583\n",
      "train loss:0.9266322951353798\n",
      "train loss:0.7109401125067655\n",
      "train loss:1.0112726626349187\n",
      "train loss:0.9994300914440077\n",
      "train loss:0.8246264642694004\n",
      "train loss:0.9524174485320396\n",
      "train loss:0.9924082849904525\n",
      "train loss:1.014064602735225\n",
      "train loss:0.9801325412141146\n",
      "train loss:0.9783419243921466\n",
      "train loss:1.0566682853611389\n",
      "train loss:0.85982212850047\n",
      "train loss:0.7333748747041714\n",
      "train loss:0.7734869545998326\n",
      "train loss:0.7871062174263177\n",
      "train loss:0.74644944466718\n",
      "train loss:0.8774251085166255\n",
      "train loss:1.0785095854464992\n",
      "train loss:0.9261261924803108\n",
      "train loss:0.7355941471314646\n",
      "train loss:0.8657012659033118\n",
      "train loss:0.847741478009084\n",
      "train loss:1.0719485898375651\n",
      "train loss:0.823517262004197\n",
      "train loss:0.9412968104629428\n",
      "train loss:1.0095490019763822\n",
      "train loss:0.9032159435772702\n",
      "train loss:0.9014198314594468\n",
      "train loss:0.9521494503935944\n",
      "train loss:0.7082594635623266\n",
      "train loss:0.8206771875630399\n",
      "train loss:0.9518114081083471\n",
      "train loss:1.0842230469062146\n",
      "train loss:0.8408955544512102\n",
      "train loss:0.8461315175545393\n",
      "train loss:0.8338000781206253\n",
      "train loss:0.9445520439204774\n",
      "train loss:0.9240587698902898\n",
      "train loss:1.022046681184257\n",
      "train loss:0.9313922724039095\n",
      "train loss:0.869176775771577\n",
      "train loss:0.9817823964570649\n",
      "train loss:0.8799741845569202\n",
      "train loss:0.8731321737945149\n",
      "train loss:0.9210937912192556\n",
      "train loss:0.993021474100995\n",
      "train loss:0.8835596426874409\n",
      "train loss:0.9375531584103848\n",
      "train loss:0.8717123447391869\n",
      "train loss:1.0826712347110492\n",
      "train loss:0.8182946196824937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8100783290142048\n",
      "train loss:0.9352776985270136\n",
      "train loss:0.9224860364071678\n",
      "train loss:1.0603130473725744\n",
      "train loss:1.0290139961805482\n",
      "train loss:1.0318537532289211\n",
      "train loss:0.8990316507622008\n",
      "train loss:0.8365954423306483\n",
      "train loss:0.8877641400471972\n",
      "train loss:0.9895401062940696\n",
      "train loss:0.8816099820071482\n",
      "train loss:0.8969416193111779\n",
      "train loss:1.0456573064902985\n",
      "train loss:0.7984390705038522\n",
      "train loss:0.9929861808306767\n",
      "train loss:0.970000512603565\n",
      "train loss:1.0322299688360674\n",
      "train loss:0.8343004634394581\n",
      "train loss:0.8988319990585358\n",
      "train loss:1.0287399998194307\n",
      "train loss:0.9408907002628386\n",
      "train loss:0.8233933076951574\n",
      "train loss:0.7137640919919122\n",
      "train loss:0.9435721122571763\n",
      "train loss:0.9374431099671393\n",
      "train loss:0.9507333408322234\n",
      "train loss:0.7411171489657328\n",
      "train loss:0.915976046533758\n",
      "train loss:0.9775593641825765\n",
      "train loss:0.8272452314452988\n",
      "train loss:0.9635615358720537\n",
      "train loss:1.055760338395907\n",
      "train loss:0.943298834128319\n",
      "train loss:0.7705401702051714\n",
      "train loss:1.1369271580276166\n",
      "train loss:0.9978570449832437\n",
      "train loss:0.9176594870673742\n",
      "train loss:0.9126814248760082\n",
      "train loss:0.8939949255757986\n",
      "train loss:0.7451539185874541\n",
      "train loss:1.0126165452406475\n",
      "train loss:0.9668841224560913\n",
      "train loss:0.8734550973041428\n",
      "train loss:1.103032168979383\n",
      "train loss:0.8838628898482622\n",
      "train loss:0.999710540459692\n",
      "train loss:0.8391399150675549\n",
      "train loss:0.8624866519331478\n",
      "train loss:0.9062200363292399\n",
      "train loss:0.8457521032016224\n",
      "train loss:0.9154280285644772\n",
      "train loss:0.9948955421241472\n",
      "train loss:0.9681418688901263\n",
      "train loss:0.9112954830242144\n",
      "train loss:0.8757632227325876\n",
      "train loss:0.9507734386192194\n",
      "train loss:1.1047063855501715\n",
      "train loss:0.9964338066655897\n",
      "train loss:0.932676998794646\n",
      "train loss:0.9217064634566248\n",
      "train loss:0.9932979378437742\n",
      "train loss:0.8416092475812227\n",
      "train loss:1.1065468678313137\n",
      "train loss:0.8739673304399532\n",
      "train loss:0.9384720068771095\n",
      "train loss:0.9546336166443513\n",
      "train loss:0.9621592956615135\n",
      "train loss:1.1054874484233197\n",
      "train loss:0.9506617632079626\n",
      "train loss:0.9230230091975637\n",
      "train loss:1.0342170392578067\n",
      "train loss:0.9396561769266475\n",
      "train loss:0.8362482085088417\n",
      "train loss:0.8868695729493808\n",
      "train loss:1.0156419470869475\n",
      "train loss:0.8646120330911389\n",
      "train loss:1.0400550114352773\n",
      "train loss:0.9621139141384222\n",
      "train loss:0.9563945910418399\n",
      "train loss:0.9677409352975589\n",
      "train loss:0.7573674657593255\n",
      "train loss:0.9651295351735512\n",
      "train loss:0.8841066918213\n",
      "train loss:0.9333044640822689\n",
      "train loss:1.0670752782399908\n",
      "train loss:1.0847746434677743\n",
      "train loss:0.9345668514748924\n",
      "train loss:0.8398915620478408\n",
      "train loss:1.0250329825127134\n",
      "train loss:0.9174892554158752\n",
      "train loss:0.8325386936780715\n",
      "train loss:1.0892420004775316\n",
      "train loss:0.8555268770038288\n",
      "train loss:0.9165393134864414\n",
      "train loss:1.1121929369172037\n",
      "train loss:0.8056456640207216\n",
      "train loss:0.9700849894326145\n",
      "train loss:1.0990187981357056\n",
      "train loss:0.9437121891481307\n",
      "train loss:0.8197366763674687\n",
      "train loss:0.9093095756442869\n",
      "train loss:0.9122514058695007\n",
      "train loss:0.8432127041793913\n",
      "train loss:1.031740870433729\n",
      "train loss:0.8331426692668878\n",
      "train loss:1.001030099300357\n",
      "train loss:1.159149628289069\n",
      "train loss:0.9475631888082215\n",
      "train loss:0.8907316264395052\n",
      "train loss:0.8321268676466773\n",
      "train loss:0.7088492934790271\n",
      "train loss:1.1334705024330434\n",
      "train loss:0.8407240107039862\n",
      "train loss:0.8651880429632438\n",
      "train loss:0.8942698180666288\n",
      "train loss:0.9733279053790521\n",
      "train loss:0.9498541940920202\n",
      "train loss:0.8286208264278379\n",
      "train loss:0.9094069697819336\n",
      "train loss:0.910320901737319\n",
      "train loss:0.9636770669146949\n",
      "train loss:0.774089328832285\n",
      "train loss:0.8232968932695951\n",
      "train loss:0.7585851060293194\n",
      "train loss:0.995438834573869\n",
      "train loss:0.8361902056545276\n",
      "train loss:0.9173506798086675\n",
      "train loss:0.8906350144007814\n",
      "train loss:0.8993487551370177\n",
      "train loss:0.7819847794001462\n",
      "train loss:0.9964999553213978\n",
      "train loss:0.8082096792753235\n",
      "train loss:0.8988859583296828\n",
      "train loss:1.1136462307177915\n",
      "train loss:0.9372586265859207\n",
      "train loss:0.8749759619621891\n",
      "train loss:0.9765842108908892\n",
      "train loss:1.0272192527825315\n",
      "train loss:1.017887639959051\n",
      "train loss:0.9872651496879195\n",
      "train loss:0.9413818883122361\n",
      "train loss:0.8498787379576745\n",
      "train loss:1.0607201528573673\n",
      "train loss:0.8422106317552961\n",
      "train loss:0.988021662426875\n",
      "train loss:0.9422277645928416\n",
      "train loss:0.9935349982551337\n",
      "train loss:0.9626168982891147\n",
      "train loss:0.9184045514496529\n",
      "train loss:0.9319619251193452\n",
      "train loss:1.0091940397086123\n",
      "train loss:1.03936949199289\n",
      "train loss:0.807461216306167\n",
      "train loss:0.8639588662715534\n",
      "train loss:0.8886310445962655\n",
      "train loss:0.9720126506542555\n",
      "train loss:0.789686534253571\n",
      "train loss:0.8967613977673404\n",
      "train loss:0.9460303511722599\n",
      "train loss:0.7676703888585062\n",
      "train loss:0.9321804635144794\n",
      "train loss:0.7118829273917163\n",
      "train loss:0.8946592088301777\n",
      "train loss:0.7498116136273224\n",
      "train loss:1.1419969971596695\n",
      "train loss:0.9599941364717626\n",
      "train loss:0.7912222254742126\n",
      "train loss:1.0228851281130804\n",
      "train loss:0.7977724788646782\n",
      "train loss:0.9779866668654716\n",
      "train loss:0.866555042079763\n",
      "train loss:0.8983051277191859\n",
      "train loss:0.9727991502632117\n",
      "train loss:0.963212534632709\n",
      "train loss:0.8771755115096675\n",
      "train loss:0.9950195142917085\n",
      "train loss:0.7648159520406722\n",
      "train loss:0.9545368628925178\n",
      "train loss:0.8549537917253158\n",
      "train loss:1.074586113314023\n",
      "train loss:1.164113211967297\n",
      "train loss:0.8768318000737233\n",
      "train loss:0.7846423711067542\n",
      "train loss:0.8803943384034354\n",
      "train loss:1.0710209067922587\n",
      "train loss:0.8940322572928382\n",
      "train loss:0.8504440790534624\n",
      "train loss:1.0228992020053886\n",
      "train loss:0.9233628389323446\n",
      "train loss:1.2370349694499\n",
      "train loss:1.1336621652651555\n",
      "train loss:0.9166665184574656\n",
      "train loss:0.8751367079784473\n",
      "train loss:1.0553271824378552\n",
      "train loss:0.8412817929524304\n",
      "train loss:1.1199553139815217\n",
      "train loss:0.8149195995315694\n",
      "train loss:0.8181147924445215\n",
      "train loss:1.045419138903103\n",
      "train loss:0.919089703793495\n",
      "train loss:0.9616305181392231\n",
      "train loss:0.9459749470599615\n",
      "train loss:1.0133789924782926\n",
      "train loss:1.1074369641349326\n",
      "train loss:0.9692505736256171\n",
      "train loss:1.029559716201273\n",
      "train loss:0.7894965218464016\n",
      "train loss:0.956120174271651\n",
      "train loss:0.9621506063840696\n",
      "train loss:1.051861868801721\n",
      "train loss:0.9573075667891386\n",
      "train loss:0.9760424873707337\n",
      "train loss:1.034073292807239\n",
      "train loss:0.8015743533155526\n",
      "train loss:0.924784210798875\n",
      "train loss:0.9026622704255396\n",
      "train loss:1.0607211704184065\n",
      "train loss:1.0510887072739494\n",
      "train loss:0.9630020209485415\n",
      "train loss:0.9446584823733022\n",
      "train loss:1.053068932667765\n",
      "train loss:0.9250992966475562\n",
      "train loss:0.8991118499271066\n",
      "train loss:0.8559162537832384\n",
      "train loss:1.0362011184359436\n",
      "train loss:0.8902782617502315\n",
      "train loss:0.944053627896114\n",
      "train loss:1.054010275772407\n",
      "train loss:0.953092591530401\n",
      "train loss:1.0085595019982954\n",
      "train loss:0.8806004555570961\n",
      "train loss:0.8985528945457449\n",
      "train loss:0.9046217121211089\n",
      "train loss:0.8613308432335164\n",
      "train loss:0.8237392517252234\n",
      "train loss:0.7557057082652421\n",
      "train loss:0.9788826623454492\n",
      "train loss:0.8068478704218296\n",
      "train loss:1.099856795932423\n",
      "train loss:1.02177702906657\n",
      "train loss:0.9601139809113545\n",
      "train loss:0.9070630986044188\n",
      "train loss:0.9931372360363698\n",
      "train loss:0.8101454332217511\n",
      "train loss:0.7900672153605879\n",
      "train loss:0.950515669147954\n",
      "train loss:0.7736900794678082\n",
      "train loss:0.9365228295918642\n",
      "train loss:1.1365052935881144\n",
      "train loss:0.9150626453813615\n",
      "train loss:0.8718282477314031\n",
      "train loss:0.9553070664732745\n",
      "train loss:0.9457419339903381\n",
      "train loss:0.8920044966835984\n",
      "train loss:0.8529766977540453\n",
      "train loss:0.9792810645120401\n",
      "train loss:0.7895611623460493\n",
      "train loss:1.0011269816915225\n",
      "train loss:0.8798666941779496\n",
      "train loss:0.8674649127765761\n",
      "train loss:0.8731820707426969\n",
      "train loss:0.9496394020466711\n",
      "train loss:0.9300277811712877\n",
      "train loss:1.010112201008578\n",
      "train loss:0.7425250076726089\n",
      "train loss:1.031170453333797\n",
      "train loss:0.8411928801705655\n",
      "train loss:0.9033097554242052\n",
      "train loss:0.9989858027189665\n",
      "train loss:0.9027393972725587\n",
      "train loss:0.897919132845062\n",
      "train loss:0.7956547921561266\n",
      "train loss:0.8742837790846885\n",
      "train loss:0.8695039751860106\n",
      "train loss:0.8248103286331758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8779894171708255\n",
      "train loss:0.8363856389627514\n",
      "train loss:0.8357261393962474\n",
      "train loss:1.035463533216758\n",
      "train loss:0.9301555982130254\n",
      "train loss:0.778325524171289\n",
      "train loss:0.9963210411554729\n",
      "train loss:1.1006636824051694\n",
      "train loss:1.0686781047330995\n",
      "train loss:0.8614942917541261\n",
      "train loss:0.8178198642569834\n",
      "train loss:0.8083973321753376\n",
      "train loss:1.1673862557560468\n",
      "train loss:0.8484738491225029\n",
      "train loss:0.7979150006396943\n",
      "train loss:0.7978062675704299\n",
      "train loss:0.8648324132890017\n",
      "train loss:0.8398797878532476\n",
      "train loss:0.7565180246477525\n",
      "train loss:0.8122262310306277\n",
      "train loss:0.8182951065903304\n",
      "train loss:0.9331655821646286\n",
      "train loss:1.041727466583692\n",
      "train loss:0.820863094778504\n",
      "train loss:1.0299037593082387\n",
      "train loss:0.8664313502760287\n",
      "train loss:0.8097182456228872\n",
      "train loss:0.7390291994278779\n",
      "train loss:0.8458546351927306\n",
      "train loss:1.1214143676873107\n",
      "train loss:0.8531490713081095\n",
      "train loss:0.9859500176546772\n",
      "train loss:0.9692888621388153\n",
      "train loss:0.810882067638724\n",
      "train loss:1.0049197576968902\n",
      "train loss:0.9306783883208767\n",
      "train loss:0.9973990689604311\n",
      "train loss:1.038067512588227\n",
      "train loss:0.8615710578673957\n",
      "train loss:0.9171908590635601\n",
      "train loss:0.9014888274079209\n",
      "train loss:0.9818760913660032\n",
      "train loss:0.9134746730647627\n",
      "train loss:0.9561989420075766\n",
      "train loss:0.850394135202881\n",
      "train loss:0.9264268030188958\n",
      "train loss:0.7473915481799844\n",
      "train loss:0.939996173113341\n",
      "train loss:0.8343208481230664\n",
      "train loss:0.8892810614680172\n",
      "train loss:1.1914183317831015\n",
      "train loss:0.8322974621146728\n",
      "train loss:1.06872705026925\n",
      "train loss:0.9119038618968167\n",
      "train loss:1.0296555899119797\n",
      "train loss:0.7555551026059169\n",
      "train loss:1.0241966898355224\n",
      "train loss:0.998983471745573\n",
      "train loss:0.9915992229263284\n",
      "train loss:0.8116424375397834\n",
      "train loss:0.8446609140177322\n",
      "train loss:1.0122512103036876\n",
      "train loss:0.8393203995727642\n",
      "train loss:1.0011460406059258\n",
      "train loss:0.8976682649531029\n",
      "train loss:0.954698080642594\n",
      "train loss:0.8979936533946998\n",
      "train loss:0.9346864090387367\n",
      "train loss:0.8304818197487874\n",
      "train loss:0.91591672319086\n",
      "train loss:0.9628939857376326\n",
      "train loss:0.9756016274692371\n",
      "train loss:1.0144340594185222\n",
      "train loss:0.8786785220850288\n",
      "train loss:0.782159926521808\n",
      "train loss:0.8993219852534686\n",
      "train loss:1.0144060203271628\n",
      "train loss:0.9006848905515278\n",
      "train loss:0.9196883311252928\n",
      "train loss:1.1100963857513948\n",
      "train loss:0.9435193673980378\n",
      "train loss:0.873275843841992\n",
      "train loss:0.7770131109757683\n",
      "train loss:0.8513971303371268\n",
      "train loss:0.8030856647843087\n",
      "=== epoch:8, train acc:0.99, test acc:0.982 ===\n",
      "train loss:0.835740570445061\n",
      "train loss:0.9060806516259374\n",
      "train loss:0.9831248241349789\n",
      "train loss:0.9395175743267004\n",
      "train loss:0.9202283473064078\n",
      "train loss:0.9800173769019286\n",
      "train loss:0.799620987350105\n",
      "train loss:0.8919297585729323\n",
      "train loss:1.0015219731432838\n",
      "train loss:1.052275360479514\n",
      "train loss:0.9077549148795785\n",
      "train loss:0.939213344060913\n",
      "train loss:0.8247039391979284\n",
      "train loss:0.9215847321495113\n",
      "train loss:0.8852401984644233\n",
      "train loss:0.8793251986635608\n",
      "train loss:0.8753168823075018\n",
      "train loss:0.9403732531030813\n",
      "train loss:0.9399850024916375\n",
      "train loss:0.9758685362183452\n",
      "train loss:0.95202092626305\n",
      "train loss:0.913553179350113\n",
      "train loss:1.2298072666722184\n",
      "train loss:0.9601168674131121\n",
      "train loss:0.9547336557926787\n",
      "train loss:0.846668474419487\n",
      "train loss:0.9469717299784165\n",
      "train loss:1.0220465978454039\n",
      "train loss:0.9147065370551928\n",
      "train loss:1.048469077299538\n",
      "train loss:0.9326174906182924\n",
      "train loss:0.8681184722178564\n",
      "train loss:0.9738285663925782\n",
      "train loss:1.0173018218682806\n",
      "train loss:0.8876747408158877\n",
      "train loss:0.9758930957673526\n",
      "train loss:0.9672943157408028\n",
      "train loss:0.7930853132692254\n",
      "train loss:0.8517493372625239\n",
      "train loss:0.9883446907225806\n",
      "train loss:1.059160653571494\n",
      "train loss:1.0167887609068145\n",
      "train loss:1.0269513512914055\n",
      "train loss:1.0092166647429495\n",
      "train loss:0.8570555541439354\n",
      "train loss:0.788598719305707\n",
      "train loss:0.8738209096286085\n",
      "train loss:0.8384751324134408\n",
      "train loss:0.8905490964093385\n",
      "train loss:0.8868145723418508\n",
      "train loss:0.8252281525324855\n",
      "train loss:0.8835017456853831\n",
      "train loss:0.8332190417013204\n",
      "train loss:1.0248018081217547\n",
      "train loss:0.7323440520081773\n",
      "train loss:0.8258200275432541\n",
      "train loss:0.9140577067308202\n",
      "train loss:0.9676931040258558\n",
      "train loss:0.9893751335478249\n",
      "train loss:0.848191110687586\n",
      "train loss:0.7924436756672236\n",
      "train loss:1.020739242672811\n",
      "train loss:1.1423973715516886\n",
      "train loss:0.871107680038217\n",
      "train loss:0.9243702199773461\n",
      "train loss:0.7479233260394902\n",
      "train loss:0.9555301925568468\n",
      "train loss:0.7810111115814111\n",
      "train loss:0.9421521640622887\n",
      "train loss:1.008773053360751\n",
      "train loss:1.0180981479092603\n",
      "train loss:0.9876304610889395\n",
      "train loss:0.970760501448821\n",
      "train loss:0.8506509600153896\n",
      "train loss:1.0171294205896415\n",
      "train loss:0.7080302812915007\n",
      "train loss:1.0185366625082388\n",
      "train loss:0.8327116171204244\n",
      "train loss:0.7995693338641956\n",
      "train loss:0.8992051869167326\n",
      "train loss:0.9014013831836946\n",
      "train loss:1.035924316566255\n",
      "train loss:0.9613586810443678\n",
      "train loss:1.003881154804873\n",
      "train loss:0.8330775845086813\n",
      "train loss:1.0320619973726155\n",
      "train loss:1.0148706860955978\n",
      "train loss:0.8191527347192634\n",
      "train loss:0.8404828955728014\n",
      "train loss:1.015736427654233\n",
      "train loss:0.8722844837523612\n",
      "train loss:1.0384740989241366\n",
      "train loss:0.8655987016786761\n",
      "train loss:0.8700808199967082\n",
      "train loss:1.017792263837099\n",
      "train loss:1.0061357841310477\n",
      "train loss:0.8393222930476292\n",
      "train loss:0.941705028115936\n",
      "train loss:0.975116597289999\n",
      "train loss:0.9009714391846176\n",
      "train loss:1.116793340936223\n",
      "train loss:0.8741123645262912\n",
      "train loss:0.7182419175550833\n",
      "train loss:0.8006615155974032\n",
      "train loss:0.9964471155644419\n",
      "train loss:0.800455307058807\n",
      "train loss:1.0039340261764853\n",
      "train loss:1.0644164270876753\n",
      "train loss:0.8228850598015204\n",
      "train loss:0.857392460092675\n",
      "train loss:0.8918588379228894\n",
      "train loss:0.9078523414834847\n",
      "train loss:0.9532407404608033\n",
      "train loss:0.9579286762149886\n",
      "train loss:0.8996630311932527\n",
      "train loss:0.8400044018780071\n",
      "train loss:0.8955965844715942\n",
      "train loss:0.9546667184449115\n",
      "train loss:0.8708025757266153\n",
      "train loss:1.0916938217601855\n",
      "train loss:0.8274007511288892\n",
      "train loss:1.0412797687682485\n",
      "train loss:0.7715529620313132\n",
      "train loss:0.9918008301488555\n",
      "train loss:0.9559773322056384\n",
      "train loss:1.0617208142806986\n",
      "train loss:0.7703613992960646\n",
      "train loss:0.9172193869758659\n",
      "train loss:0.741095428314998\n",
      "train loss:0.8908435316416587\n",
      "train loss:0.796136725767642\n",
      "train loss:0.9563972316258834\n",
      "train loss:0.8625877339903041\n",
      "train loss:0.9285336411104075\n",
      "train loss:0.7060082944160357\n",
      "train loss:0.7405044595294767\n",
      "train loss:0.8922936232180505\n",
      "train loss:1.0025894431890083\n",
      "train loss:0.902548386804357\n",
      "train loss:0.8105159040972534\n",
      "train loss:0.8850816351601232\n",
      "train loss:0.8817354316466383\n",
      "train loss:0.9373482768657493\n",
      "train loss:0.7482365964221863\n",
      "train loss:0.9270077897709713\n",
      "train loss:0.8592677956181813\n",
      "train loss:0.7920481001294055\n",
      "train loss:0.8951285212523864\n",
      "train loss:0.907511731400062\n",
      "train loss:0.9593518186533866\n",
      "train loss:0.8113154604207466\n",
      "train loss:0.9595506663783983\n",
      "train loss:0.8776905627308063\n",
      "train loss:0.797376668197263\n",
      "train loss:0.9025593409660092\n",
      "train loss:0.9720410446208443\n",
      "train loss:0.7714793686501382\n",
      "train loss:1.0044857399887643\n",
      "train loss:1.006124497251247\n",
      "train loss:0.9752243713036479\n",
      "train loss:0.8875796693160979\n",
      "train loss:0.9867531886722256\n",
      "train loss:0.8255297660197928\n",
      "train loss:0.9879081633194708\n",
      "train loss:0.9696867795923516\n",
      "train loss:0.9888552138604247\n",
      "train loss:0.9177982353546177\n",
      "train loss:1.0761798104698945\n",
      "train loss:0.8962605418701171\n",
      "train loss:0.8431281726328507\n",
      "train loss:0.8483726709684611\n",
      "train loss:0.8730218113808106\n",
      "train loss:0.7827401206112329\n",
      "train loss:1.028752975835757\n",
      "train loss:0.8829214889461151\n",
      "train loss:0.8772009480755684\n",
      "train loss:0.8126983988874192\n",
      "train loss:0.9946069224367787\n",
      "train loss:1.0315645700818021\n",
      "train loss:0.9209269647264817\n",
      "train loss:0.8095281119735813\n",
      "train loss:0.905233773900414\n",
      "train loss:0.7970690632404428\n",
      "train loss:0.9419606539876502\n",
      "train loss:0.8494752674140882\n",
      "train loss:0.9455644203878261\n",
      "train loss:0.989281197781367\n",
      "train loss:0.8652281022357314\n",
      "train loss:0.9013594462612037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.0442725614161725\n",
      "train loss:0.7687407018930188\n",
      "train loss:0.924132986996015\n",
      "train loss:0.8802736595759498\n",
      "train loss:0.953971848755157\n",
      "train loss:0.855438221505133\n",
      "train loss:0.957093817891558\n",
      "train loss:1.0301018406891125\n",
      "train loss:1.189744863479202\n",
      "train loss:0.7501195472380572\n",
      "train loss:0.9928518037686015\n",
      "train loss:0.7727321992423061\n",
      "train loss:0.9073314800620915\n",
      "train loss:0.9338587730831237\n",
      "train loss:1.0114461530838588\n",
      "train loss:0.6995546331590503\n",
      "train loss:1.0128234456455347\n",
      "train loss:0.9546452766600371\n",
      "train loss:0.9693164003364252\n",
      "train loss:0.8229334001516325\n",
      "train loss:1.0032404816350922\n",
      "train loss:0.8388690308185535\n",
      "train loss:0.9392087160268722\n",
      "train loss:0.9230195908780696\n",
      "train loss:0.9855965369772849\n",
      "train loss:1.0259646436324532\n",
      "train loss:1.0061109638726478\n",
      "train loss:0.8785491483722145\n",
      "train loss:0.7515954668447082\n",
      "train loss:0.8522093662868339\n",
      "train loss:1.167413496125897\n",
      "train loss:1.0118122533351963\n",
      "train loss:0.9059972270112887\n",
      "train loss:1.0339580232512198\n",
      "train loss:0.9928508687921991\n",
      "train loss:1.0080341970701792\n",
      "train loss:0.9327834793194897\n",
      "train loss:1.04687310310757\n",
      "train loss:0.9051304720583088\n",
      "train loss:0.8163305284509906\n",
      "train loss:0.9263767398197189\n",
      "train loss:0.9998903989708573\n",
      "train loss:0.8393423065882197\n",
      "train loss:0.9040086005397551\n",
      "train loss:1.042578691927621\n",
      "train loss:0.8453952350334183\n",
      "train loss:0.9530408304184265\n",
      "train loss:0.8397219971700445\n",
      "train loss:1.027441148201288\n",
      "train loss:0.9678903700818983\n",
      "train loss:0.9927390504155489\n",
      "train loss:0.907065922206053\n",
      "train loss:0.7751711539500452\n",
      "train loss:0.9484564254721742\n",
      "train loss:0.929253586617895\n",
      "train loss:0.9216650364352157\n",
      "train loss:0.8504704018661294\n",
      "train loss:1.0245666259471984\n",
      "train loss:0.8852717707092104\n",
      "train loss:0.9404204542508338\n",
      "train loss:0.9815452645856942\n",
      "train loss:0.8471063708070301\n",
      "train loss:0.8523649193525263\n",
      "train loss:0.915919937389138\n",
      "train loss:0.9445310226371494\n",
      "train loss:0.9435338035752227\n",
      "train loss:0.9511846091999479\n",
      "train loss:0.9266373787157062\n",
      "train loss:0.9474846645003575\n",
      "train loss:1.004254070370743\n",
      "train loss:0.9275812108022058\n",
      "train loss:0.7110184510604494\n",
      "train loss:0.8790889962248959\n",
      "train loss:0.9270698632967729\n",
      "train loss:1.0600944815331217\n",
      "train loss:0.9942107374660892\n",
      "train loss:0.9143254740813467\n",
      "train loss:0.869389201002866\n",
      "train loss:0.9451754415303539\n",
      "train loss:0.9339497246608711\n",
      "train loss:0.7966525926677233\n",
      "train loss:0.9999909950809773\n",
      "train loss:0.9627122877050506\n",
      "train loss:1.1364357867974926\n",
      "train loss:0.8214687342741377\n",
      "train loss:0.8291866808766283\n",
      "train loss:0.9176364327977108\n",
      "train loss:0.7901610880386829\n",
      "train loss:0.9749718881072057\n",
      "train loss:0.9310431470612736\n",
      "train loss:1.2060178357052753\n",
      "train loss:0.7851748615672045\n",
      "train loss:0.9465244132851554\n",
      "train loss:0.7964409391496384\n",
      "train loss:0.9981974373885207\n",
      "train loss:1.1098942921932429\n",
      "train loss:1.1449187550706492\n",
      "train loss:0.8833529443877203\n",
      "train loss:0.8337422576160806\n",
      "train loss:0.9142835456290315\n",
      "train loss:0.662567710962658\n",
      "train loss:0.9792302576182615\n",
      "train loss:0.8623588136836178\n",
      "train loss:0.8477609579466544\n",
      "train loss:0.7947563329706058\n",
      "train loss:0.971653678807502\n",
      "train loss:0.8081986523490844\n",
      "train loss:0.9054387764154516\n",
      "train loss:0.9614876524573929\n",
      "train loss:0.943493082111003\n",
      "train loss:0.918966808642012\n",
      "train loss:1.1621050159430628\n",
      "train loss:0.7712137437891982\n",
      "train loss:0.8416581350128307\n",
      "train loss:0.7688514588338994\n",
      "train loss:0.8285422870023205\n",
      "train loss:0.9909818140257026\n",
      "train loss:0.9466037114414534\n",
      "train loss:0.9003885710929899\n",
      "train loss:1.0971736210734009\n",
      "train loss:0.999673571688195\n",
      "train loss:0.8069769100440195\n",
      "train loss:0.8885299417116685\n",
      "train loss:1.0149073745090205\n",
      "train loss:1.0120240531810238\n",
      "train loss:1.0354086611669735\n",
      "train loss:0.9195073433551824\n",
      "train loss:0.7867623967898768\n",
      "train loss:0.8798281714772992\n",
      "train loss:0.9802174183548467\n",
      "train loss:0.9172660748785552\n",
      "train loss:0.9149165515707537\n",
      "train loss:0.9430618231387891\n",
      "train loss:0.9517091513269125\n",
      "train loss:0.8977687949851617\n",
      "train loss:0.8337588903648603\n",
      "train loss:0.7478489785783783\n",
      "train loss:0.9885565773342013\n",
      "train loss:1.0131335040058553\n",
      "train loss:0.7943188296949886\n",
      "train loss:0.9176229889438997\n",
      "train loss:0.9593971375255842\n",
      "train loss:0.9532025036834884\n",
      "train loss:0.851305116115763\n",
      "train loss:0.9638239414525985\n",
      "train loss:0.8645133228710332\n",
      "train loss:0.829415595338415\n",
      "train loss:0.9147921595165656\n",
      "train loss:0.8744138036673236\n",
      "train loss:0.9147219150818251\n",
      "train loss:0.7772774332580501\n",
      "train loss:1.0027664094479731\n",
      "train loss:0.9317746687152159\n",
      "train loss:0.9539611073052618\n",
      "train loss:1.043265060177883\n",
      "train loss:1.1232547777981148\n",
      "train loss:0.9432925915782274\n",
      "train loss:0.8006683938977049\n",
      "train loss:0.8098948508417091\n",
      "train loss:1.014256218356888\n",
      "train loss:1.0057906612380763\n",
      "train loss:0.9302220457172743\n",
      "train loss:1.059836780335821\n",
      "train loss:0.9400806893281868\n",
      "train loss:0.9015449284177818\n",
      "train loss:1.0154218622629336\n",
      "train loss:0.850053075100534\n",
      "train loss:0.9723957142026574\n",
      "train loss:0.9919521508171267\n",
      "train loss:0.7944313768105407\n",
      "train loss:0.9880771900525173\n",
      "train loss:0.9248794484098327\n",
      "train loss:0.7550924715060958\n",
      "train loss:0.9090544798820233\n",
      "train loss:1.0246043285896564\n",
      "train loss:0.9661819703343878\n",
      "train loss:0.819361584218186\n",
      "train loss:0.9269060222357965\n",
      "train loss:0.9865622344744144\n",
      "train loss:0.8919711485290772\n",
      "train loss:0.9311281681876175\n",
      "train loss:0.9033364415073835\n",
      "train loss:0.8609345293567174\n",
      "train loss:0.8340249820150799\n",
      "train loss:0.8670781881455666\n",
      "train loss:0.9408108500297526\n",
      "train loss:0.8880366283089881\n",
      "train loss:0.8374964933709964\n",
      "train loss:0.8065344036175891\n",
      "train loss:1.0200947139311543\n",
      "train loss:0.842829688472594\n",
      "train loss:0.8462017548290254\n",
      "train loss:1.0070716379310647\n",
      "train loss:1.0123005438510406\n",
      "train loss:0.9782826967952442\n",
      "train loss:0.8758268724812099\n",
      "train loss:0.7883013339503973\n",
      "train loss:0.9571557477504501\n",
      "train loss:1.0449229376708589\n",
      "train loss:0.8667337311329862\n",
      "train loss:1.0692754982765629\n",
      "train loss:1.0833501963412324\n",
      "train loss:1.0594377979875518\n",
      "train loss:0.8187828924722997\n",
      "train loss:0.7097227727136768\n",
      "train loss:0.8909695170307314\n",
      "train loss:0.9575751278299225\n",
      "train loss:0.8567151634879693\n",
      "train loss:0.7332889303948937\n",
      "train loss:0.9142463335958404\n",
      "train loss:0.9435773503162065\n",
      "train loss:0.9414629530035518\n",
      "train loss:1.0535684856941965\n",
      "train loss:1.0420284901325685\n",
      "train loss:1.113131115655122\n",
      "train loss:1.0683962881559754\n",
      "train loss:0.9963554329766215\n",
      "train loss:0.7990615990219664\n",
      "train loss:0.9762781417987996\n",
      "train loss:0.9798555860662879\n",
      "train loss:0.9750966574115933\n",
      "train loss:0.9649064626278262\n",
      "train loss:0.9228580656807531\n",
      "train loss:0.9418478651720629\n",
      "train loss:0.7584397644038622\n",
      "train loss:1.0708323434273144\n",
      "train loss:1.0246060204403653\n",
      "train loss:0.8919705502483565\n",
      "train loss:0.8645815815526976\n",
      "train loss:0.8697592180138157\n",
      "train loss:0.784049734641108\n",
      "train loss:0.9707480716406316\n",
      "train loss:0.7751711615634078\n",
      "train loss:0.9455099923035633\n",
      "train loss:0.7794573370936743\n",
      "train loss:0.8278144522880971\n",
      "train loss:0.8207906925319989\n",
      "train loss:0.8797059318433581\n",
      "train loss:0.9598301019027291\n",
      "train loss:0.8992333327847889\n",
      "train loss:0.9060377133531741\n",
      "train loss:0.7901011490003653\n",
      "train loss:0.9475462273021209\n",
      "train loss:0.9188357330983284\n",
      "train loss:0.92294563440163\n",
      "train loss:0.9517359287851944\n",
      "train loss:0.9869084162583043\n",
      "train loss:0.9194142228261606\n",
      "train loss:0.9321890051187063\n",
      "train loss:1.0354713466828462\n",
      "train loss:0.8118788931761106\n",
      "train loss:1.0398922837433575\n",
      "train loss:0.9637971694246411\n",
      "train loss:0.8343425744698914\n",
      "train loss:0.9063404940509916\n",
      "train loss:0.9108700979334051\n",
      "train loss:0.8006200668241376\n",
      "train loss:0.9899445161313986\n",
      "train loss:0.9699418968498229\n",
      "train loss:0.933317469945022\n",
      "train loss:1.0239760983555357\n",
      "train loss:0.968432050376079\n",
      "train loss:0.8800815025941033\n",
      "train loss:0.8676195879789678\n",
      "train loss:0.9711915854132143\n",
      "train loss:0.7937346974416377\n",
      "train loss:0.9594020762112443\n",
      "train loss:0.9209566415608073\n",
      "train loss:0.8023282699487774\n",
      "train loss:0.9779667643356293\n",
      "train loss:0.8182114627626196\n",
      "train loss:0.8333542655516152\n",
      "train loss:0.8943325517764091\n",
      "train loss:0.8582404459029243\n",
      "train loss:0.7952699578953474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7818568666704951\n",
      "train loss:1.0025232742455563\n",
      "train loss:0.8912142712130218\n",
      "train loss:0.8427026360487692\n",
      "train loss:0.8795788744230123\n",
      "train loss:0.837062991492203\n",
      "train loss:0.8710628686176716\n",
      "train loss:0.8878467026462001\n",
      "train loss:0.7210803288747417\n",
      "train loss:0.8562941181675581\n",
      "train loss:0.9244396997834907\n",
      "train loss:0.9451348236065066\n",
      "train loss:0.9730083129810754\n",
      "train loss:1.0035813343828657\n",
      "train loss:0.9672005214731336\n",
      "train loss:0.9820039299255856\n",
      "train loss:0.9655119385991361\n",
      "train loss:0.9178080807232647\n",
      "train loss:0.9180107664776471\n",
      "train loss:0.9707605742490277\n",
      "train loss:0.7663006609714942\n",
      "train loss:0.7673275557892459\n",
      "train loss:0.8002777834580376\n",
      "train loss:0.9931590395184814\n",
      "train loss:0.6587104751149103\n",
      "train loss:0.7960599783260899\n",
      "train loss:0.9047354645611274\n",
      "train loss:1.1424620129897387\n",
      "train loss:0.9123352512157584\n",
      "train loss:0.7562444014148546\n",
      "train loss:1.0953076740603596\n",
      "train loss:0.7815724277773234\n",
      "train loss:0.9409789876840701\n",
      "train loss:0.9388643680994888\n",
      "train loss:0.8940113285567988\n",
      "train loss:0.9537618454321622\n",
      "train loss:0.9639477337262712\n",
      "train loss:0.909116694979749\n",
      "train loss:0.8475624250477942\n",
      "train loss:0.8976428049003772\n",
      "train loss:0.963182804020832\n",
      "train loss:0.939884969611099\n",
      "train loss:0.6756390889410693\n",
      "train loss:0.8270638228868564\n",
      "train loss:0.909643362018558\n",
      "train loss:0.957602563203057\n",
      "train loss:1.116829845878664\n",
      "train loss:0.7963603919626027\n",
      "train loss:0.8238307501331346\n",
      "train loss:0.776757993562557\n",
      "train loss:1.052797782326186\n",
      "train loss:1.0210112472459802\n",
      "train loss:0.7845206083985006\n",
      "train loss:0.8361435507372019\n",
      "train loss:0.8495901159082111\n",
      "train loss:0.8188487672311793\n",
      "train loss:0.9516792014258104\n",
      "train loss:0.838531395456852\n",
      "train loss:0.9321736405735368\n",
      "train loss:0.8598746144228662\n",
      "train loss:0.816165064994388\n",
      "train loss:0.9252755653733098\n",
      "train loss:0.720180849418728\n",
      "train loss:0.7746249436819856\n",
      "train loss:0.8367489077609784\n",
      "train loss:0.8475155425757314\n",
      "train loss:0.9870959517732493\n",
      "train loss:0.9320195924603225\n",
      "train loss:0.8933784944835554\n",
      "train loss:1.0284142377021603\n",
      "train loss:0.9618312771026765\n",
      "train loss:0.9435201971292719\n",
      "train loss:1.018222552721835\n",
      "train loss:1.0407032530234521\n",
      "train loss:0.8402678628024834\n",
      "train loss:0.9241179387311798\n",
      "train loss:0.824642869011728\n",
      "train loss:0.9756895535717796\n",
      "train loss:0.8558740606873976\n",
      "train loss:0.9572843721636243\n",
      "train loss:0.8708228800021723\n",
      "train loss:1.015548111429724\n",
      "train loss:0.7891765481581767\n",
      "train loss:0.8804818017840197\n",
      "train loss:0.9530761336245241\n",
      "train loss:0.8481004073219688\n",
      "train loss:0.9809109425095975\n",
      "train loss:0.8238016850480254\n",
      "train loss:0.8882642218876988\n",
      "train loss:0.8321939250838204\n",
      "train loss:0.7585347429975754\n",
      "train loss:0.8987623313593052\n",
      "train loss:0.8801483962293672\n",
      "train loss:0.973861416903691\n",
      "train loss:0.723114874094\n",
      "train loss:0.9027483364897081\n",
      "train loss:1.0109291044079387\n",
      "train loss:0.9016259692399252\n",
      "train loss:0.7695268732649356\n",
      "train loss:1.1100561657446066\n",
      "train loss:0.7720973522917258\n",
      "train loss:1.004264127543567\n",
      "train loss:0.7540558382430704\n",
      "train loss:1.0164757891157916\n",
      "train loss:0.8981422149782812\n",
      "train loss:0.8272484118341206\n",
      "train loss:0.8539345808912101\n",
      "train loss:0.9319429755017918\n",
      "train loss:0.8540362749973789\n",
      "train loss:0.7941250573334362\n",
      "train loss:0.8386474088335985\n",
      "train loss:0.7402651011710857\n",
      "train loss:0.9760159029734919\n",
      "train loss:0.8647001320473493\n",
      "train loss:0.8977780405301772\n",
      "train loss:0.9352673390411299\n",
      "train loss:0.8196786642891014\n",
      "train loss:0.9881525742002737\n",
      "train loss:0.9453155895329576\n",
      "train loss:0.8425889732373661\n",
      "train loss:0.8758185358191749\n",
      "train loss:0.9008480545954398\n",
      "train loss:0.9420775976397223\n",
      "train loss:1.004083189200948\n",
      "train loss:0.9305780630289405\n",
      "train loss:0.9001116129546848\n",
      "train loss:1.0929107307899055\n",
      "train loss:0.8881544557778571\n",
      "train loss:0.9573776606510596\n",
      "train loss:0.9361577491505061\n",
      "train loss:0.8387033924186156\n",
      "train loss:0.8069279460975426\n",
      "train loss:0.8781880043714771\n",
      "train loss:0.7964032720782697\n",
      "train loss:1.014478027097771\n",
      "train loss:0.8188945687139867\n",
      "=== epoch:9, train acc:0.993, test acc:0.99 ===\n",
      "train loss:0.9691941684009625\n",
      "train loss:0.9791749621917084\n",
      "train loss:0.8675697370400755\n",
      "train loss:0.890291841455118\n",
      "train loss:0.8432008681713641\n",
      "train loss:0.7982288838752467\n",
      "train loss:1.023878317733917\n",
      "train loss:0.9072049617330958\n",
      "train loss:1.1815386465228401\n",
      "train loss:1.00012571169248\n",
      "train loss:0.793478130870629\n",
      "train loss:1.0096467835654177\n",
      "train loss:0.7701625257983465\n",
      "train loss:1.06433215323822\n",
      "train loss:1.0115150597890683\n",
      "train loss:0.9566116343140892\n",
      "train loss:0.8437890177691336\n",
      "train loss:0.8292319056264924\n",
      "train loss:0.8815788477417703\n",
      "train loss:1.043005025149951\n",
      "train loss:0.9637037416400231\n",
      "train loss:0.8777557770532256\n",
      "train loss:0.7689818937153755\n",
      "train loss:1.0039145321196732\n",
      "train loss:0.8955912230147398\n",
      "train loss:0.9892676330510368\n",
      "train loss:0.8167072201022695\n",
      "train loss:0.8942786709694789\n",
      "train loss:0.7769035062323114\n",
      "train loss:0.8746960672104374\n",
      "train loss:0.9749976373884272\n",
      "train loss:0.9832534286816603\n",
      "train loss:0.9021194431255501\n",
      "train loss:0.906489882366907\n",
      "train loss:0.8061201261644961\n",
      "train loss:0.8194637353253522\n",
      "train loss:1.0942041053328204\n",
      "train loss:1.0174173882270097\n",
      "train loss:0.8326849641899217\n",
      "train loss:0.9724116247211883\n",
      "train loss:1.0982096232041905\n",
      "train loss:1.0120286161262069\n",
      "train loss:1.0968323872027064\n",
      "train loss:1.0206235540763695\n",
      "train loss:0.9164501002322164\n",
      "train loss:0.7529849960768747\n",
      "train loss:0.8795309977890827\n",
      "train loss:0.9105823198288815\n",
      "train loss:0.9326886244931143\n",
      "train loss:0.9318602645460535\n",
      "train loss:0.7879433129884825\n",
      "train loss:1.0169782908480691\n",
      "train loss:0.898503669256166\n",
      "train loss:0.8047000905968724\n",
      "train loss:0.9493673857722746\n",
      "train loss:0.8343905678494873\n",
      "train loss:0.9333800827293943\n",
      "train loss:0.9839742654606733\n",
      "train loss:0.888699397735921\n",
      "train loss:0.9389205139625632\n",
      "train loss:0.9525097833591042\n",
      "train loss:1.0279546334917087\n",
      "train loss:0.8359521381800401\n",
      "train loss:0.9568725358356664\n",
      "train loss:0.6822676879630549\n",
      "train loss:1.048415647335734\n",
      "train loss:0.8858193272423495\n",
      "train loss:0.712998502496732\n",
      "train loss:0.8587447189402786\n",
      "train loss:0.9075850256003161\n",
      "train loss:0.8792850909561513\n",
      "train loss:1.0060625447701879\n",
      "train loss:0.7692537550458054\n",
      "train loss:0.7700617839615947\n",
      "train loss:0.8814005501163775\n",
      "train loss:0.891655428196933\n",
      "train loss:0.9079872311712102\n",
      "train loss:1.0379357163423526\n",
      "train loss:0.8175471256256602\n",
      "train loss:0.8531644980355041\n",
      "train loss:1.0035895772460124\n",
      "train loss:0.922989748163597\n",
      "train loss:0.8472967215930386\n",
      "train loss:0.8270949389597517\n",
      "train loss:1.095863085321231\n",
      "train loss:0.9558267219308776\n",
      "train loss:0.8548907079247426\n",
      "train loss:0.7919474122761875\n",
      "train loss:0.8804198462701648\n",
      "train loss:0.7505275490180702\n",
      "train loss:0.9679138104595636\n",
      "train loss:1.0896663045978896\n",
      "train loss:0.8546112730562168\n",
      "train loss:0.9778431158330987\n",
      "train loss:0.9928912253870911\n",
      "train loss:0.8808071952710569\n",
      "train loss:0.8779651616162117\n",
      "train loss:0.8566417046724838\n",
      "train loss:0.8075650958160313\n",
      "train loss:0.9148948299952093\n",
      "train loss:0.891119163648108\n",
      "train loss:0.9498931453087271\n",
      "train loss:1.0802334444113848\n",
      "train loss:1.00722636942507\n",
      "train loss:1.0509169631705704\n",
      "train loss:0.9983328670473359\n",
      "train loss:0.8209729227398668\n",
      "train loss:1.0009520850303508\n",
      "train loss:0.8978654618712405\n",
      "train loss:0.9300616773054214\n",
      "train loss:0.9341072737642575\n",
      "train loss:0.809073958864849\n",
      "train loss:0.9958847805206006\n",
      "train loss:1.020470201489656\n",
      "train loss:0.90105850650387\n",
      "train loss:0.8668866211720797\n",
      "train loss:0.8321820138439783\n",
      "train loss:0.9687686204232792\n",
      "train loss:0.8977809104641128\n",
      "train loss:0.8272331957205081\n",
      "train loss:1.0581307079190896\n",
      "train loss:0.7928718599869675\n",
      "train loss:0.710319615300652\n",
      "train loss:0.9362273740699155\n",
      "train loss:1.0248570293669117\n",
      "train loss:0.8804283123522925\n",
      "train loss:0.840881240019947\n",
      "train loss:1.0284626949549542\n",
      "train loss:0.7698867517461662\n",
      "train loss:0.9614443971585116\n",
      "train loss:0.8349442625994797\n",
      "train loss:0.7960610618115723\n",
      "train loss:0.9388994911726762\n",
      "train loss:1.0825219525230303\n",
      "train loss:1.0657257912878715\n",
      "train loss:1.0152774565774272\n",
      "train loss:1.0380651107585719\n",
      "train loss:0.9403286421342538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.0723486620376361\n",
      "train loss:0.8453753532480193\n",
      "train loss:0.7693796747957273\n",
      "train loss:0.9639515023531113\n",
      "train loss:0.9688405913688207\n",
      "train loss:0.7951103055407087\n",
      "train loss:1.056692850656871\n",
      "train loss:0.7718980145561315\n",
      "train loss:0.9972803084237014\n",
      "train loss:1.0063528609579784\n",
      "train loss:0.7765661090522811\n",
      "train loss:0.8922165950076638\n",
      "train loss:0.8806173549057867\n",
      "train loss:1.0723931698377769\n",
      "train loss:0.8993224531822429\n",
      "train loss:0.9435389669627697\n",
      "train loss:0.7272644652488327\n",
      "train loss:1.0094395714861388\n",
      "train loss:0.9766859681625152\n",
      "train loss:0.8688437831914048\n",
      "train loss:1.0012166115613281\n",
      "train loss:0.6685212550793566\n",
      "train loss:0.9865717977376549\n",
      "train loss:0.8969776114464952\n",
      "train loss:0.9417490777049372\n",
      "train loss:0.8189687342603577\n",
      "train loss:0.9388309395156272\n",
      "train loss:0.8808155259582245\n",
      "train loss:1.048221752143026\n",
      "train loss:0.8481886592749823\n",
      "train loss:0.8459495262371548\n",
      "train loss:0.9038618816177137\n",
      "train loss:0.9295973793654381\n",
      "train loss:0.9595234096858976\n",
      "train loss:0.816959336246034\n",
      "train loss:0.9332485224176521\n",
      "train loss:0.8793698658274842\n",
      "train loss:0.8078428763430527\n",
      "train loss:1.0709397271901897\n",
      "train loss:1.0132239859815833\n",
      "train loss:0.900898500258512\n",
      "train loss:0.8254995908424302\n",
      "train loss:1.0653182662369856\n",
      "train loss:0.908675779767864\n",
      "train loss:1.026725000452816\n",
      "train loss:0.8325449181613438\n",
      "train loss:0.9074220286544213\n",
      "train loss:1.0899723782471071\n",
      "train loss:0.7636975870290235\n",
      "train loss:0.8566576141606044\n",
      "train loss:0.963082503719628\n",
      "train loss:0.9365329800862742\n",
      "train loss:1.0719676356432952\n",
      "train loss:0.9044725797557831\n",
      "train loss:0.9685053858532351\n",
      "train loss:0.9411774852756899\n",
      "train loss:0.8745680242767735\n",
      "train loss:0.9149093714345926\n",
      "train loss:1.0507974474257227\n",
      "train loss:1.0080166105003854\n",
      "train loss:0.8528251507534692\n",
      "train loss:0.9204026142404395\n",
      "train loss:0.955764539769374\n",
      "train loss:0.918004552999728\n",
      "train loss:0.8551072857787014\n",
      "train loss:0.9027853286237963\n",
      "train loss:0.890364879442236\n",
      "train loss:0.8282337109163503\n",
      "train loss:0.7052408621110989\n",
      "train loss:0.7824811681873198\n",
      "train loss:0.9997452711350593\n",
      "train loss:1.0200116404414132\n",
      "train loss:1.0927276433865771\n",
      "train loss:0.9819359363341473\n",
      "train loss:0.8468391992623217\n",
      "train loss:0.7855468235659033\n",
      "train loss:0.9589689661221515\n",
      "train loss:1.0229091181033538\n",
      "train loss:0.8678482349988208\n",
      "train loss:1.016894583799938\n",
      "train loss:0.7839280467489967\n",
      "train loss:0.8623525245475231\n",
      "train loss:0.913147949624329\n",
      "train loss:1.0018625408724304\n",
      "train loss:0.8875349679355867\n",
      "train loss:0.8607950817357007\n",
      "train loss:0.9582471776812318\n",
      "train loss:0.9794813324310735\n",
      "train loss:0.8383620698556155\n",
      "train loss:1.1229236469686652\n",
      "train loss:0.9349199300003319\n",
      "train loss:1.0436252681307616\n",
      "train loss:1.0368454270328267\n",
      "train loss:0.9716336953538552\n",
      "train loss:0.8932290550466946\n",
      "train loss:0.8914927815018019\n",
      "train loss:0.8243980445123839\n",
      "train loss:1.0341291328790125\n",
      "train loss:0.934828539142587\n",
      "train loss:0.9176900076056067\n",
      "train loss:0.7154287265122978\n",
      "train loss:0.9079187354301527\n",
      "train loss:0.8409426422773191\n",
      "train loss:0.8288776077504565\n",
      "train loss:1.0290266455452282\n",
      "train loss:0.790809650333846\n",
      "train loss:1.0522841880013807\n",
      "train loss:0.8943624657888164\n",
      "train loss:1.0914543184470356\n",
      "train loss:0.8585035708574246\n",
      "train loss:0.8075225481916842\n",
      "train loss:0.906565191592137\n",
      "train loss:0.7239743107430795\n",
      "train loss:0.8011678280569189\n",
      "train loss:0.9021203292211414\n",
      "train loss:0.9150939652068452\n",
      "train loss:0.8462874815070017\n",
      "train loss:0.9112165009248392\n",
      "train loss:0.8241770376071205\n",
      "train loss:0.9027606986563902\n",
      "train loss:0.8879494406586051\n",
      "train loss:0.977112437862464\n",
      "train loss:0.9793685586413704\n",
      "train loss:0.8959626397745746\n",
      "train loss:0.8937267958362703\n",
      "train loss:0.9968886087177229\n",
      "train loss:0.945585256513521\n",
      "train loss:1.039057539141309\n",
      "train loss:0.9833642936556762\n",
      "train loss:0.7639371774799792\n",
      "train loss:0.9409071735534866\n",
      "train loss:0.9572301889801474\n",
      "train loss:0.9615897327783449\n",
      "train loss:0.9606014934832369\n",
      "train loss:1.044262853642242\n",
      "train loss:0.8183544612779912\n",
      "train loss:0.998200300498603\n",
      "train loss:0.940034773635235\n",
      "train loss:1.1291648410285227\n",
      "train loss:0.9446425140963197\n",
      "train loss:0.7627440695816381\n",
      "train loss:0.8730292890412364\n",
      "train loss:1.070384211146547\n",
      "train loss:0.8372780642422655\n",
      "train loss:1.0078497107925426\n",
      "train loss:0.9149511991722972\n",
      "train loss:0.8045760435200968\n",
      "train loss:0.9702428660421721\n",
      "train loss:0.9664237545135321\n",
      "train loss:0.8310771523084932\n",
      "train loss:1.0625203789067503\n",
      "train loss:1.0709502322636986\n",
      "train loss:0.8513441126917993\n",
      "train loss:0.8984908526942875\n",
      "train loss:0.8887085075251829\n",
      "train loss:0.9251401599373434\n",
      "train loss:0.9329251668695185\n",
      "train loss:0.7585559603274119\n",
      "train loss:1.0008673420693683\n",
      "train loss:0.7854136032058916\n",
      "train loss:0.8185772250258166\n",
      "train loss:0.8881672118252724\n",
      "train loss:1.0325325126341456\n",
      "train loss:0.7872479835208566\n",
      "train loss:0.9318289409255257\n",
      "train loss:0.9678325062766298\n",
      "train loss:0.8947953107346481\n",
      "train loss:0.9537377516994261\n",
      "train loss:0.9795651723080393\n",
      "train loss:0.7866937727579271\n",
      "train loss:0.9629855433737569\n",
      "train loss:1.1805164495449403\n",
      "train loss:0.7662435305999725\n",
      "train loss:0.8036693839609977\n",
      "train loss:0.8537872234065109\n",
      "train loss:1.0166929402380962\n",
      "train loss:1.0149520278466932\n",
      "train loss:0.8452543987551608\n",
      "train loss:0.8224716661674671\n",
      "train loss:0.8789315956167028\n",
      "train loss:0.9703442114067178\n",
      "train loss:0.8483002371210336\n",
      "train loss:0.7976210536791275\n",
      "train loss:1.0260987295382125\n",
      "train loss:1.2866441799786434\n",
      "train loss:0.879803929983199\n",
      "train loss:0.8421725311346089\n",
      "train loss:0.9551646441706712\n",
      "train loss:1.0191647914011375\n",
      "train loss:0.9784723195163878\n",
      "train loss:1.1066365604207034\n",
      "train loss:0.9170474537002522\n",
      "train loss:0.8346687284611666\n",
      "train loss:0.8051347098324209\n",
      "train loss:0.8921614382349812\n",
      "train loss:1.1053633440437605\n",
      "train loss:0.8923610159950323\n",
      "train loss:0.9125529899168613\n",
      "train loss:0.8752337686508413\n",
      "train loss:0.8278210911596257\n",
      "train loss:0.7461408117718697\n",
      "train loss:0.9206987669887603\n",
      "train loss:0.8083659284233424\n",
      "train loss:0.8491426509627067\n",
      "train loss:1.010799741136691\n",
      "train loss:0.861406388802045\n",
      "train loss:0.8654220349684332\n",
      "train loss:1.0095698554425079\n",
      "train loss:0.9597163447400544\n",
      "train loss:0.941433596637299\n",
      "train loss:0.841413101756072\n",
      "train loss:0.9261588898600508\n",
      "train loss:0.8306165520615135\n",
      "train loss:1.0213386220631318\n",
      "train loss:0.9910288979438061\n",
      "train loss:0.7434171276754311\n",
      "train loss:0.9963476037373431\n",
      "train loss:0.9517192462351781\n",
      "train loss:0.7601340475016737\n",
      "train loss:0.8589123107734945\n",
      "train loss:1.1190149075399998\n",
      "train loss:1.0010912138625967\n",
      "train loss:0.8641702274342166\n",
      "train loss:0.9319058541692562\n",
      "train loss:0.8288945124348943\n",
      "train loss:0.9889207063316019\n",
      "train loss:0.8999864659037865\n",
      "train loss:0.8070276029021717\n",
      "train loss:0.7673744961276638\n",
      "train loss:0.8153407158098118\n",
      "train loss:0.7151575078186911\n",
      "train loss:0.8665841713513244\n",
      "train loss:0.9002771605543586\n",
      "train loss:0.9026115033907347\n",
      "train loss:0.9357498837667854\n",
      "train loss:0.8988963301823152\n",
      "train loss:0.9733498391494299\n",
      "train loss:0.910325749647086\n",
      "train loss:0.9142980732642179\n",
      "train loss:0.9714523668637386\n",
      "train loss:0.7865510021906996\n",
      "train loss:0.8606955441191582\n",
      "train loss:1.078726694152068\n",
      "train loss:0.8467635996942212\n",
      "train loss:0.8140452126837759\n",
      "train loss:0.9218015112884653\n",
      "train loss:0.8932372028254182\n",
      "train loss:0.7115565619580708\n",
      "train loss:0.7290087123402919\n",
      "train loss:0.9702845224333401\n",
      "train loss:0.7617715384140802\n",
      "train loss:0.9799192438962661\n",
      "train loss:0.8847973183804518\n",
      "train loss:0.9001650419249345\n",
      "train loss:1.1004845578699296\n",
      "train loss:1.0204158887586947\n",
      "train loss:0.7421237399530862\n",
      "train loss:0.8366582441942715\n",
      "train loss:0.9266050026686504\n",
      "train loss:0.8502886306403397\n",
      "train loss:0.9486534829903717\n",
      "train loss:0.9321792564458571\n",
      "train loss:0.8962138552012374\n",
      "train loss:0.9415488010884667\n",
      "train loss:0.8640207923731594\n",
      "train loss:0.9914325949229237\n",
      "train loss:1.0402099963195426\n",
      "train loss:0.8557367888694631\n",
      "train loss:1.1099664004644965\n",
      "train loss:0.8257694772765509\n",
      "train loss:0.8714195459693836\n",
      "train loss:0.8815797599321846\n",
      "train loss:0.731620417762853\n",
      "train loss:1.032208499771272\n",
      "train loss:0.9086735198511181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8582850153400581\n",
      "train loss:0.8188209184332639\n",
      "train loss:0.7888933526583926\n",
      "train loss:1.0101060534195174\n",
      "train loss:0.83345060197114\n",
      "train loss:0.5876740787352611\n",
      "train loss:1.0116275941887372\n",
      "train loss:1.0672502157393997\n",
      "train loss:0.9491922234988328\n",
      "train loss:0.8683174666313427\n",
      "train loss:0.9986932997225831\n",
      "train loss:0.9674895481157039\n",
      "train loss:0.9079164528069247\n",
      "train loss:1.0581481296557487\n",
      "train loss:0.8303902175647281\n",
      "train loss:0.8269302893809821\n",
      "train loss:0.9802032394945326\n",
      "train loss:0.9010136540471804\n",
      "train loss:1.071572892367669\n",
      "train loss:0.8246914653804903\n",
      "train loss:0.9178765744812694\n",
      "train loss:0.9811871439767468\n",
      "train loss:0.9419114005798496\n",
      "train loss:0.899981420003553\n",
      "train loss:0.9304266264500463\n",
      "train loss:0.9190568212387318\n",
      "train loss:0.9724500241583403\n",
      "train loss:0.8890723856074239\n",
      "train loss:0.8511526160186033\n",
      "train loss:0.9126222817641865\n",
      "train loss:0.901902797775922\n",
      "train loss:0.7924960503289423\n",
      "train loss:0.9356559237206804\n",
      "train loss:0.8053955447471118\n",
      "train loss:0.8846266634325208\n",
      "train loss:0.9278595663703257\n",
      "train loss:1.017729837157999\n",
      "train loss:0.8031482771452003\n",
      "train loss:0.845346285788643\n",
      "train loss:0.9785031416531553\n",
      "train loss:0.8798604623985439\n",
      "train loss:0.8721409612297285\n",
      "train loss:0.7895280788638251\n",
      "train loss:0.8235697280850993\n",
      "train loss:0.9637781658364178\n",
      "train loss:0.798571980007226\n",
      "train loss:0.8060627071482174\n",
      "train loss:0.9013644418946208\n",
      "train loss:0.8652488552790132\n",
      "train loss:0.8347185149471871\n",
      "train loss:0.8370121905627564\n",
      "train loss:1.0083981585312547\n",
      "train loss:0.9470881986698667\n",
      "train loss:0.777153601914314\n",
      "train loss:1.152166681061044\n",
      "train loss:0.8476290568614816\n",
      "train loss:0.7966145641541955\n",
      "train loss:0.9736066156898733\n",
      "train loss:0.9236378109299374\n",
      "train loss:0.9463716623374464\n",
      "train loss:0.7059478289527412\n",
      "train loss:0.7193369004921922\n",
      "train loss:1.0897095334014912\n",
      "train loss:0.9096807611715129\n",
      "train loss:1.1006245567144284\n",
      "train loss:0.9739730246973956\n",
      "train loss:0.9840037217095698\n",
      "train loss:0.894068747845042\n",
      "train loss:0.8828809423205545\n",
      "train loss:1.0790077080240383\n",
      "train loss:0.7489659620034034\n",
      "train loss:0.7053308704092757\n",
      "train loss:0.8216865458843152\n",
      "train loss:0.6631264951458181\n",
      "train loss:0.795683154426861\n",
      "train loss:1.0083371798071774\n",
      "train loss:1.0348622883355503\n",
      "train loss:0.9361855127926618\n",
      "train loss:0.9942531748192441\n",
      "train loss:0.9764999760945485\n",
      "train loss:0.9253845645116034\n",
      "train loss:0.729748824495653\n",
      "train loss:0.8517213924988011\n",
      "train loss:0.9417714527379384\n",
      "train loss:0.9188553572902345\n",
      "train loss:0.9583877361173364\n",
      "train loss:1.0402892308892913\n",
      "train loss:1.0054766594230093\n",
      "train loss:0.7566570833489524\n",
      "train loss:1.0041709068188984\n",
      "train loss:0.8456469614507643\n",
      "train loss:0.8975090372911996\n",
      "train loss:0.9351560073982533\n",
      "train loss:0.8480955180102747\n",
      "train loss:0.8626532726274683\n",
      "train loss:1.022899167882301\n",
      "train loss:0.7546097416534677\n",
      "train loss:1.0110435592805884\n",
      "train loss:1.049958689812288\n",
      "train loss:1.006360396758209\n",
      "train loss:0.9911012936263862\n",
      "train loss:0.8530500493343279\n",
      "train loss:0.7947871076687888\n",
      "train loss:0.8616371937601681\n",
      "train loss:0.9023071365619592\n",
      "train loss:0.9435674199240544\n",
      "train loss:1.0283843797344636\n",
      "train loss:0.9194825136504043\n",
      "train loss:0.7286652304434748\n",
      "train loss:1.0569618847556206\n",
      "train loss:0.9174053457787658\n",
      "train loss:0.8895345772977019\n",
      "train loss:0.7967102146210466\n",
      "train loss:0.7909282873940591\n",
      "train loss:0.8920694845996294\n",
      "train loss:0.8567073622929722\n",
      "train loss:0.947818579747702\n",
      "train loss:0.9246689175595462\n",
      "train loss:0.831446586735982\n",
      "train loss:0.8476682966365928\n",
      "train loss:0.9300169505172796\n",
      "train loss:0.8231036093819699\n",
      "train loss:0.8298415771700378\n",
      "train loss:0.8559900763370863\n",
      "train loss:1.1052030453062875\n",
      "train loss:0.9592233964633187\n",
      "train loss:0.9894303936059345\n",
      "train loss:0.9239653909218783\n",
      "train loss:1.0078367261288863\n",
      "train loss:0.7013317785794804\n",
      "train loss:0.9722626867741713\n",
      "train loss:1.0177690940768604\n",
      "train loss:0.794083466186892\n",
      "train loss:1.0244647265141753\n",
      "train loss:0.8561349383791349\n",
      "train loss:0.8211048113315725\n",
      "train loss:1.0504399629458763\n",
      "train loss:0.8892271901202625\n",
      "train loss:0.9540868902364334\n",
      "train loss:0.9038076543345425\n",
      "train loss:0.858183060062559\n",
      "train loss:0.9489072502492132\n",
      "train loss:0.9824916068101116\n",
      "train loss:0.9856474149889575\n",
      "train loss:0.8825053449015037\n",
      "train loss:0.9689369646113858\n",
      "train loss:0.8134374192773168\n",
      "train loss:0.7727370426913568\n",
      "train loss:0.856714874808043\n",
      "train loss:1.02461693544289\n",
      "train loss:1.031839036622084\n",
      "train loss:0.9538722874980294\n",
      "train loss:0.859747517374139\n",
      "train loss:0.733263320704662\n",
      "train loss:0.8913266551411165\n",
      "train loss:0.861042437046596\n",
      "train loss:0.8825985998328698\n",
      "train loss:0.9594367694350768\n",
      "train loss:0.8811757685481837\n",
      "train loss:0.8989124116575136\n",
      "train loss:0.9594418659715642\n",
      "train loss:0.8028683167463501\n",
      "train loss:0.8749208183714381\n",
      "train loss:0.9068052130465987\n",
      "train loss:0.8764532840104531\n",
      "train loss:0.8840614945631401\n",
      "train loss:0.8973151689896862\n",
      "train loss:0.9020142056492414\n",
      "train loss:0.8174819869525153\n",
      "train loss:0.9283404235967214\n",
      "train loss:0.8362425874426617\n",
      "train loss:1.0819530880952761\n",
      "train loss:0.9067402214486148\n",
      "train loss:0.8798862541777975\n",
      "train loss:0.9566840849784312\n",
      "train loss:0.8687444582844737\n",
      "train loss:0.9866230368328094\n",
      "train loss:0.9059924312099976\n",
      "train loss:0.8239920760310224\n",
      "train loss:0.7931395926960201\n",
      "train loss:0.8693578499655988\n",
      "train loss:1.0317187249340294\n",
      "train loss:0.918244986504605\n",
      "train loss:1.0089184489999683\n",
      "train loss:1.0606918198542687\n",
      "train loss:0.9766678160838401\n",
      "train loss:0.9465785225590538\n",
      "=== epoch:10, train acc:0.997, test acc:0.985 ===\n",
      "train loss:0.9282773663997943\n",
      "train loss:0.8724574261790117\n",
      "train loss:0.7801853710081511\n",
      "train loss:0.8866180524455374\n",
      "train loss:0.8648090083249422\n",
      "train loss:1.0525551338260088\n",
      "train loss:0.7963110519073296\n",
      "train loss:0.9307317407984746\n",
      "train loss:0.9910437971824861\n",
      "train loss:1.0502123544724062\n",
      "train loss:0.7263721952835526\n",
      "train loss:1.1241781113831504\n",
      "train loss:0.9884230116686952\n",
      "train loss:1.0890730293956228\n",
      "train loss:0.9464443595180059\n",
      "train loss:0.8181438013393882\n",
      "train loss:0.9029188097862898\n",
      "train loss:0.7922923026184273\n",
      "train loss:0.9571453766424596\n",
      "train loss:0.7113411378684786\n",
      "train loss:0.9823385250625555\n",
      "train loss:0.8511018099886704\n",
      "train loss:0.8162973165662537\n",
      "train loss:0.895423168814705\n",
      "train loss:0.9965912962021055\n",
      "train loss:1.01902369962804\n",
      "train loss:0.8406782621625011\n",
      "train loss:0.7334191322912247\n",
      "train loss:0.9469300848806975\n",
      "train loss:0.980102433741845\n",
      "train loss:0.8051801332433186\n",
      "train loss:0.9163241856829785\n",
      "train loss:0.9466704718834194\n",
      "train loss:1.0729664609367684\n",
      "train loss:0.894361097280807\n",
      "train loss:0.8308129843714902\n",
      "train loss:1.0667792021573541\n",
      "train loss:0.7405785383227174\n",
      "train loss:1.054256495550044\n",
      "train loss:0.9537334040759606\n",
      "train loss:0.8473622137500272\n",
      "train loss:0.8718867633198777\n",
      "train loss:0.8525514724708256\n",
      "train loss:1.0028291635137017\n",
      "train loss:0.9434506318306837\n",
      "train loss:0.8973683089844618\n",
      "train loss:0.9092805303529597\n",
      "train loss:0.9577239377040196\n",
      "train loss:1.0979708048787942\n",
      "train loss:0.8963971989877719\n",
      "train loss:0.9537729622889127\n",
      "train loss:0.7971521562011666\n",
      "train loss:0.7924693089046632\n",
      "train loss:0.8923176965889836\n",
      "train loss:0.818851899298039\n",
      "train loss:0.977046906761331\n",
      "train loss:0.9352882050142318\n",
      "train loss:0.823481465719334\n",
      "train loss:0.7516600545876329\n",
      "train loss:0.8391602219123447\n",
      "train loss:0.8968672344471377\n",
      "train loss:0.925525042232711\n",
      "train loss:0.8753533302455011\n",
      "train loss:1.0726156124185988\n",
      "train loss:0.7830326828695624\n",
      "train loss:1.0180103130153186\n",
      "train loss:0.9963686334062614\n",
      "train loss:0.9683833939415131\n",
      "train loss:0.9863706626404568\n",
      "train loss:0.9366674372763409\n",
      "train loss:0.7542911098567895\n",
      "train loss:0.9076191055138928\n",
      "train loss:0.896577936543627\n",
      "train loss:0.6825001709325857\n",
      "train loss:1.040316217435161\n",
      "train loss:0.7618385759878601\n",
      "train loss:0.7984914861551033\n",
      "train loss:0.8186996212893364\n",
      "train loss:0.9888817388348713\n",
      "train loss:0.9849848064823344\n",
      "train loss:0.9420696680037918\n",
      "train loss:1.0274689377891333\n",
      "train loss:0.8213384279213966\n",
      "train loss:0.8554539407140216\n",
      "train loss:0.943730338802333\n",
      "train loss:0.8883177649112001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8489248917872528\n",
      "train loss:0.9212314214536039\n",
      "train loss:0.9210496019996106\n",
      "train loss:0.8585515165676725\n",
      "train loss:0.9520628960229441\n",
      "train loss:0.9627766803849744\n",
      "train loss:0.8947009330313598\n",
      "train loss:1.0067504342886269\n",
      "train loss:0.935916223281005\n",
      "train loss:0.8870178387999132\n",
      "train loss:0.7740353466724565\n",
      "train loss:0.9674766507593475\n",
      "train loss:0.9592754066003069\n",
      "train loss:0.9055268632682509\n",
      "train loss:0.9055917505825488\n",
      "train loss:0.9874201873106081\n",
      "train loss:0.9435942151566238\n",
      "train loss:0.8296755815494579\n",
      "train loss:1.089775250549058\n",
      "train loss:0.916466250011216\n",
      "train loss:1.0250984204593692\n",
      "train loss:1.0129504404291305\n",
      "train loss:0.9317961623525683\n",
      "train loss:0.9863349562760093\n",
      "train loss:0.7125691477499879\n",
      "train loss:0.9590014608117683\n",
      "train loss:0.7816754202798982\n",
      "train loss:0.870252908704526\n",
      "train loss:0.9064144473534419\n",
      "train loss:0.8751574230056033\n",
      "train loss:0.8604673379190896\n",
      "train loss:0.921699912387894\n",
      "train loss:0.89634243297221\n",
      "train loss:0.8134414919721439\n",
      "train loss:0.9122593136400949\n",
      "train loss:0.8507534835287391\n",
      "train loss:1.051362312791245\n",
      "train loss:0.9599935779196744\n",
      "train loss:0.8482740882818856\n",
      "train loss:0.8831521573140948\n",
      "train loss:0.8963920351087331\n",
      "train loss:0.8162748396849092\n",
      "train loss:0.8835339448731182\n",
      "train loss:0.9709722846519633\n",
      "train loss:1.0598852665288134\n",
      "train loss:0.8426942821399508\n",
      "train loss:1.0977651276656164\n",
      "train loss:0.9450469719392203\n",
      "train loss:0.8018266280014646\n",
      "train loss:0.9609551800751452\n",
      "train loss:0.9557868785131147\n",
      "train loss:0.7834577181727799\n",
      "train loss:0.9151191977928397\n",
      "train loss:1.031749492270657\n",
      "train loss:0.811488861603654\n",
      "train loss:0.8233556343546998\n",
      "train loss:0.8474421109868346\n",
      "train loss:0.8397183832045794\n",
      "train loss:0.8229696560691694\n",
      "train loss:0.8685785780688122\n",
      "train loss:0.7837716205655982\n",
      "train loss:0.8768299846045415\n",
      "train loss:0.8654736013701521\n",
      "train loss:0.9736110267856231\n",
      "train loss:0.8834620995124587\n",
      "train loss:0.9693401102258354\n",
      "train loss:0.9638343656464311\n",
      "train loss:0.9250525548934613\n",
      "train loss:0.8225281728745432\n",
      "train loss:0.9618517953971736\n",
      "train loss:0.8306069535520174\n",
      "train loss:0.8711514738774349\n",
      "train loss:0.9304204199202141\n",
      "train loss:0.6929156427558886\n",
      "train loss:0.9369589802164974\n",
      "train loss:0.8335035210184487\n",
      "train loss:0.9361690207960117\n",
      "train loss:0.966483545938783\n",
      "train loss:0.9376658119382809\n",
      "train loss:0.9135130944448201\n",
      "train loss:0.9289653265691471\n",
      "train loss:0.9098494698262253\n",
      "train loss:0.8417558497677388\n",
      "train loss:0.8510058132499979\n",
      "train loss:0.8425382931970199\n",
      "train loss:0.8708007827176408\n",
      "train loss:0.876415701131059\n",
      "train loss:0.8287940023323227\n",
      "train loss:0.9098632106955494\n",
      "train loss:0.8132349287244109\n",
      "train loss:0.998557271150925\n",
      "train loss:0.7949026778122571\n",
      "train loss:0.9383324193640391\n",
      "train loss:0.9388842482573015\n",
      "train loss:0.9728491392103479\n",
      "train loss:0.8581270529104019\n",
      "train loss:0.9882369428223905\n",
      "train loss:0.9671561245928474\n",
      "train loss:0.9916461051079962\n",
      "train loss:0.8010036206218907\n",
      "train loss:0.834080988372072\n",
      "train loss:0.8648721807619455\n",
      "train loss:0.7579618368364908\n",
      "train loss:0.9098845145307238\n",
      "train loss:0.9752924317036499\n",
      "train loss:0.8655694770472564\n",
      "train loss:0.7256921927448056\n",
      "train loss:1.0100342030250464\n",
      "train loss:0.8927095178128215\n",
      "train loss:0.912735883655212\n",
      "train loss:0.7461252282334299\n",
      "train loss:0.9763761054185638\n",
      "train loss:0.9365136254642414\n",
      "train loss:0.6916085727169857\n",
      "train loss:0.8007785421970621\n",
      "train loss:0.95910691304932\n",
      "train loss:0.9738721037531652\n",
      "train loss:1.0207038929427836\n",
      "train loss:0.9734937432015477\n",
      "train loss:0.9905827507047413\n",
      "train loss:0.7841192783868423\n",
      "train loss:0.7353302046470237\n",
      "train loss:0.9220273574373111\n",
      "train loss:0.9257127037401018\n",
      "train loss:0.9133801223451828\n",
      "train loss:0.8611520272561252\n",
      "train loss:0.9250057913730961\n",
      "train loss:0.8610082346993648\n",
      "train loss:0.9402127298736376\n",
      "train loss:0.8144452965467858\n",
      "train loss:0.8833536656681146\n",
      "train loss:0.7616174033743752\n",
      "train loss:0.9224655215009016\n",
      "train loss:0.7948719422331534\n",
      "train loss:0.9596253421770083\n",
      "train loss:1.0790669887790032\n",
      "train loss:0.9789534610080847\n",
      "train loss:0.8966577054993298\n",
      "train loss:0.9022372776598993\n",
      "train loss:0.8324969557159712\n",
      "train loss:0.7629870112495298\n",
      "train loss:0.8634569146019346\n",
      "train loss:0.9589155792526708\n",
      "train loss:1.0406321517465\n",
      "train loss:0.9903049662028844\n",
      "train loss:1.0734890771592551\n",
      "train loss:0.991829654803798\n",
      "train loss:0.8260466663363765\n",
      "train loss:0.7996547895813927\n",
      "train loss:0.6622256085802724\n",
      "train loss:0.8963217784659021\n",
      "train loss:0.8614314313250072\n",
      "train loss:0.8939560705476532\n",
      "train loss:0.9168115941704411\n",
      "train loss:0.9982317271144632\n",
      "train loss:0.8598137099097422\n",
      "train loss:0.9068002927182257\n",
      "train loss:0.9429071595248003\n",
      "train loss:0.8719433290007248\n",
      "train loss:0.9794807639208617\n",
      "train loss:0.954521598692262\n",
      "train loss:1.0118681914679704\n",
      "train loss:0.8902970348697137\n",
      "train loss:0.8845699865060314\n",
      "train loss:0.837302909420374\n",
      "train loss:0.9700309211919729\n",
      "train loss:0.9711259596262846\n",
      "train loss:0.8092003836726576\n",
      "train loss:0.8248107182694079\n",
      "train loss:0.9417920611127285\n",
      "train loss:0.8088256942157366\n",
      "train loss:0.8951426051103611\n",
      "train loss:0.8905598058697787\n",
      "train loss:0.8313082391065195\n",
      "train loss:0.9556069096110091\n",
      "train loss:1.0382811374999554\n",
      "train loss:0.9925115372782609\n",
      "train loss:0.8773949907553645\n",
      "train loss:0.7948449708128316\n",
      "train loss:0.8594291115554651\n",
      "train loss:1.2139795132224735\n",
      "train loss:0.8489549796069541\n",
      "train loss:0.8655807816288218\n",
      "train loss:0.9056250422384151\n",
      "train loss:0.8999039434218422\n",
      "train loss:1.0103443756223096\n",
      "train loss:0.9862934916385805\n",
      "train loss:0.9413530718570208\n",
      "train loss:0.7890470205342135\n",
      "train loss:0.934954664851574\n",
      "train loss:0.9184370693513165\n",
      "train loss:1.0894307555149256\n",
      "train loss:0.9077034653149622\n",
      "train loss:0.9539900912524366\n",
      "train loss:0.778422837615318\n",
      "train loss:0.8716567219714452\n",
      "train loss:0.9359984782530958\n",
      "train loss:0.9180726607765489\n",
      "train loss:0.9914282981328247\n",
      "train loss:0.9045770510340904\n",
      "train loss:0.7327432121415772\n",
      "train loss:0.9332880315230555\n",
      "train loss:1.0104732379476422\n",
      "train loss:0.8850816602741104\n",
      "train loss:0.7382380415924087\n",
      "train loss:0.8794373802440127\n",
      "train loss:0.8373846616825724\n",
      "train loss:0.888437348981396\n",
      "train loss:1.0493086173805204\n",
      "train loss:0.9101339931336793\n",
      "train loss:0.9553421153722188\n",
      "train loss:0.8310671021280528\n",
      "train loss:0.9596720015690647\n",
      "train loss:0.9687157827784367\n",
      "train loss:1.0358238657770762\n",
      "train loss:0.8604991962671825\n",
      "train loss:0.7172697915482382\n",
      "train loss:0.9902317054499044\n",
      "train loss:0.9126112700714252\n",
      "train loss:0.9958645069232456\n",
      "train loss:0.8518520981326436\n",
      "train loss:0.8861459679189673\n",
      "train loss:0.9840265191103499\n",
      "train loss:0.7835986917781446\n",
      "train loss:0.8325981560570308\n",
      "train loss:0.9286347288711642\n",
      "train loss:0.8361912623505308\n",
      "train loss:0.9226156526098535\n",
      "train loss:0.9567882891458234\n",
      "train loss:0.805491326610171\n",
      "train loss:0.9817270132715286\n",
      "train loss:1.0167318210894833\n",
      "train loss:0.9558569659134174\n",
      "train loss:0.9594847877357708\n",
      "train loss:1.001248946843366\n",
      "train loss:0.9189326101315661\n",
      "train loss:0.9219760872183607\n",
      "train loss:1.1098898676458864\n",
      "train loss:0.7332980667894617\n",
      "train loss:1.0901962066032533\n",
      "train loss:0.9462276376507249\n",
      "train loss:1.0452903376285037\n",
      "train loss:0.8433129026680818\n",
      "train loss:1.034192748719834\n",
      "train loss:1.0279649248886458\n",
      "train loss:0.9188529802721089\n",
      "train loss:0.9774542896964725\n",
      "train loss:0.8303862350162936\n",
      "train loss:0.9117787652763293\n",
      "train loss:0.8311356122403324\n",
      "train loss:0.8908545218708427\n",
      "train loss:0.8484515222313973\n",
      "train loss:0.9316926854345486\n",
      "train loss:1.083605162672653\n",
      "train loss:1.0120896677639712\n",
      "train loss:0.9851502328614398\n",
      "train loss:0.8919188370054592\n",
      "train loss:1.071212517063587\n",
      "train loss:0.9100894852439313\n",
      "train loss:1.0222867437308574\n",
      "train loss:1.091797144918558\n",
      "train loss:0.8770668656281336\n",
      "train loss:0.997147127394945\n",
      "train loss:0.7654501524788669\n",
      "train loss:0.9663676325635613\n",
      "train loss:0.8847154416879824\n",
      "train loss:0.953798453025028\n",
      "train loss:0.8569100827024211\n",
      "train loss:0.9667122061207836\n",
      "train loss:1.0803980625209912\n",
      "train loss:0.9663371054165627\n",
      "train loss:0.9327052498188623\n",
      "train loss:0.9451362819582346\n",
      "train loss:1.0316269129589566\n",
      "train loss:0.8969487003782655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9493375487198928\n",
      "train loss:1.057404065921478\n",
      "train loss:0.940171920798289\n",
      "train loss:0.7999829108812455\n",
      "train loss:0.9701425090713214\n",
      "train loss:0.8243298399257272\n",
      "train loss:0.8852844097979897\n",
      "train loss:0.9963017203708171\n",
      "train loss:0.89297375044831\n",
      "train loss:0.7895868600691698\n",
      "train loss:0.9541603706070386\n",
      "train loss:0.9063169866184374\n",
      "train loss:1.074286653283205\n",
      "train loss:0.8203469694053208\n",
      "train loss:0.903871557851933\n",
      "train loss:0.9633462307736359\n",
      "train loss:0.9321731496990826\n",
      "train loss:0.9225474763842965\n",
      "train loss:1.0303751378467232\n",
      "train loss:0.9773788120557441\n",
      "train loss:0.9478936794886756\n",
      "train loss:1.1073611275037771\n",
      "train loss:0.962349606881444\n",
      "train loss:0.7718288868123957\n",
      "train loss:0.9953228505428993\n",
      "train loss:0.9052641124188193\n",
      "train loss:0.8693618187644582\n",
      "train loss:0.9907127146822222\n",
      "train loss:0.8644633606705932\n",
      "train loss:1.0040335904710915\n",
      "train loss:0.8959010595555986\n",
      "train loss:1.0538493507564977\n",
      "train loss:0.8409345171358136\n",
      "train loss:0.9865970109026647\n",
      "train loss:0.9725493461278519\n",
      "train loss:0.9958734676307986\n",
      "train loss:0.9048529947848248\n",
      "train loss:0.8528387899402469\n",
      "train loss:0.992564294010622\n",
      "train loss:0.8144310765801137\n",
      "train loss:1.093600163588134\n",
      "train loss:0.9910361048694452\n",
      "train loss:0.9634759814208919\n",
      "train loss:0.9687115087731881\n",
      "train loss:0.9920517933769321\n",
      "train loss:1.0180517631267447\n",
      "train loss:0.7807298766478804\n",
      "train loss:0.834298506052804\n",
      "train loss:1.0793837040040637\n",
      "train loss:0.8252553624151057\n",
      "train loss:0.8897057336457357\n",
      "train loss:0.9224263463174686\n",
      "train loss:1.1116263167186538\n",
      "train loss:0.7287124201991176\n",
      "train loss:1.0470062463006016\n",
      "train loss:0.9672676393882679\n",
      "train loss:0.8931359941029977\n",
      "train loss:0.9674910118751606\n",
      "train loss:1.0938424565846252\n",
      "train loss:0.8151455247093604\n",
      "train loss:1.073774334615424\n",
      "train loss:0.7935311892914783\n",
      "train loss:0.9501176229000572\n",
      "train loss:0.8836891988941034\n",
      "train loss:0.9179937934095953\n",
      "train loss:0.7941867815857813\n",
      "train loss:0.9502844551940289\n",
      "train loss:0.8995723077801087\n",
      "train loss:0.9286540430575563\n",
      "train loss:0.987629588032258\n",
      "train loss:0.914710109235078\n",
      "train loss:0.921880878037999\n",
      "train loss:0.9481998727953787\n",
      "train loss:0.9630024215643402\n",
      "train loss:0.7606094101091007\n",
      "train loss:0.8541728561316521\n",
      "train loss:1.0828024328154775\n",
      "train loss:1.121896109066439\n",
      "train loss:0.7870542777858032\n",
      "train loss:0.9480240063193145\n",
      "train loss:0.8400454896902978\n",
      "train loss:0.8890191994974391\n",
      "train loss:0.9684368758560368\n",
      "train loss:0.9392469795597167\n",
      "train loss:0.7752327567801739\n",
      "train loss:0.9013355724937565\n",
      "train loss:0.8835839329806151\n",
      "train loss:0.9638018981430696\n",
      "train loss:0.9561997129026308\n",
      "train loss:0.6977063614848293\n",
      "train loss:0.9581091272634477\n",
      "train loss:0.9102852494807775\n",
      "train loss:0.9152506993930271\n",
      "train loss:1.006498923376165\n",
      "train loss:0.9252860711326865\n",
      "train loss:0.962396017773928\n",
      "train loss:0.9892847692077852\n",
      "train loss:0.7887453722656355\n",
      "train loss:0.9217506655802242\n",
      "train loss:0.810624709964155\n",
      "train loss:0.9230011117932189\n",
      "train loss:0.891888359704554\n",
      "train loss:0.987415212962056\n",
      "train loss:0.9933366062899295\n",
      "train loss:0.8336064827281416\n",
      "train loss:0.8869869625140987\n",
      "train loss:0.9815374101573101\n",
      "train loss:1.0808714785896156\n",
      "train loss:0.8966211189787766\n",
      "train loss:0.9608057094040613\n",
      "train loss:0.9612786321082838\n",
      "train loss:0.8156186912099508\n",
      "train loss:0.8761929951241187\n",
      "train loss:0.93689904300422\n",
      "train loss:0.9546265238226155\n",
      "train loss:0.9976337257219997\n",
      "train loss:0.9187865324229594\n",
      "train loss:0.8759708456039614\n",
      "train loss:0.7868807163866175\n",
      "train loss:0.7883249376301458\n",
      "train loss:0.8310637374327805\n",
      "train loss:0.95411521824234\n",
      "train loss:0.9687668390974089\n",
      "train loss:0.8711369866551156\n",
      "train loss:0.9708575508892797\n",
      "train loss:0.8804642596133833\n",
      "train loss:0.9134320351918823\n",
      "train loss:0.9122381087044221\n",
      "train loss:0.8945392200837151\n",
      "train loss:1.04933292780093\n",
      "train loss:1.0684925410311628\n",
      "train loss:0.9101263887315564\n",
      "train loss:0.7877297090161482\n",
      "train loss:1.1114994233693845\n",
      "train loss:0.7890073176016078\n",
      "train loss:0.6937551278267446\n",
      "train loss:0.8421520726313614\n",
      "train loss:0.8839861979049369\n",
      "train loss:0.966625206270305\n",
      "train loss:0.9072791818531108\n",
      "train loss:0.8670572886058817\n",
      "train loss:0.9510310340667091\n",
      "train loss:1.0650406517242965\n",
      "train loss:1.0257354317408052\n",
      "train loss:0.8219498556946192\n",
      "train loss:0.9691886196851476\n",
      "train loss:0.8426480384115698\n",
      "train loss:0.9253007459567474\n",
      "train loss:0.8361696675661626\n",
      "train loss:0.8975118634794547\n",
      "train loss:0.9085308774764752\n",
      "train loss:1.118297064912431\n",
      "train loss:0.8461138935244489\n",
      "train loss:0.7579268838641879\n",
      "train loss:0.6921344063079861\n",
      "train loss:1.0233825928139921\n",
      "train loss:0.8942722473117334\n",
      "train loss:0.9437295750145523\n",
      "train loss:0.7904903654270546\n",
      "train loss:0.8838884260392211\n",
      "train loss:1.007035632132319\n",
      "train loss:0.7890041949508274\n",
      "train loss:0.9887528650162847\n",
      "train loss:0.879590499531637\n",
      "train loss:0.8430602075252527\n",
      "train loss:0.9183132707708708\n",
      "train loss:0.9096893261386703\n",
      "train loss:0.9856844332770569\n",
      "train loss:0.8998208107236926\n",
      "train loss:0.7459111513534276\n",
      "train loss:0.8237406417712339\n",
      "train loss:0.8494923646480238\n",
      "train loss:0.8635647819942995\n",
      "train loss:0.8826830640852372\n",
      "train loss:0.8068509512443073\n",
      "train loss:0.835343215719804\n",
      "train loss:0.9031188005660526\n",
      "train loss:0.7738034194127407\n",
      "train loss:0.6210434461134251\n",
      "train loss:0.9424822026238319\n",
      "train loss:1.054203459915727\n",
      "train loss:0.9146849517025667\n",
      "train loss:0.7869073192593593\n",
      "train loss:0.9861431156619631\n",
      "train loss:0.8862805284315562\n",
      "train loss:0.9528168006698472\n",
      "train loss:0.9559674913886166\n",
      "train loss:0.8424596756236682\n",
      "train loss:0.971764612177168\n",
      "train loss:0.8609977615273019\n",
      "train loss:1.0351194654671123\n",
      "train loss:0.9751481113161669\n",
      "train loss:0.8955881713127551\n",
      "train loss:1.0462495884965017\n",
      "train loss:0.9190116367742479\n",
      "train loss:0.8321974536672664\n",
      "train loss:0.9593754789838143\n",
      "train loss:0.7347993582072792\n",
      "train loss:1.0368599139601333\n",
      "train loss:0.8896791074260461\n",
      "train loss:1.0293186800240435\n",
      "train loss:1.0115320293954146\n",
      "train loss:1.1140490781659602\n",
      "train loss:0.8151750193241027\n",
      "train loss:0.8334090398369315\n",
      "train loss:0.9807980348213539\n",
      "train loss:1.027858740564925\n",
      "train loss:0.8385171753225061\n",
      "train loss:0.9504918632080407\n",
      "train loss:0.8850410651201485\n",
      "train loss:0.7916387269339441\n",
      "train loss:0.807342772914797\n",
      "train loss:0.9153170194934337\n",
      "train loss:0.8158162996543717\n",
      "train loss:1.0557048941319918\n",
      "train loss:0.9074295655910167\n",
      "train loss:0.983969639705053\n",
      "train loss:0.7977934431942671\n",
      "train loss:0.7920762545404578\n",
      "train loss:0.9061793306717562\n",
      "train loss:0.7218261952908196\n",
      "train loss:0.854671221734818\n",
      "train loss:0.9654258288975559\n",
      "train loss:0.8909395415885406\n",
      "train loss:0.8085972981780003\n",
      "train loss:0.83666593885901\n",
      "train loss:0.9462665571027755\n",
      "train loss:0.7431050440052988\n",
      "train loss:0.8992831519961056\n",
      "train loss:0.8819210540342718\n",
      "train loss:0.9176267573439317\n",
      "train loss:0.9486881616650692\n",
      "train loss:0.9139257073128054\n",
      "train loss:1.0108382674810932\n",
      "train loss:0.7998675660523178\n",
      "train loss:0.8225578663744314\n",
      "train loss:0.9971830289273594\n",
      "train loss:0.9379577615193682\n",
      "train loss:0.9821138334818851\n",
      "=== epoch:11, train acc:0.997, test acc:0.99 ===\n",
      "train loss:0.9133623192279049\n",
      "train loss:0.9260780645453386\n",
      "train loss:0.844567259957796\n",
      "train loss:1.0308759065293438\n",
      "train loss:0.8935144128692352\n",
      "train loss:0.8797066471104559\n",
      "train loss:1.02799317258143\n",
      "train loss:1.1364460592015364\n",
      "train loss:1.0182764170050378\n",
      "train loss:0.8620414797868841\n",
      "train loss:0.8658304039783253\n",
      "train loss:0.9229581095152335\n",
      "train loss:0.9393304419415628\n",
      "train loss:0.8069431618731844\n",
      "train loss:0.8222639398112787\n",
      "train loss:0.8265244786524315\n",
      "train loss:0.7535264424904184\n",
      "train loss:0.9445900453298947\n",
      "train loss:0.9391964034694275\n",
      "train loss:1.0229197343868592\n",
      "train loss:0.8889235298496891\n",
      "train loss:0.895509365980117\n",
      "train loss:0.8743490471991209\n",
      "train loss:0.9310351312768796\n",
      "train loss:0.8076892552815917\n",
      "train loss:0.9412736672248622\n",
      "train loss:0.9940766547954959\n",
      "train loss:0.913877731111389\n",
      "train loss:0.8627431012090505\n",
      "train loss:0.973559551364188\n",
      "train loss:0.9435928433294\n",
      "train loss:0.7391495837140813\n",
      "train loss:0.8305095087345413\n",
      "train loss:0.9283679486118338\n",
      "train loss:0.9635973724102149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9215758012618359\n",
      "train loss:0.7172575557075376\n",
      "train loss:0.8334261354563753\n",
      "train loss:0.8471272512790178\n",
      "train loss:0.8592734277913487\n",
      "train loss:1.005813105796293\n",
      "train loss:0.906926382899512\n",
      "train loss:0.9640732859299951\n",
      "train loss:0.9232627423041486\n",
      "train loss:0.8780715442076799\n",
      "train loss:0.8088496018699654\n",
      "train loss:1.0175210746447834\n",
      "train loss:0.8328442509070841\n",
      "train loss:0.9214330209948125\n",
      "train loss:0.9401868790154049\n",
      "train loss:0.838091526998641\n",
      "train loss:0.8141080732229378\n",
      "train loss:0.9715996508200822\n",
      "train loss:0.8240434959990166\n",
      "train loss:0.8081893492186824\n",
      "train loss:0.7553587224081325\n",
      "train loss:1.019308867789111\n",
      "train loss:0.8451801421717918\n",
      "train loss:0.948036625264266\n",
      "train loss:1.1163665370854943\n",
      "train loss:0.8889058404387505\n",
      "train loss:0.8329614050120907\n",
      "train loss:0.8353291822102584\n",
      "train loss:0.8927091017878923\n",
      "train loss:0.8462135924560275\n",
      "train loss:1.020948744334315\n",
      "train loss:0.931191722562466\n",
      "train loss:1.005370520075942\n",
      "train loss:0.8903363354763308\n",
      "train loss:0.9853535003890737\n",
      "train loss:0.8033685340543394\n",
      "train loss:0.8793096797771683\n",
      "train loss:0.8929079878982988\n",
      "train loss:0.8993844365093979\n",
      "train loss:1.0156001394834537\n",
      "train loss:0.8931944491262318\n",
      "train loss:0.9965314794875048\n",
      "train loss:0.9092165641753336\n",
      "train loss:0.9895687002168362\n",
      "train loss:0.8787236075745308\n",
      "train loss:0.8767785137352067\n",
      "train loss:0.9749184288678565\n",
      "train loss:0.8705449710165556\n",
      "train loss:0.9270925845924474\n",
      "train loss:0.8524566003243144\n",
      "train loss:0.8901119156638058\n",
      "train loss:0.9954114333860916\n",
      "train loss:0.8934871942188507\n",
      "train loss:1.0612683797966151\n",
      "train loss:0.975720015963976\n",
      "train loss:0.9553367611537266\n",
      "train loss:0.942419305484669\n",
      "train loss:0.9613582426124563\n",
      "train loss:0.7416275169707611\n",
      "train loss:1.0189038006550988\n",
      "train loss:0.8793851067536784\n",
      "train loss:0.9955905257755165\n",
      "train loss:0.9071684943404159\n",
      "train loss:0.8324712828196118\n",
      "train loss:0.8675751000666219\n",
      "train loss:0.9500122028414404\n",
      "train loss:0.8477007116734822\n",
      "train loss:0.7317226350893254\n",
      "train loss:0.9905745973187241\n",
      "train loss:0.8541067666737703\n",
      "train loss:0.807615984960772\n",
      "train loss:0.9287406425594119\n",
      "train loss:0.7609225629961857\n",
      "train loss:0.7889601939304478\n",
      "train loss:0.8295995181625809\n",
      "train loss:0.9890073454152719\n",
      "train loss:0.8942385532436028\n",
      "train loss:1.0036575570037478\n",
      "train loss:0.9934960721994435\n",
      "train loss:0.8871503828094629\n",
      "train loss:0.8623141138788541\n",
      "train loss:0.8925976582234061\n",
      "train loss:0.7557636069793431\n",
      "train loss:1.0201828747602233\n",
      "train loss:0.9568014653155117\n",
      "train loss:0.812777263125701\n",
      "train loss:0.9163515204717256\n",
      "train loss:0.7258696942141013\n",
      "train loss:0.9195514405285712\n",
      "train loss:0.8726168617394033\n",
      "train loss:1.0351587021307245\n",
      "train loss:0.8113262512736124\n",
      "train loss:0.8449773479322107\n",
      "train loss:0.9515848906194249\n",
      "train loss:0.7898056309108082\n",
      "train loss:0.8346231825409499\n",
      "train loss:0.7960392097847262\n",
      "train loss:1.0147975508671199\n",
      "train loss:0.8033537049620715\n",
      "train loss:1.0022159369607246\n",
      "train loss:0.8586716635040372\n",
      "train loss:0.8321258013810874\n",
      "train loss:0.7804459038645678\n",
      "train loss:0.9619133359536524\n",
      "train loss:0.9087562708235274\n",
      "train loss:0.8976998246939837\n",
      "train loss:0.7675302152683233\n",
      "train loss:0.9501428371879516\n",
      "train loss:0.7638523479764641\n",
      "train loss:1.0038509134556242\n",
      "train loss:0.859541698903389\n",
      "train loss:0.9519332051619649\n",
      "train loss:0.8463179439749721\n",
      "train loss:0.9101188252575214\n",
      "train loss:0.9168476790477287\n",
      "train loss:0.8547353737025865\n",
      "train loss:0.971867725988418\n",
      "train loss:0.9519197010357351\n",
      "train loss:0.8600208081828717\n",
      "train loss:0.8171679291019436\n",
      "train loss:0.7780820520852905\n",
      "train loss:0.9623150820610725\n",
      "train loss:0.8735645928521876\n",
      "train loss:0.9583233503760396\n",
      "train loss:0.9809786658127407\n",
      "train loss:0.953087003294734\n",
      "train loss:1.0983720293711408\n",
      "train loss:0.8113956458458543\n",
      "train loss:0.8553239487759215\n",
      "train loss:0.7881914516183324\n",
      "train loss:0.7440055173867389\n",
      "train loss:0.8028102174164409\n",
      "train loss:1.0331069866402454\n",
      "train loss:0.8055476799757822\n",
      "train loss:0.7869887324596799\n",
      "train loss:1.0379336263057197\n",
      "train loss:0.9462802136195552\n",
      "train loss:1.0088902307609984\n",
      "train loss:0.7360937348933143\n",
      "train loss:0.9179639564631326\n",
      "train loss:0.9739890786353379\n",
      "train loss:0.9510117230595307\n",
      "train loss:0.662184377404199\n",
      "train loss:0.7359498076743384\n",
      "train loss:0.9425220202756279\n",
      "train loss:0.9530373583981683\n",
      "train loss:0.9700515417169991\n",
      "train loss:0.6323851841017142\n",
      "train loss:0.93156269105011\n",
      "train loss:0.8953445825613012\n",
      "train loss:0.6697915977354282\n",
      "train loss:0.8004905110102841\n",
      "train loss:0.9335890395096575\n",
      "train loss:1.0122818372392965\n",
      "train loss:0.9074052580206348\n",
      "train loss:0.945403081136368\n",
      "train loss:0.9152933135093317\n",
      "train loss:0.8634194688731717\n",
      "train loss:0.9782202993391753\n",
      "train loss:0.8809162167348538\n",
      "train loss:0.9241412396134551\n",
      "train loss:0.9289150727234908\n",
      "train loss:0.9229992927013976\n",
      "train loss:0.8926643340430076\n",
      "train loss:0.8371821128933834\n",
      "train loss:0.9906834086963531\n",
      "train loss:1.05520827343387\n",
      "train loss:0.822269547942081\n",
      "train loss:0.8034910143108641\n",
      "train loss:1.0012573859982754\n",
      "train loss:0.8643661412480158\n",
      "train loss:0.8838208741930056\n",
      "train loss:0.7795282149958973\n",
      "train loss:0.8143957062446464\n",
      "train loss:0.7994724379992181\n",
      "train loss:0.9247895276108803\n",
      "train loss:0.8114501726100677\n",
      "train loss:0.8548886365574961\n",
      "train loss:0.9797250747330983\n",
      "train loss:0.8282189832475488\n",
      "train loss:0.8476246654170351\n",
      "train loss:1.1199116940077762\n",
      "train loss:0.8873916261480883\n",
      "train loss:0.895195113545397\n",
      "train loss:0.9041202015518204\n",
      "train loss:0.8958619976809034\n",
      "train loss:0.904852779237466\n",
      "train loss:0.8894441107172953\n",
      "train loss:0.8472961916495548\n",
      "train loss:0.9998244522842357\n",
      "train loss:0.9016466502594682\n",
      "train loss:0.8526489813746378\n",
      "train loss:1.0533873337320918\n",
      "train loss:1.0238261160996585\n",
      "train loss:0.6821936929176321\n",
      "train loss:0.9857403238198582\n",
      "train loss:0.9310137111368225\n",
      "train loss:0.9199969440225595\n",
      "train loss:0.8797317653010852\n",
      "train loss:0.9895340174870735\n",
      "train loss:0.8920029612490916\n",
      "train loss:0.8680493482037002\n",
      "train loss:0.9362737168830723\n",
      "train loss:0.929407583759637\n",
      "train loss:1.0181426266400984\n",
      "train loss:1.0947828793750056\n",
      "train loss:0.7497474240708618\n",
      "train loss:0.9596056246899726\n",
      "train loss:0.8450368268174787\n",
      "train loss:0.9038957364739819\n",
      "train loss:0.8070091030839385\n",
      "train loss:0.9175488253853998\n",
      "train loss:0.988738211510223\n",
      "train loss:0.837117681480715\n",
      "train loss:0.8836138685603251\n",
      "train loss:0.9254245626614039\n",
      "train loss:0.9811811586182917\n",
      "train loss:0.9103390426073682\n",
      "train loss:0.7839836331454592\n",
      "train loss:0.7818255284390283\n",
      "train loss:0.8176187849772455\n",
      "train loss:0.8152588200375166\n",
      "train loss:0.9640899926430115\n",
      "train loss:0.8700163952971116\n",
      "train loss:0.9204797954993262\n",
      "train loss:1.1202574774877228\n",
      "train loss:0.8905149778670893\n",
      "train loss:0.8943630366745375\n",
      "train loss:0.8141031702350504\n",
      "train loss:0.8479598655342059\n",
      "train loss:0.9846743669635641\n",
      "train loss:0.9744453590523683\n",
      "train loss:0.769769905267531\n",
      "train loss:0.9205813927537855\n",
      "train loss:0.8275181569140176\n",
      "train loss:0.906124758411805\n",
      "train loss:0.6839168946287192\n",
      "train loss:0.9084228828268095\n",
      "train loss:0.7839080051117453\n",
      "train loss:0.9624107275900513\n",
      "train loss:0.9043101189811097\n",
      "train loss:0.8184642108176855\n",
      "train loss:0.7588471144091413\n",
      "train loss:0.7418450125011065\n",
      "train loss:0.7193763024481826\n",
      "train loss:1.0565701908306744\n",
      "train loss:0.8795977169596223\n",
      "train loss:1.0339541543762387\n",
      "train loss:0.9690576065786629\n",
      "train loss:0.9230856881486793\n",
      "train loss:0.9941314447256295\n",
      "train loss:0.9607078950818939\n",
      "train loss:0.8298163728272887\n",
      "train loss:1.0177823182722525\n",
      "train loss:1.0013946896304362\n",
      "train loss:0.8600551060466983\n",
      "train loss:0.9448726816384807\n",
      "train loss:0.8157619770162043\n",
      "train loss:1.0382814324504706\n",
      "train loss:1.0465293644656035\n",
      "train loss:0.9726773927515491\n",
      "train loss:0.9186139104623198\n",
      "train loss:0.9227969257858382\n",
      "train loss:0.8727789970714191\n",
      "train loss:0.8839583537284003\n",
      "train loss:1.0504703970359086\n",
      "train loss:0.9664998559798608\n",
      "train loss:0.891971150223186\n",
      "train loss:0.8745274760702882\n",
      "train loss:0.9817846569836419\n",
      "train loss:0.8836188066572676\n",
      "train loss:0.906961896179491\n",
      "train loss:0.9417344410895102\n",
      "train loss:0.8407555936669149\n",
      "train loss:0.9151014431727791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9375878328727352\n",
      "train loss:0.9455593087393575\n",
      "train loss:0.9051007236301406\n",
      "train loss:0.8297473523396226\n",
      "train loss:1.0117527714201957\n",
      "train loss:0.8237084105084691\n",
      "train loss:0.8599264432770498\n",
      "train loss:0.9102516112518648\n",
      "train loss:0.8757426380557688\n",
      "train loss:0.8415408545242193\n",
      "train loss:0.8918287753784742\n",
      "train loss:0.8840052682941305\n",
      "train loss:0.7793264612026397\n",
      "train loss:0.8253127806739998\n",
      "train loss:0.7010874260776118\n",
      "train loss:1.020473818617892\n",
      "train loss:0.9846923187736445\n",
      "train loss:0.9055356594124785\n",
      "train loss:0.9778478456699043\n",
      "train loss:0.9724898273615995\n",
      "train loss:0.9543345511689354\n",
      "train loss:0.9711991141798877\n",
      "train loss:0.9265962154547384\n",
      "train loss:0.9413715320478037\n",
      "train loss:0.7592028143192578\n",
      "train loss:0.9822622277652658\n",
      "train loss:0.9536874599375709\n",
      "train loss:0.8342982426569033\n",
      "train loss:0.7667808041861258\n",
      "train loss:0.8484381319463327\n",
      "train loss:0.8500098821031739\n",
      "train loss:0.9775751700957938\n",
      "train loss:0.8331849812769643\n",
      "train loss:0.8850620570606853\n",
      "train loss:0.8554129088392284\n",
      "train loss:0.9140315966519245\n",
      "train loss:0.9650370639449574\n",
      "train loss:0.9132676091966603\n",
      "train loss:0.9955990950387991\n",
      "train loss:0.9007646688839432\n",
      "train loss:0.8769349089053374\n",
      "train loss:1.0750624202378942\n",
      "train loss:0.7572535729544206\n",
      "train loss:1.1623270696376595\n",
      "train loss:0.9658953041352002\n",
      "train loss:1.030917170852337\n",
      "train loss:0.9205774771290636\n",
      "train loss:1.0461243069512367\n",
      "train loss:1.0032527015004147\n",
      "train loss:0.9172468434023314\n",
      "train loss:0.8589032809570043\n",
      "train loss:0.8766169319299959\n",
      "train loss:0.8999900034943622\n",
      "train loss:0.7166797504552934\n",
      "train loss:0.8265935643028712\n",
      "train loss:0.9731285433292486\n",
      "train loss:0.9657219652032832\n",
      "train loss:0.7743585746004653\n",
      "train loss:0.9577818612786192\n",
      "train loss:0.8522945882911247\n",
      "train loss:0.9087567122618361\n",
      "train loss:0.7697351273292261\n",
      "train loss:0.7951080881816154\n",
      "train loss:0.9169538308824078\n",
      "train loss:0.9477087069230932\n",
      "train loss:0.873748152404137\n",
      "train loss:0.8748896313783832\n",
      "train loss:0.982796112744467\n",
      "train loss:0.7695198997068965\n",
      "train loss:0.95475950028442\n",
      "train loss:0.8986096505849166\n",
      "train loss:0.8207970530768555\n",
      "train loss:0.7952210852731035\n",
      "train loss:0.9783445602975934\n",
      "train loss:0.9044452518137014\n",
      "train loss:0.9504908426442925\n",
      "train loss:0.8699970940114532\n",
      "train loss:0.9455171400662232\n",
      "train loss:0.8433434186797228\n",
      "train loss:0.8731833451657384\n",
      "train loss:0.9699049082944673\n",
      "train loss:0.8089264946421766\n",
      "train loss:0.9779531399920144\n",
      "train loss:0.98938370682082\n",
      "train loss:0.924883433075188\n",
      "train loss:0.8100153463548267\n",
      "train loss:0.6186877508010447\n",
      "train loss:1.0914635745493142\n",
      "train loss:0.8436208302053049\n",
      "train loss:0.9584884040417603\n",
      "train loss:0.9784431287723696\n",
      "train loss:0.9971177086664376\n",
      "train loss:0.8150831754554244\n",
      "train loss:0.9479273867551037\n",
      "train loss:0.9880887476690833\n",
      "train loss:0.9285975182676441\n",
      "train loss:0.9187894749294262\n",
      "train loss:1.0681554808368012\n",
      "train loss:0.9527516451438267\n",
      "train loss:0.8994452634361513\n",
      "train loss:0.9363113495795689\n",
      "train loss:0.8320933026570232\n",
      "train loss:0.8311654094115174\n",
      "train loss:0.8297565895808141\n",
      "train loss:0.919977054651944\n",
      "train loss:1.033736766183109\n",
      "train loss:1.0219045625346663\n",
      "train loss:0.9823510645041122\n",
      "train loss:0.8207539837101013\n",
      "train loss:1.0533666215441297\n",
      "train loss:0.9434094627506089\n",
      "train loss:0.9562379314547453\n",
      "train loss:0.9198854277437172\n",
      "train loss:0.8535817425511415\n",
      "train loss:0.9177670371534435\n",
      "train loss:0.9137593986572561\n",
      "train loss:1.049574904449341\n",
      "train loss:0.9738961594001512\n",
      "train loss:0.9356155214364713\n",
      "train loss:1.0810620633413337\n",
      "train loss:0.9398833886825857\n",
      "train loss:0.9608244679496782\n",
      "train loss:0.8161505127175046\n",
      "train loss:0.9171446747436295\n",
      "train loss:0.8219938938791853\n",
      "train loss:0.9368740865623879\n",
      "train loss:0.8586327085357659\n",
      "train loss:0.9423282981737958\n",
      "train loss:0.9797903950154334\n",
      "train loss:0.8964599821511666\n",
      "train loss:1.0288989549402572\n",
      "train loss:1.0594245445836465\n",
      "train loss:0.8896810996036284\n",
      "train loss:0.8385187833829013\n",
      "train loss:0.7334652231996798\n",
      "train loss:0.9361674903068729\n",
      "train loss:0.8165488849761309\n",
      "train loss:1.0608644251494028\n",
      "train loss:0.8820175740262026\n",
      "train loss:0.9244588737607883\n",
      "train loss:0.8665689785061284\n",
      "train loss:0.9293041793187524\n",
      "train loss:0.8784890398774432\n",
      "train loss:0.8946160449193873\n",
      "train loss:0.8851001484654362\n",
      "train loss:0.8296155257611219\n",
      "train loss:0.9367666454915238\n",
      "train loss:0.7851449643709416\n",
      "train loss:0.8899047000638767\n",
      "train loss:0.881415901304823\n",
      "train loss:1.0765543602618002\n",
      "train loss:0.9421484264905524\n",
      "train loss:0.8684262741930175\n",
      "train loss:0.9391058106543099\n",
      "train loss:0.7736249769530175\n",
      "train loss:0.8910421413159265\n",
      "train loss:0.8720108882930266\n",
      "train loss:0.955726471994161\n",
      "train loss:0.8949531292895372\n",
      "train loss:0.8864983175373105\n",
      "train loss:0.868029894578394\n",
      "train loss:0.8966566062424904\n",
      "train loss:0.8878866352308843\n",
      "train loss:0.7557657281596073\n",
      "train loss:0.9084234709489106\n",
      "train loss:0.8297570458128493\n",
      "train loss:0.8241878326678658\n",
      "train loss:1.105040202547067\n",
      "train loss:0.8226015002333676\n",
      "train loss:0.9209678022085555\n",
      "train loss:0.8041597159634639\n",
      "train loss:0.8274160442083943\n",
      "train loss:0.8471196384203529\n",
      "train loss:0.9246956714232177\n",
      "train loss:0.7432895744384856\n",
      "train loss:1.1176560343343604\n",
      "train loss:1.002294321655822\n",
      "train loss:1.027867223208325\n",
      "train loss:0.7250080253470955\n",
      "train loss:0.8343850484576356\n",
      "train loss:0.8943136255092594\n",
      "train loss:0.9024485577610829\n",
      "train loss:0.8052277090490493\n",
      "train loss:0.8120004131698874\n",
      "train loss:0.8903699975057164\n",
      "train loss:0.749640459518802\n",
      "train loss:0.9524018178568967\n",
      "train loss:0.9350475203733152\n",
      "train loss:0.9608591493129623\n",
      "train loss:0.9851331374914344\n",
      "train loss:1.0113188254722376\n",
      "train loss:0.8175720025028855\n",
      "train loss:0.9495014453303334\n",
      "train loss:0.9831997514171613\n",
      "train loss:0.7777222182326706\n",
      "train loss:0.915406553872455\n",
      "train loss:0.741317821325411\n",
      "train loss:0.7031552344246522\n",
      "train loss:0.7486811309754775\n",
      "train loss:0.9248865538444382\n",
      "train loss:0.9192078988652201\n",
      "train loss:1.0033569966556597\n",
      "train loss:0.9765247108133768\n",
      "train loss:0.8370226980084419\n",
      "train loss:0.8590999994462315\n",
      "train loss:0.8321251138737678\n",
      "train loss:0.9821793060461218\n",
      "train loss:0.8634746417349385\n",
      "train loss:0.8004335881245944\n",
      "train loss:0.9155233124442852\n",
      "train loss:0.8372627410163969\n",
      "train loss:0.8453016043156899\n",
      "train loss:0.9982417616649188\n",
      "train loss:0.8670593040018235\n",
      "train loss:0.9054003698234132\n",
      "train loss:0.8851264990636446\n",
      "train loss:1.0230164652441898\n",
      "train loss:1.0021140420809844\n",
      "train loss:1.0456765873083753\n",
      "train loss:0.8859112453462121\n",
      "train loss:0.8140654157492595\n",
      "train loss:0.8435896752663286\n",
      "train loss:0.8678149417549816\n",
      "train loss:0.8618073015809705\n",
      "train loss:0.9334583544087682\n",
      "train loss:0.9163428943785048\n",
      "train loss:0.8606434198773409\n",
      "train loss:0.7894837662219609\n",
      "train loss:0.8493467393423174\n",
      "train loss:0.8758466680904278\n",
      "train loss:1.0023667850763174\n",
      "train loss:0.8345675134590911\n",
      "train loss:0.8658011055891968\n",
      "train loss:0.9296392596349093\n",
      "train loss:0.6627053349496486\n",
      "train loss:0.9139163394581069\n",
      "train loss:0.9796298270780663\n",
      "train loss:0.9506159048829675\n",
      "train loss:0.8992517691610168\n",
      "train loss:0.9674352193099227\n",
      "train loss:0.8024659205239955\n",
      "train loss:1.0602443389683083\n",
      "train loss:0.9007013178018651\n",
      "train loss:0.8871071603267324\n",
      "train loss:0.9896350719094944\n",
      "train loss:0.957547539938388\n",
      "train loss:0.9883415091022241\n",
      "train loss:0.9861684381801714\n",
      "train loss:0.9791250194543569\n",
      "train loss:1.0011939842700377\n",
      "train loss:0.9274819721610811\n",
      "train loss:0.9241014928904935\n",
      "train loss:0.8754084927280793\n",
      "train loss:0.8964368970197788\n",
      "train loss:0.9812959179174938\n",
      "train loss:0.7706967054789434\n",
      "train loss:0.8475713403824031\n",
      "train loss:0.9672841394549553\n",
      "train loss:0.8705611124207755\n",
      "train loss:0.9929144219735108\n",
      "train loss:0.8683242982381452\n",
      "train loss:0.9040533228211067\n",
      "train loss:0.9951464829649548\n",
      "train loss:0.9831467648293565\n",
      "train loss:0.7913376684091257\n",
      "train loss:0.7863894130124899\n",
      "train loss:0.9062812903799969\n",
      "train loss:0.8439692516612186\n",
      "train loss:0.990425231942115\n",
      "train loss:0.8577625364320087\n",
      "train loss:0.9818564176247149\n",
      "train loss:1.1065505553280648\n",
      "train loss:0.9694662683385613\n",
      "train loss:1.0153396242285857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9902260352418485\n",
      "train loss:0.8595837104702214\n",
      "train loss:0.9608334767872485\n",
      "train loss:0.9897013810751661\n",
      "train loss:0.7366224704647815\n",
      "train loss:1.0823651173544548\n",
      "train loss:0.8265001787515045\n",
      "train loss:0.9635451227379863\n",
      "train loss:0.7608089539679629\n",
      "train loss:0.885888216429964\n",
      "train loss:1.0166597695742996\n",
      "train loss:0.9178572874470089\n",
      "train loss:0.9889533548660719\n",
      "train loss:0.7552811466748767\n",
      "train loss:0.8724498485006942\n",
      "train loss:0.8583778364385195\n",
      "=== epoch:12, train acc:0.995, test acc:0.987 ===\n",
      "train loss:0.8042534221514884\n",
      "train loss:0.9333769536019512\n",
      "train loss:0.7149137114891522\n",
      "train loss:0.682397653498292\n",
      "train loss:0.903330513561793\n",
      "train loss:1.1356100556458604\n",
      "train loss:0.9706006223702269\n",
      "train loss:0.7428341328834963\n",
      "train loss:0.7967311525422409\n",
      "train loss:0.9207243754006592\n",
      "train loss:0.7492671224139462\n",
      "train loss:0.911397648255866\n",
      "train loss:1.0309848160671307\n",
      "train loss:0.8005869630063781\n",
      "train loss:0.8859180390850413\n",
      "train loss:0.9268230657930807\n",
      "train loss:0.8961361830412062\n",
      "train loss:0.9836455669430408\n",
      "train loss:0.9193269167953679\n",
      "train loss:0.9049761547394639\n",
      "train loss:1.006943341953209\n",
      "train loss:0.7671616147674476\n",
      "train loss:0.7781355897783135\n",
      "train loss:0.875433597594015\n",
      "train loss:0.9674900209666143\n",
      "train loss:0.9357846815141163\n",
      "train loss:0.8355400086160886\n",
      "train loss:0.9545616080643533\n",
      "train loss:0.9540898010295582\n",
      "train loss:0.8665246941319574\n",
      "train loss:0.8265912231488577\n",
      "train loss:0.7816734696242871\n",
      "train loss:0.8456659074877235\n",
      "train loss:0.8531253042314407\n",
      "train loss:0.9851881542334024\n",
      "train loss:0.9212256707637357\n",
      "train loss:0.9245811213664215\n",
      "train loss:0.9652129537516169\n",
      "train loss:0.949878846096085\n",
      "train loss:0.8704271161010219\n",
      "train loss:0.9983670847857243\n",
      "train loss:0.745409383993321\n",
      "train loss:0.9072044655812895\n",
      "train loss:0.8648151540452993\n",
      "train loss:0.9105739037484595\n",
      "train loss:1.0929183191611167\n",
      "train loss:0.7525835431314478\n",
      "train loss:0.9394992092346766\n",
      "train loss:0.9189507217552122\n",
      "train loss:0.9145407821654721\n",
      "train loss:0.8884280054394842\n",
      "train loss:0.9977502886933397\n",
      "train loss:0.8981840763790848\n",
      "train loss:1.1153508424668912\n",
      "train loss:1.0246434851347244\n",
      "train loss:0.9403452797801564\n",
      "train loss:0.9629784762601833\n",
      "train loss:0.9804148098229284\n",
      "train loss:0.8909909667430049\n",
      "train loss:1.0140934005885238\n",
      "train loss:0.8174743521453743\n",
      "train loss:0.8499373791858028\n",
      "train loss:0.8588826048272803\n",
      "train loss:0.8997729702542379\n",
      "train loss:0.8450137399099316\n",
      "train loss:0.8303531813874747\n",
      "train loss:1.033944986127253\n",
      "train loss:0.8298276327175135\n",
      "train loss:0.8462003106290266\n",
      "train loss:0.8937793348248474\n",
      "train loss:0.9106396140317834\n",
      "train loss:0.9748741959378558\n",
      "train loss:0.978780780835614\n",
      "train loss:0.7947911242115508\n",
      "train loss:0.9234320547091757\n",
      "train loss:0.815401729102396\n",
      "train loss:0.7976151756389663\n",
      "train loss:0.7847435810110948\n",
      "train loss:0.8709959865597118\n",
      "train loss:0.8415197202203559\n",
      "train loss:1.0358267158601422\n",
      "train loss:0.8414977421300204\n",
      "train loss:0.8825526046780824\n",
      "train loss:0.9135459693489665\n",
      "train loss:1.0299105293178275\n",
      "train loss:1.1216690394975655\n",
      "train loss:0.9758275568772126\n",
      "train loss:0.8355998742918969\n",
      "train loss:0.8140251500214126\n",
      "train loss:0.9712437133457328\n",
      "train loss:0.9074889336603786\n",
      "train loss:0.9251251847468498\n",
      "train loss:0.9163810315093751\n",
      "train loss:0.8589278614864783\n",
      "train loss:0.9150618179033876\n",
      "train loss:0.7484063653613865\n",
      "train loss:0.9632742305003217\n",
      "train loss:1.0748504956688643\n",
      "train loss:1.0738631520541297\n",
      "train loss:0.8077490152165345\n",
      "train loss:0.9850174475920319\n",
      "train loss:0.8986442727769908\n",
      "train loss:0.9218916693477552\n",
      "train loss:0.9364657274557419\n",
      "train loss:0.9367450395100267\n",
      "train loss:0.9108224567839478\n",
      "train loss:0.9756472055742164\n",
      "train loss:1.086222451362287\n",
      "train loss:0.7683915850486355\n",
      "train loss:0.8720561297229694\n",
      "train loss:0.7992518992483569\n",
      "train loss:1.007994785724504\n",
      "train loss:0.8162213202454953\n",
      "train loss:0.7298030481260105\n",
      "train loss:0.9146170284715147\n",
      "train loss:0.9051424473698395\n",
      "train loss:0.8164871687966785\n",
      "train loss:0.8923384912862626\n",
      "train loss:0.8802000615333437\n",
      "train loss:0.9048181566479516\n",
      "train loss:0.6617117412198306\n",
      "train loss:0.859873835833775\n",
      "train loss:0.9195726801999554\n",
      "train loss:0.8718058054800819\n",
      "train loss:0.7419103569623092\n",
      "train loss:0.7062107634589032\n",
      "train loss:0.6896966875109589\n",
      "train loss:0.8094535463664276\n",
      "train loss:0.9521539137593991\n",
      "train loss:0.9780786085424108\n",
      "train loss:0.8624027308980096\n",
      "train loss:0.8287811351473726\n",
      "train loss:0.759265359516554\n",
      "train loss:1.0023570926426197\n",
      "train loss:0.8621300987271715\n",
      "train loss:0.8803725905362447\n",
      "train loss:1.0153935162699832\n",
      "train loss:0.862102697713091\n",
      "train loss:0.9514463280705107\n",
      "train loss:0.8583383076593768\n",
      "train loss:0.9089764889699522\n",
      "train loss:1.024546561551038\n",
      "train loss:0.9389935122029772\n",
      "train loss:1.0781613003870898\n",
      "train loss:0.833122848327698\n",
      "train loss:0.7745011548565581\n",
      "train loss:1.0985982877998937\n",
      "train loss:0.9037172953497631\n",
      "train loss:1.0174492635341625\n",
      "train loss:0.929291531634272\n",
      "train loss:1.0465641608633773\n",
      "train loss:1.0269057499665515\n",
      "train loss:0.9718223328898564\n",
      "train loss:0.854263856643489\n",
      "train loss:0.9485879799513703\n",
      "train loss:0.8706703011885137\n",
      "train loss:0.8672050823229118\n",
      "train loss:0.9552201563962425\n",
      "train loss:0.8044315214420001\n",
      "train loss:0.7964176576157367\n",
      "train loss:0.9949867401800689\n",
      "train loss:1.029261587089982\n",
      "train loss:0.8638998519043476\n",
      "train loss:1.0422690545021167\n",
      "train loss:0.8363267235946168\n",
      "train loss:0.9063894156343388\n",
      "train loss:1.0310361667691357\n",
      "train loss:0.8318266038674973\n",
      "train loss:0.865908603981629\n",
      "train loss:0.8452301939295382\n",
      "train loss:1.0021504473337102\n",
      "train loss:1.0087755573319015\n",
      "train loss:0.8215313382946142\n",
      "train loss:0.8669354625193079\n",
      "train loss:0.780808641733165\n",
      "train loss:0.770026386252942\n",
      "train loss:0.8434128513242917\n",
      "train loss:0.9485308911504126\n",
      "train loss:0.9162930236970653\n",
      "train loss:0.9319462436002378\n",
      "train loss:0.8327149522672775\n",
      "train loss:0.7805851585073106\n",
      "train loss:0.9492351077746101\n",
      "train loss:0.8393148881339489\n",
      "train loss:0.8353634328889621\n",
      "train loss:0.8574202220118771\n",
      "train loss:1.116931111866913\n",
      "train loss:0.8956498626310142\n",
      "train loss:0.8374067017247013\n",
      "train loss:0.9151122127882045\n",
      "train loss:0.7815121983062565\n",
      "train loss:1.0355109394034834\n",
      "train loss:0.8299446128081535\n",
      "train loss:0.8249072753004271\n",
      "train loss:0.9122474879200437\n",
      "train loss:0.8317888264790916\n",
      "train loss:0.8210699217095458\n",
      "train loss:0.9284520449365021\n",
      "train loss:1.0151730858778787\n",
      "train loss:1.063035014819492\n",
      "train loss:0.9570566028120535\n",
      "train loss:0.8294072571915839\n",
      "train loss:0.9400014938027295\n",
      "train loss:0.8584911907439822\n",
      "train loss:0.6745722860239369\n",
      "train loss:1.1135368544510094\n",
      "train loss:0.8346306591384584\n",
      "train loss:0.8544272591232789\n",
      "train loss:0.7394427999981775\n",
      "train loss:0.8186691838678395\n",
      "train loss:0.9426614390282895\n",
      "train loss:0.8919784225181923\n",
      "train loss:0.9147495683958559\n",
      "train loss:0.9112670874849931\n",
      "train loss:0.9198543496035583\n",
      "train loss:0.9065225153587981\n",
      "train loss:0.8283165109020532\n",
      "train loss:0.919007979148848\n",
      "train loss:0.8982005231716661\n",
      "train loss:0.9103915287188742\n",
      "train loss:0.7919246262068161\n",
      "train loss:0.8824525700596161\n",
      "train loss:0.9411580325628423\n",
      "train loss:0.9190067443448063\n",
      "train loss:0.8299538334586545\n",
      "train loss:0.8715530498322528\n",
      "train loss:0.9219333578013571\n",
      "train loss:0.919524551820318\n",
      "train loss:0.8672569685677388\n",
      "train loss:0.9257667679426064\n",
      "train loss:0.7539706515724302\n",
      "train loss:0.7790911290249548\n",
      "train loss:0.9383272107958784\n",
      "train loss:0.874265580658937\n",
      "train loss:0.8775938095278866\n",
      "train loss:1.0202542561259704\n",
      "train loss:0.8815207548584335\n",
      "train loss:1.0918112016364496\n",
      "train loss:0.9125201687761104\n",
      "train loss:1.0961221688712492\n",
      "train loss:0.9197785453028061\n",
      "train loss:0.8903315303080348\n",
      "train loss:0.7551810686120358\n",
      "train loss:0.7432935669890949\n",
      "train loss:1.113256863987733\n",
      "train loss:0.9655147911607284\n",
      "train loss:0.8167870955791802\n",
      "train loss:0.7209410455765898\n",
      "train loss:0.8429045675959697\n",
      "train loss:0.9917397507164009\n",
      "train loss:1.0316243952275672\n",
      "train loss:0.9155537015722834\n",
      "train loss:0.8574512926185222\n",
      "train loss:0.9771762587660378\n",
      "train loss:0.8793969340611717\n",
      "train loss:0.9069594367883866\n",
      "train loss:0.886234817675324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8131263054384654\n",
      "train loss:0.8150273644536697\n",
      "train loss:0.80204257669489\n",
      "train loss:1.0125492410570873\n",
      "train loss:0.8384876280329705\n",
      "train loss:0.9678823014396781\n",
      "train loss:0.9013129932357679\n",
      "train loss:0.9246899068290924\n",
      "train loss:0.9033479793296556\n",
      "train loss:0.8810037130640729\n",
      "train loss:0.9522079089870042\n",
      "train loss:0.732801103527429\n",
      "train loss:0.9543139181050267\n",
      "train loss:0.9381918217251632\n",
      "train loss:0.8926580378147364\n",
      "train loss:0.9686884196832162\n",
      "train loss:1.0389326307904714\n",
      "train loss:0.9763265138602409\n",
      "train loss:0.8722979786013321\n",
      "train loss:0.8067493812495619\n",
      "train loss:0.7773711259870771\n",
      "train loss:0.843019295801938\n",
      "train loss:1.0057593517872727\n",
      "train loss:0.7394335683028095\n",
      "train loss:1.0948809967739233\n",
      "train loss:0.9824265299956637\n",
      "train loss:0.88468437229606\n",
      "train loss:0.914890950029448\n",
      "train loss:0.8851366195898182\n",
      "train loss:1.0641842439953628\n",
      "train loss:0.8890528231722644\n",
      "train loss:0.9803493360775575\n",
      "train loss:0.9971879432551815\n",
      "train loss:0.9789031102847567\n",
      "train loss:0.9534695994411632\n",
      "train loss:0.8751017488736444\n",
      "train loss:1.0056327527929125\n",
      "train loss:0.8767386070274331\n",
      "train loss:0.8948875107666381\n",
      "train loss:0.8079297356704191\n",
      "train loss:0.8376384914839745\n",
      "train loss:0.8527649513536395\n",
      "train loss:0.9021098209831543\n",
      "train loss:0.8681600727515907\n",
      "train loss:0.9928982153951194\n",
      "train loss:0.9358999804882102\n",
      "train loss:1.0159206877995814\n",
      "train loss:1.0244892771264602\n",
      "train loss:1.0503566692369501\n",
      "train loss:1.1251280704180253\n",
      "train loss:0.8899533051902823\n",
      "train loss:0.8262407598747408\n",
      "train loss:0.8211538855861966\n",
      "train loss:0.9146109643720028\n",
      "train loss:0.7942498558691475\n",
      "train loss:1.0353629179870714\n",
      "train loss:0.9198465572949344\n",
      "train loss:0.9516452008419101\n",
      "train loss:0.7897253505917844\n",
      "train loss:0.8810781114806281\n",
      "train loss:1.014885433101623\n",
      "train loss:0.8722905514507359\n",
      "train loss:0.930625390199264\n",
      "train loss:0.9900740467333187\n",
      "train loss:0.8052007331660838\n",
      "train loss:0.8345002737320337\n",
      "train loss:0.9046278874351237\n",
      "train loss:0.8450297826628586\n",
      "train loss:0.9546812672025272\n",
      "train loss:0.9818224820820788\n",
      "train loss:0.9784340546354037\n",
      "train loss:0.7811935804944539\n",
      "train loss:0.7599299992574428\n",
      "train loss:0.7041657613356413\n",
      "train loss:0.83658433781095\n",
      "train loss:0.8990001933752143\n",
      "train loss:1.0047599880458955\n",
      "train loss:0.9190003129878367\n",
      "train loss:1.067562718729577\n",
      "train loss:1.1273010175013989\n",
      "train loss:1.0243841842731636\n",
      "train loss:1.2886099650023173\n",
      "train loss:0.76269523477986\n",
      "train loss:0.8110040392309386\n",
      "train loss:0.957028624081959\n",
      "train loss:0.9965347819096201\n",
      "train loss:0.8300977601094853\n",
      "train loss:0.8872683818486038\n",
      "train loss:0.788692930439907\n",
      "train loss:0.9448585268383338\n",
      "train loss:0.8629514346513568\n",
      "train loss:0.9287676399896285\n",
      "train loss:0.7719471940599197\n",
      "train loss:0.9865908076301251\n",
      "train loss:0.7864355204335887\n",
      "train loss:1.0363942800814145\n",
      "train loss:0.7816676863999196\n",
      "train loss:1.0509480888122913\n",
      "train loss:0.8279232794555392\n",
      "train loss:0.7439916951155482\n",
      "train loss:0.8844406496572438\n",
      "train loss:0.8959873593540547\n",
      "train loss:0.879706826234159\n",
      "train loss:1.0911538713180258\n",
      "train loss:0.8386176363147768\n",
      "train loss:1.096035094012436\n",
      "train loss:0.7466791612041921\n",
      "train loss:0.9348397012790737\n",
      "train loss:0.9557915265425437\n",
      "train loss:0.8743676893160169\n",
      "train loss:0.9866203989139806\n",
      "train loss:0.8946277457744277\n",
      "train loss:0.9626774006379603\n",
      "train loss:0.971352540947254\n",
      "train loss:0.8624661539277392\n",
      "train loss:0.8787317687066175\n",
      "train loss:1.0116867059180448\n",
      "train loss:0.8709468450052184\n",
      "train loss:0.9534858188758113\n",
      "train loss:0.9172445881560715\n",
      "train loss:0.885530740074106\n",
      "train loss:0.7558768424013702\n",
      "train loss:0.8125049419500837\n",
      "train loss:1.0535901070236133\n",
      "train loss:0.894801762705269\n",
      "train loss:0.8420592648365292\n",
      "train loss:0.9144843192603317\n",
      "train loss:0.9244260616693115\n",
      "train loss:0.6579209915747526\n",
      "train loss:0.9818898484476165\n",
      "train loss:0.8978074035648966\n",
      "train loss:0.7189501226627385\n",
      "train loss:0.9682332935809655\n",
      "train loss:0.8827445542601505\n",
      "train loss:1.0314457637131162\n",
      "train loss:1.0228008450756423\n",
      "train loss:0.8436207516603862\n",
      "train loss:0.8707483284486445\n",
      "train loss:0.9211813871983492\n",
      "train loss:1.0139591108138117\n",
      "train loss:0.8204925640908195\n",
      "train loss:0.9334094823322975\n",
      "train loss:1.0607923413906988\n",
      "train loss:0.8401724776875035\n",
      "train loss:0.8547788617880083\n",
      "train loss:1.0899820633644155\n",
      "train loss:0.8721096565812015\n",
      "train loss:0.9512583595189774\n",
      "train loss:0.8448172953864177\n",
      "train loss:0.9173736869975871\n",
      "train loss:0.8394320079313549\n",
      "train loss:0.9709571915876128\n",
      "train loss:0.835862395506691\n",
      "train loss:0.8306148248195458\n",
      "train loss:0.8753595680257104\n",
      "train loss:0.7943843665779232\n",
      "train loss:1.1006110410610157\n",
      "train loss:0.8998423719326348\n",
      "train loss:0.9905727612603199\n",
      "train loss:1.0182593985225337\n",
      "train loss:0.9458204783150329\n",
      "train loss:0.9232610324969214\n",
      "train loss:0.9244674597253685\n",
      "train loss:0.8811709368467802\n",
      "train loss:0.9930880266439356\n",
      "train loss:0.8296755476138675\n",
      "train loss:0.8701915957965417\n",
      "train loss:0.7919271094487901\n",
      "train loss:0.8974882319251605\n",
      "train loss:0.8431352516878414\n",
      "train loss:0.8427164592550622\n",
      "train loss:0.9644761643429355\n",
      "train loss:1.0004507581066024\n",
      "train loss:0.8520447168346439\n",
      "train loss:0.88171605930155\n",
      "train loss:1.024061222487414\n",
      "train loss:1.1169632258919895\n",
      "train loss:0.7373670085463057\n",
      "train loss:1.0299451849664478\n",
      "train loss:0.9213554720118527\n",
      "train loss:0.7523675694387773\n",
      "train loss:0.9332855180241458\n",
      "train loss:0.8356155171301589\n",
      "train loss:0.8300579830547696\n",
      "train loss:0.7513954391593595\n",
      "train loss:0.8556756996528437\n",
      "train loss:0.988093516680588\n",
      "train loss:0.8852373940450364\n",
      "train loss:0.8004578781968044\n",
      "train loss:0.9131099433247458\n",
      "train loss:0.7050741289530322\n",
      "train loss:0.8110698543144711\n",
      "train loss:0.8762786095758198\n",
      "train loss:0.7049950368385859\n",
      "train loss:0.9231156231951645\n",
      "train loss:0.7352040047346803\n",
      "train loss:0.9250659891129572\n",
      "train loss:0.9268393407592673\n",
      "train loss:0.8927584997510611\n",
      "train loss:1.0144522823558748\n",
      "train loss:0.8774279813828989\n",
      "train loss:0.9948721619505784\n",
      "train loss:0.8039425859356154\n",
      "train loss:0.8258700970314707\n",
      "train loss:0.8334464157295133\n",
      "train loss:0.8507058342042637\n",
      "train loss:0.7728888660245397\n",
      "train loss:0.9789077415613611\n",
      "train loss:0.9881878296931714\n",
      "train loss:1.0156875676957646\n",
      "train loss:0.8684612301970845\n",
      "train loss:0.7578739225522112\n",
      "train loss:0.814968085870104\n",
      "train loss:0.7343850935257215\n",
      "train loss:0.883075208934023\n",
      "train loss:0.7227416745819554\n",
      "train loss:1.0000127375857435\n",
      "train loss:0.8932205701095932\n",
      "train loss:0.9835600753548179\n",
      "train loss:0.8233165455993011\n",
      "train loss:0.8755498929823122\n",
      "train loss:0.8828949145477831\n",
      "train loss:0.8491762245524391\n",
      "train loss:0.9462621276667075\n",
      "train loss:0.8903785118107715\n",
      "train loss:0.8024610314984821\n",
      "train loss:0.855486300773748\n",
      "train loss:0.9527567585295833\n",
      "train loss:1.0619356526716408\n",
      "train loss:1.0778935798177476\n",
      "train loss:0.9202819710729793\n",
      "train loss:0.880635119267706\n",
      "train loss:0.9754413652844892\n",
      "train loss:0.8573408556147684\n",
      "train loss:0.8718393897958387\n",
      "train loss:0.8247695793494811\n",
      "train loss:0.8453492668406263\n",
      "train loss:0.9959590964781054\n",
      "train loss:0.7671603630225989\n",
      "train loss:0.9598241943755136\n",
      "train loss:0.904686622025646\n",
      "train loss:1.0035229885445847\n",
      "train loss:0.8314559056979947\n",
      "train loss:0.9019676935503808\n",
      "train loss:0.9125138554365152\n",
      "train loss:0.8770959040376973\n",
      "train loss:0.8562031453521558\n",
      "train loss:0.8687838656956975\n",
      "train loss:0.9113214344023427\n",
      "train loss:0.820787877879293\n",
      "train loss:1.0142645033547493\n",
      "train loss:1.0274093194580478\n",
      "train loss:1.0217225350090144\n",
      "train loss:0.9720755078576366\n",
      "train loss:0.8239531233309902\n",
      "train loss:0.8708382632473588\n",
      "train loss:0.8903519546852113\n",
      "train loss:0.8340301127213705\n",
      "train loss:0.894942217500562\n",
      "train loss:0.8577387594501447\n",
      "train loss:0.7670077404304623\n",
      "train loss:0.9808961637252845\n",
      "train loss:0.8649648425168813\n",
      "train loss:0.9107293606138072\n",
      "train loss:0.7906644058692733\n",
      "train loss:0.9832192629390539\n",
      "train loss:0.8188445078079444\n",
      "train loss:0.9155660237492684\n",
      "train loss:1.0128766685418389\n",
      "train loss:0.9080400928109547\n",
      "train loss:0.9428209460696099\n",
      "train loss:0.9027266457984626\n",
      "train loss:0.8795081868735285\n",
      "train loss:0.9907153757679948\n",
      "train loss:0.8553970823186335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8337943334790979\n",
      "train loss:0.9856693347030061\n",
      "train loss:0.9220289269491099\n",
      "train loss:0.8454313051471922\n",
      "train loss:0.748385909403338\n",
      "train loss:0.7893867240583488\n",
      "train loss:1.0645712212541072\n",
      "train loss:0.8079149415086196\n",
      "train loss:0.9663696196313626\n",
      "train loss:0.8859959161078591\n",
      "train loss:1.0318722162575724\n",
      "train loss:0.7362499354685177\n",
      "train loss:0.9044596344724495\n",
      "train loss:1.0420645928367411\n",
      "train loss:0.9103356482370119\n",
      "train loss:0.9143344795950267\n",
      "train loss:0.9369049780563864\n",
      "train loss:0.972603520683709\n",
      "train loss:0.8742657481167143\n",
      "train loss:0.9556829692098897\n",
      "train loss:0.8800084124256693\n",
      "train loss:0.8949003717162013\n",
      "train loss:0.7641845658246216\n",
      "train loss:0.9271914449025198\n",
      "train loss:0.916252889132125\n",
      "train loss:0.9449584523762354\n",
      "train loss:0.9649200227938459\n",
      "train loss:0.8379740321709821\n",
      "train loss:0.8428129854991129\n",
      "train loss:0.8806853444493997\n",
      "train loss:0.8610817208405086\n",
      "train loss:0.8358397821620933\n",
      "train loss:1.008568364383431\n",
      "train loss:0.866822800763373\n",
      "train loss:1.0393311295232635\n",
      "train loss:0.7342139120124836\n",
      "train loss:0.8790616869935658\n",
      "train loss:0.8130879916412862\n",
      "train loss:0.9651785412457364\n",
      "train loss:0.9848556201390852\n",
      "train loss:0.7176149394473487\n",
      "train loss:1.0899753168367154\n",
      "train loss:0.8506672447692105\n",
      "train loss:0.9424015655108734\n",
      "train loss:0.9100218402056148\n",
      "train loss:0.9210040449296183\n",
      "train loss:0.8280842593626992\n",
      "train loss:1.0045355459474166\n",
      "train loss:0.8850376560218836\n",
      "train loss:0.9141455841456861\n",
      "train loss:0.9336002201542987\n",
      "train loss:0.9746313652971759\n",
      "train loss:0.8450772434270089\n",
      "train loss:0.9870279949514129\n",
      "train loss:1.007730352866167\n",
      "train loss:0.76990521537301\n",
      "train loss:0.9246691803424524\n",
      "train loss:0.7976508872168039\n",
      "train loss:0.8418692225235322\n",
      "train loss:0.9678774434870937\n",
      "train loss:0.8316394027396149\n",
      "train loss:0.88878598340463\n",
      "train loss:0.9166391004284015\n",
      "train loss:0.8286048628456139\n",
      "train loss:0.655079486728932\n",
      "train loss:0.8256801838465421\n",
      "train loss:1.0926382547964522\n",
      "train loss:1.0454611437569534\n",
      "=== epoch:13, train acc:0.998, test acc:0.992 ===\n",
      "train loss:0.9474803895846101\n",
      "train loss:0.8581794716343762\n",
      "train loss:0.9288549832446721\n",
      "train loss:0.9644048653126428\n",
      "train loss:0.8836206185474812\n",
      "train loss:0.9053430431616735\n",
      "train loss:1.051319490838709\n",
      "train loss:0.8200809221041819\n",
      "train loss:0.802471493140574\n",
      "train loss:0.8816372232626105\n",
      "train loss:0.883447934523257\n",
      "train loss:0.9611891668157939\n",
      "train loss:1.0330313257669015\n",
      "train loss:0.8387533363200599\n",
      "train loss:0.9531076728231715\n",
      "train loss:0.8858663487425119\n",
      "train loss:0.9654756884309971\n",
      "train loss:0.8602349414865931\n",
      "train loss:0.7502527511554223\n",
      "train loss:0.9041572326161412\n",
      "train loss:0.954658393451784\n",
      "train loss:0.9770122527479376\n",
      "train loss:0.9038952009089042\n",
      "train loss:0.9338478766449321\n",
      "train loss:0.9868465021942084\n",
      "train loss:0.9674397577945762\n",
      "train loss:0.9563297631164405\n",
      "train loss:0.8215851339546794\n",
      "train loss:0.9380108525098286\n",
      "train loss:0.9221640301864729\n",
      "train loss:0.9324476639351179\n",
      "train loss:1.0327759466630333\n",
      "train loss:0.9942910896908721\n",
      "train loss:1.0975896996809147\n",
      "train loss:0.8600064943971796\n",
      "train loss:0.9757139870649545\n",
      "train loss:0.9034056565541025\n",
      "train loss:0.8978584047438267\n",
      "train loss:0.9191814678897695\n",
      "train loss:0.7403209407527696\n",
      "train loss:0.8366750844546879\n",
      "train loss:0.8712228139268159\n",
      "train loss:0.8273564235356781\n",
      "train loss:0.909250046218985\n",
      "train loss:0.9654724336003419\n",
      "train loss:0.7908156247101534\n",
      "train loss:0.8387033688689073\n",
      "train loss:1.079620228914166\n",
      "train loss:0.8048690516683698\n",
      "train loss:0.8656930897174386\n",
      "train loss:0.8188681167590475\n",
      "train loss:0.8864471545171694\n",
      "train loss:0.8055049046192557\n",
      "train loss:0.7875290230139023\n",
      "train loss:0.9485527886444431\n",
      "train loss:0.893132970692717\n",
      "train loss:0.8160556491924639\n",
      "train loss:0.8789063729148461\n",
      "train loss:0.865779669738849\n",
      "train loss:0.9702201915663927\n",
      "train loss:0.8888187312698663\n",
      "train loss:0.8509804423575182\n",
      "train loss:0.7687575087248166\n",
      "train loss:0.8508047786470344\n",
      "train loss:0.91661810897606\n",
      "train loss:0.8385706600561353\n",
      "train loss:0.9152698163147782\n",
      "train loss:1.0190607365466535\n",
      "train loss:0.7892910873536537\n",
      "train loss:0.7581745803716909\n",
      "train loss:0.8149923482716847\n",
      "train loss:0.921785127503547\n",
      "train loss:0.9268690414471203\n",
      "train loss:0.8742412134100513\n",
      "train loss:0.932600475256086\n",
      "train loss:0.9022758960947683\n",
      "train loss:1.0143098195535296\n",
      "train loss:0.9289788127409172\n",
      "train loss:0.7866056254369499\n",
      "train loss:0.9454867775515001\n",
      "train loss:0.9465134951839187\n",
      "train loss:0.7865428714814819\n",
      "train loss:1.0851428981397262\n",
      "train loss:0.8268338401839637\n",
      "train loss:0.835762045003009\n",
      "train loss:0.9269705524754451\n",
      "train loss:0.8025521466744061\n",
      "train loss:0.9892317497808152\n",
      "train loss:0.7639620371188661\n",
      "train loss:0.8781742727734592\n",
      "train loss:1.1021708452534937\n",
      "train loss:1.129268223041585\n",
      "train loss:0.7823314126658594\n",
      "train loss:0.746382492071328\n",
      "train loss:0.993022534310633\n",
      "train loss:0.6363291945080417\n",
      "train loss:0.7869491246203297\n",
      "train loss:0.9094628989228083\n",
      "train loss:0.9868579046861179\n",
      "train loss:0.8428067639889302\n",
      "train loss:0.8355623864918708\n",
      "train loss:0.8687164085331629\n",
      "train loss:0.8812462061306437\n",
      "train loss:0.7308123596169657\n",
      "train loss:0.8748486300851351\n",
      "train loss:0.8536346069277257\n",
      "train loss:0.8130301183179225\n",
      "train loss:1.026627861318152\n",
      "train loss:0.8655940052631489\n",
      "train loss:1.2550348354745047\n",
      "train loss:0.9009685239802802\n",
      "train loss:0.8383540264311661\n",
      "train loss:0.8809693830412461\n",
      "train loss:0.9978584381859388\n",
      "train loss:0.8687421774222353\n",
      "train loss:0.9751968802247204\n",
      "train loss:0.8026701654454713\n",
      "train loss:0.9117255710139271\n",
      "train loss:0.9146592695536259\n",
      "train loss:0.8755755663367768\n",
      "train loss:0.9664393714679695\n",
      "train loss:0.9495119458598211\n",
      "train loss:0.9749374370950501\n",
      "train loss:0.8446512861516174\n",
      "train loss:0.7592247716577737\n",
      "train loss:0.8493916172075876\n",
      "train loss:0.8956402399769039\n",
      "train loss:0.8504410823502311\n",
      "train loss:0.9752004691589009\n",
      "train loss:0.9579383969143427\n",
      "train loss:0.9544302720866874\n",
      "train loss:0.9511682606316324\n",
      "train loss:0.9183701963552778\n",
      "train loss:0.920134257605133\n",
      "train loss:0.8655175052853837\n",
      "train loss:0.9589025062312525\n",
      "train loss:0.9208309144988763\n",
      "train loss:0.8537404858541775\n",
      "train loss:0.9065165259338924\n",
      "train loss:0.8956806153101624\n",
      "train loss:0.8749254175086228\n",
      "train loss:0.8899943327453671\n",
      "train loss:0.9293249736109311\n",
      "train loss:0.7909595610241369\n",
      "train loss:1.0414675605114538\n",
      "train loss:0.8970393207507809\n",
      "train loss:0.8861596663220239\n",
      "train loss:0.7103678419333722\n",
      "train loss:0.9789034570213261\n",
      "train loss:0.9786266661652339\n",
      "train loss:0.8972105746907375\n",
      "train loss:0.9652630044535023\n",
      "train loss:0.924620896071745\n",
      "train loss:1.040691131112601\n",
      "train loss:0.9429189810490485\n",
      "train loss:0.8335231320251516\n",
      "train loss:0.987274548165283\n",
      "train loss:0.9070127290391251\n",
      "train loss:0.9624085835951892\n",
      "train loss:0.800402778048446\n",
      "train loss:0.9474697111838103\n",
      "train loss:0.9446896540805916\n",
      "train loss:1.042718054971912\n",
      "train loss:0.6787815166342286\n",
      "train loss:0.8348286935554167\n",
      "train loss:0.8010384557100769\n",
      "train loss:0.7517151970231833\n",
      "train loss:0.9233026361919192\n",
      "train loss:0.9074003469936309\n",
      "train loss:0.7737129260456423\n",
      "train loss:0.7187484803639742\n",
      "train loss:0.986816118822466\n",
      "train loss:1.0112906515559263\n",
      "train loss:0.9802731275110973\n",
      "train loss:1.016668483275991\n",
      "train loss:0.7055850995230185\n",
      "train loss:0.7928105518777896\n",
      "train loss:1.0708084632028387\n",
      "train loss:0.8530864145381883\n",
      "train loss:0.8706422860476192\n",
      "train loss:0.9039137404230801\n",
      "train loss:0.9347357217691278\n",
      "train loss:0.7371040566759868\n",
      "train loss:0.8817452876805841\n",
      "train loss:0.9482198463869986\n",
      "train loss:0.9541404749821186\n",
      "train loss:0.9932733861638192\n",
      "train loss:0.939846996861964\n",
      "train loss:1.0011242603235349\n",
      "train loss:0.8713782148993399\n",
      "train loss:0.7776502233653295\n",
      "train loss:0.9651349291637544\n",
      "train loss:0.9453150667382899\n",
      "train loss:0.9382369456984178\n",
      "train loss:0.8654724467449106\n",
      "train loss:0.9264821261370179\n",
      "train loss:0.8998041297538539\n",
      "train loss:0.9132549733137114\n",
      "train loss:0.702839743881993\n",
      "train loss:0.8075835572483571\n",
      "train loss:0.8278974031933326\n",
      "train loss:0.9055755351684645\n",
      "train loss:0.7473398850036931\n",
      "train loss:0.8461527989677097\n",
      "train loss:0.8390836855919594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8817228425409265\n",
      "train loss:0.8385951329621625\n",
      "train loss:0.8634360533457004\n",
      "train loss:0.8203742669531994\n",
      "train loss:0.9763205007175216\n",
      "train loss:1.1572871876190371\n",
      "train loss:0.8828150760443947\n",
      "train loss:1.0341058869631465\n",
      "train loss:0.8197307886209182\n",
      "train loss:0.9105856708136977\n",
      "train loss:0.6457243525268279\n",
      "train loss:0.8360682094443974\n",
      "train loss:0.7581017283166017\n",
      "train loss:0.9178409364211924\n",
      "train loss:0.9924679191395339\n",
      "train loss:0.9874861012434174\n",
      "train loss:0.893488366822258\n",
      "train loss:1.0631811471008579\n",
      "train loss:0.8562729327952635\n",
      "train loss:0.8858205015451809\n",
      "train loss:0.9296203867712385\n",
      "train loss:0.8673691195609612\n",
      "train loss:0.9395874818228449\n",
      "train loss:0.8965055899084783\n",
      "train loss:0.8156517695441078\n",
      "train loss:0.8645435151369787\n",
      "train loss:0.8999341702319018\n",
      "train loss:0.9009762972622645\n",
      "train loss:0.9864022813547431\n",
      "train loss:0.9256596130697183\n",
      "train loss:0.8339439473366916\n",
      "train loss:1.0560021868623002\n",
      "train loss:0.892832882051789\n",
      "train loss:0.8923300513006883\n",
      "train loss:0.8418749921453209\n",
      "train loss:0.8492181866373312\n",
      "train loss:0.8166213795667633\n",
      "train loss:0.8177779665346528\n",
      "train loss:0.9107108687850267\n",
      "train loss:0.9456898979907112\n",
      "train loss:0.9370421747962699\n",
      "train loss:0.9152184453697123\n",
      "train loss:0.9683169863172183\n",
      "train loss:0.70126812514705\n",
      "train loss:0.8344080643775541\n",
      "train loss:0.8823738503294106\n",
      "train loss:0.8964014738942242\n",
      "train loss:0.8559211975946733\n",
      "train loss:0.931258726230465\n",
      "train loss:0.9161018009463744\n",
      "train loss:0.8741759861457505\n",
      "train loss:0.902402446947597\n",
      "train loss:0.792107172092306\n",
      "train loss:1.0031401760402308\n",
      "train loss:0.8830209461400875\n",
      "train loss:0.8428837986145234\n",
      "train loss:0.897283379925291\n",
      "train loss:0.9428348086001264\n",
      "train loss:0.8335486689003646\n",
      "train loss:1.0400930258307646\n",
      "train loss:0.7880415873101125\n",
      "train loss:0.853302274558622\n",
      "train loss:0.9102617325436543\n",
      "train loss:0.9339094950841789\n",
      "train loss:0.8790463230096934\n",
      "train loss:0.9305486125724272\n",
      "train loss:0.8873939577487715\n",
      "train loss:0.9261154522655499\n",
      "train loss:0.829785510658983\n",
      "train loss:1.038155042171343\n",
      "train loss:1.0058886944443601\n",
      "train loss:0.7604389809636818\n",
      "train loss:0.75258174000542\n",
      "train loss:0.840209467391308\n",
      "train loss:0.8313470732963872\n",
      "train loss:0.8718730650502361\n",
      "train loss:0.773272739617556\n",
      "train loss:0.7830038267770482\n",
      "train loss:0.7655054976084081\n",
      "train loss:0.7924520311332068\n",
      "train loss:0.8259413886224329\n",
      "train loss:0.8937814148144202\n",
      "train loss:0.9175382684436724\n",
      "train loss:0.9980499823581322\n",
      "train loss:0.6699653175418537\n",
      "train loss:0.8222166180693496\n",
      "train loss:0.8315310506766196\n",
      "train loss:0.8725365167083952\n",
      "train loss:0.8687098513357963\n",
      "train loss:0.9048075800245132\n",
      "train loss:0.9759590863581535\n",
      "train loss:0.8385249333362961\n",
      "train loss:0.843809721554777\n",
      "train loss:0.704490039439059\n",
      "train loss:0.8368613749534849\n",
      "train loss:0.7598020145689566\n",
      "train loss:0.7448537233428731\n",
      "train loss:0.7310385918673632\n",
      "train loss:0.8360394480616357\n",
      "train loss:0.8869467623259676\n",
      "train loss:0.9220304987731492\n",
      "train loss:0.6553735082812325\n",
      "train loss:0.7106385022991933\n",
      "train loss:0.9517963149317729\n",
      "train loss:1.1265533826389031\n",
      "train loss:0.9377007654603137\n",
      "train loss:1.1413992678861442\n",
      "train loss:0.7044991261614251\n",
      "train loss:0.8952319682620743\n",
      "train loss:0.9028072573284599\n",
      "train loss:0.7554162341794275\n",
      "train loss:0.8071575254920753\n",
      "train loss:0.853067379795894\n",
      "train loss:0.80662413405391\n",
      "train loss:0.8325951678836803\n",
      "train loss:0.9283661347108614\n",
      "train loss:0.7138812271410491\n",
      "train loss:1.0257185287155557\n",
      "train loss:0.8917191910073409\n",
      "train loss:0.8265490680304969\n",
      "train loss:0.9108575990677366\n",
      "train loss:0.8090408639862221\n",
      "train loss:0.8158036612900317\n",
      "train loss:0.8002722866567243\n",
      "train loss:0.9547825285775702\n",
      "train loss:0.8520025094586616\n",
      "train loss:0.9895692253058845\n",
      "train loss:0.8851921713590672\n",
      "train loss:0.7612875401715344\n",
      "train loss:0.7936256980234286\n",
      "train loss:0.8634427962593869\n",
      "train loss:1.0028420564343319\n",
      "train loss:0.8916507258790582\n",
      "train loss:0.9265539462344438\n",
      "train loss:0.8547506174634927\n",
      "train loss:0.845953286787956\n",
      "train loss:0.9358201241176068\n",
      "train loss:0.9019713164231352\n",
      "train loss:1.052825139499404\n",
      "train loss:0.8633564689914154\n",
      "train loss:0.7443856702634748\n",
      "train loss:0.9419007926488956\n",
      "train loss:0.8522195148643399\n",
      "train loss:0.9390481562697407\n",
      "train loss:0.9704169340950548\n",
      "train loss:0.7713080844777309\n",
      "train loss:0.8359744424864287\n",
      "train loss:0.8123401878547445\n",
      "train loss:0.8470576471568356\n",
      "train loss:0.8396305005872269\n",
      "train loss:0.8504167408359251\n",
      "train loss:0.6846299273399353\n",
      "train loss:0.901134926889337\n",
      "train loss:0.8321087594738992\n",
      "train loss:0.9371646551443666\n",
      "train loss:0.8954544096574043\n",
      "train loss:0.8022621993245213\n",
      "train loss:1.009756433621164\n",
      "train loss:0.9015578255923039\n",
      "train loss:0.8014095595558498\n",
      "train loss:0.868443135131962\n",
      "train loss:0.9447722380125977\n",
      "train loss:0.6336013560871492\n",
      "train loss:0.8748322982038084\n",
      "train loss:0.9852116108550316\n",
      "train loss:0.9321633901158084\n",
      "train loss:0.8262751890643781\n",
      "train loss:0.9157441234682391\n",
      "train loss:0.778345046244095\n",
      "train loss:1.082908129343236\n",
      "train loss:0.8427400043748675\n",
      "train loss:0.9500957360526899\n",
      "train loss:0.9464970025585255\n",
      "train loss:0.7925671279907571\n",
      "train loss:0.8518778173993659\n",
      "train loss:0.8418213566311812\n",
      "train loss:0.9375703368933307\n",
      "train loss:0.9581327925927833\n",
      "train loss:0.7989014922800992\n",
      "train loss:0.8266431175557009\n",
      "train loss:0.783124178988645\n",
      "train loss:0.9541295882844887\n",
      "train loss:0.9442890071334193\n",
      "train loss:0.9275618342897282\n",
      "train loss:0.8712593897828583\n",
      "train loss:0.9068923856244843\n",
      "train loss:0.9721616488739576\n",
      "train loss:0.9637182015765533\n",
      "train loss:0.8354113588542699\n",
      "train loss:0.7629365593211184\n",
      "train loss:0.9325720174411015\n",
      "train loss:0.8403862551621226\n",
      "train loss:0.822202384263037\n",
      "train loss:0.8347233101833362\n",
      "train loss:0.9047728513183186\n",
      "train loss:0.8540296508423065\n",
      "train loss:0.918042322162418\n",
      "train loss:0.8783360779192136\n",
      "train loss:0.829542479015362\n",
      "train loss:0.9708159234397824\n",
      "train loss:1.0331434257507268\n",
      "train loss:0.700571273883241\n",
      "train loss:1.0371922135013378\n",
      "train loss:0.6279032093334592\n",
      "train loss:0.918030214139765\n",
      "train loss:0.8906714725407835\n",
      "train loss:0.7658404792938839\n",
      "train loss:0.9271988844931351\n",
      "train loss:0.8479171378825698\n",
      "train loss:0.8583959889273731\n",
      "train loss:0.7723981125400214\n",
      "train loss:0.648650099349625\n",
      "train loss:0.9366912540397131\n",
      "train loss:1.0302329821093605\n",
      "train loss:0.855473276717946\n",
      "train loss:0.8648150275505508\n",
      "train loss:0.6915544809786016\n",
      "train loss:0.9586627190785051\n",
      "train loss:0.835478514587674\n",
      "train loss:1.0048296928867322\n",
      "train loss:0.8237656577373815\n",
      "train loss:0.9589356346309308\n",
      "train loss:0.8476169032849935\n",
      "train loss:0.8260803161397022\n",
      "train loss:0.8907581025789725\n",
      "train loss:0.8100615304962341\n",
      "train loss:1.0212244333223368\n",
      "train loss:0.8749203570029468\n",
      "train loss:0.9621019164297014\n",
      "train loss:0.9296188898962053\n",
      "train loss:0.7264673003428076\n",
      "train loss:0.7759322456889239\n",
      "train loss:0.7902298988658812\n",
      "train loss:0.7664640791652686\n",
      "train loss:0.8830437788315134\n",
      "train loss:0.8540443055381481\n",
      "train loss:0.8726940913003616\n",
      "train loss:1.040552228185576\n",
      "train loss:0.9034608056614492\n",
      "train loss:1.078189971506701\n",
      "train loss:0.9700388111933691\n",
      "train loss:0.8150566317128274\n",
      "train loss:0.9162472854594776\n",
      "train loss:0.8122390350004093\n",
      "train loss:1.0628493068116107\n",
      "train loss:1.0415478329150205\n",
      "train loss:0.8110726428998867\n",
      "train loss:0.8823532375329868\n",
      "train loss:0.8215436284134003\n",
      "train loss:1.0323597921986072\n",
      "train loss:0.8554034790142172\n",
      "train loss:0.8057901980848209\n",
      "train loss:0.8976700315615451\n",
      "train loss:0.8747404568643162\n",
      "train loss:0.9399580804172585\n",
      "train loss:0.9197891321809127\n",
      "train loss:0.8680225591753667\n",
      "train loss:0.9367753737917769\n",
      "train loss:0.9875201834487064\n",
      "train loss:1.0237765758202613\n",
      "train loss:0.9020468977053361\n",
      "train loss:0.729259291322052\n",
      "train loss:0.815959776065132\n",
      "train loss:0.7573399511429305\n",
      "train loss:0.948138244488857\n",
      "train loss:0.8886482713220056\n",
      "train loss:0.9897433351912119\n",
      "train loss:0.9442092482334474\n",
      "train loss:0.7494218867758896\n",
      "train loss:0.8681927472704807\n",
      "train loss:0.8763015883400951\n",
      "train loss:0.9283671537645545\n",
      "train loss:0.6806938972060808\n",
      "train loss:1.0805055319376813\n",
      "train loss:0.9726872141106289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8304364182014251\n",
      "train loss:0.9298843956713069\n",
      "train loss:1.0691175495118004\n",
      "train loss:0.8850440303780793\n",
      "train loss:0.9305552392433525\n",
      "train loss:0.7637409850299683\n",
      "train loss:0.8247917146963825\n",
      "train loss:0.8247031419381163\n",
      "train loss:0.742603996923309\n",
      "train loss:0.8527456811972786\n",
      "train loss:0.9073419152337805\n",
      "train loss:0.6736315840017937\n",
      "train loss:0.704235326951993\n",
      "train loss:1.0382783896014773\n",
      "train loss:0.9653373425677887\n",
      "train loss:0.9261615945387627\n",
      "train loss:0.8646654339146849\n",
      "train loss:0.8645473821257148\n",
      "train loss:0.7619591462604306\n",
      "train loss:0.8920953552012262\n",
      "train loss:0.7642730076001585\n",
      "train loss:0.7977912855042588\n",
      "train loss:0.8619414698818575\n",
      "train loss:0.9253461700299179\n",
      "train loss:0.7784441231947593\n",
      "train loss:1.0080622979785112\n",
      "train loss:1.1544437349781727\n",
      "train loss:0.8034727104978466\n",
      "train loss:0.7823821516926679\n",
      "train loss:0.9377440246474681\n",
      "train loss:0.9431590305784483\n",
      "train loss:0.8422012886508456\n",
      "train loss:0.9990107748743924\n",
      "train loss:0.9273461944124963\n",
      "train loss:0.7570894715816497\n",
      "train loss:0.9447067857197098\n",
      "train loss:1.0412846973710856\n",
      "train loss:0.8618759767580804\n",
      "train loss:0.9338445274653059\n",
      "train loss:0.884841779397444\n",
      "train loss:0.8859268262625436\n",
      "train loss:0.8877319701829848\n",
      "train loss:0.8293255226021761\n",
      "train loss:0.9549169789875128\n",
      "train loss:0.9246475463822845\n",
      "train loss:0.8140395958889154\n",
      "train loss:0.873659990071839\n",
      "train loss:1.023481067213269\n",
      "train loss:0.7120724497336031\n",
      "train loss:0.8965522214603243\n",
      "train loss:0.6929762126406367\n",
      "train loss:0.8881536281142813\n",
      "train loss:0.9220570852574441\n",
      "train loss:0.9303864278180494\n",
      "train loss:0.8088161135322527\n",
      "train loss:0.8024014737327222\n",
      "train loss:1.040026074799176\n",
      "train loss:0.8185467826808602\n",
      "train loss:1.0065481359878985\n",
      "train loss:0.8181631370685118\n",
      "train loss:0.9064617629003697\n",
      "train loss:0.844124057835821\n",
      "train loss:0.9185473023389064\n",
      "train loss:0.8186256681797436\n",
      "train loss:0.824896808170396\n",
      "train loss:0.946795389677149\n",
      "train loss:0.9605861777750428\n",
      "train loss:0.8082535337912304\n",
      "train loss:0.8015047508460481\n",
      "train loss:0.8495102752903216\n",
      "train loss:0.7693345925730913\n",
      "train loss:0.8681594364316507\n",
      "train loss:0.7080796614489121\n",
      "train loss:0.7688834074099463\n",
      "train loss:1.0072653106840388\n",
      "train loss:0.7927014832664868\n",
      "train loss:0.7777430305895003\n",
      "train loss:0.9901123475336903\n",
      "train loss:0.8862044953056153\n",
      "train loss:0.8400359844867803\n",
      "train loss:0.9384015311794888\n",
      "train loss:0.916376281053529\n",
      "train loss:1.0342628438948984\n",
      "train loss:0.9474853712710943\n",
      "train loss:0.8189509331228318\n",
      "train loss:1.004967447776175\n",
      "train loss:0.943681095245373\n",
      "train loss:0.7809192484925905\n",
      "train loss:0.8818046026301222\n",
      "train loss:0.9518479233835936\n",
      "train loss:0.9460717423512213\n",
      "train loss:0.8509859616769745\n",
      "train loss:0.9235802523757402\n",
      "train loss:0.8361855941526829\n",
      "train loss:0.7906822569891726\n",
      "train loss:0.9898978541176012\n",
      "train loss:0.97533470778451\n",
      "train loss:0.8921840773548901\n",
      "train loss:0.9595189793843975\n",
      "train loss:0.9934412833772224\n",
      "train loss:0.9088829997771508\n",
      "train loss:0.7348875404223705\n",
      "train loss:0.8757301368513869\n",
      "train loss:1.0111389421013104\n",
      "train loss:0.8861500858977991\n",
      "train loss:0.8217855029735407\n",
      "train loss:0.9667295485341634\n",
      "train loss:0.933925552909434\n",
      "train loss:0.8583226626716761\n",
      "train loss:0.8047881610669545\n",
      "train loss:0.8766781147936009\n",
      "train loss:1.0469469173545547\n",
      "train loss:1.0272078738777395\n",
      "train loss:0.843215558050567\n",
      "train loss:0.8561255416185257\n",
      "train loss:0.8791179542511347\n",
      "train loss:0.8548860142153479\n",
      "train loss:0.9367583545479153\n",
      "train loss:0.9866454263247489\n",
      "train loss:0.7608056684631506\n",
      "=== epoch:14, train acc:0.995, test acc:0.992 ===\n",
      "train loss:0.7801068948204909\n",
      "train loss:0.981636621763769\n",
      "train loss:0.9581233082474803\n",
      "train loss:0.9180462965673695\n",
      "train loss:0.890143770702328\n",
      "train loss:0.9457158450394132\n",
      "train loss:0.8852722122150877\n",
      "train loss:0.8618223684276743\n",
      "train loss:0.7681994072304628\n",
      "train loss:0.7926216670274403\n",
      "train loss:0.9475536281837921\n",
      "train loss:0.8658091470194297\n",
      "train loss:0.7631915385154993\n",
      "train loss:0.8939951555996553\n",
      "train loss:0.8384154378446093\n",
      "train loss:0.7015460991010295\n",
      "train loss:1.0596818796480767\n",
      "train loss:0.9782514569055657\n",
      "train loss:0.7925231673438478\n",
      "train loss:0.8681958756530868\n",
      "train loss:0.8408843203257004\n",
      "train loss:0.7814959786709603\n",
      "train loss:0.8614861304342452\n",
      "train loss:0.9965503479190887\n",
      "train loss:0.8800974629608532\n",
      "train loss:0.953783471361663\n",
      "train loss:0.8431924567506819\n",
      "train loss:0.8300204770196709\n",
      "train loss:0.8051318659467509\n",
      "train loss:0.8469009560797519\n",
      "train loss:0.810968624521507\n",
      "train loss:0.9583548439483793\n",
      "train loss:0.9009755401647422\n",
      "train loss:0.8462416764494136\n",
      "train loss:0.9711410378409152\n",
      "train loss:0.8243603504480734\n",
      "train loss:0.8274349023439963\n",
      "train loss:1.0442881111750744\n",
      "train loss:0.8929411680212724\n",
      "train loss:0.8285751483148321\n",
      "train loss:0.8914811629500483\n",
      "train loss:0.9406641543174237\n",
      "train loss:0.6725713305880224\n",
      "train loss:0.8521547579739404\n",
      "train loss:0.8576096357937201\n",
      "train loss:0.8854301870359201\n",
      "train loss:1.0008140662885656\n",
      "train loss:0.8939653850063826\n",
      "train loss:0.9296772765426264\n",
      "train loss:0.7898216612597615\n",
      "train loss:0.7534253589332439\n",
      "train loss:1.0101871101683628\n",
      "train loss:1.0106190984959782\n",
      "train loss:1.036193234251102\n",
      "train loss:0.8577032321181184\n",
      "train loss:0.8963435051291933\n",
      "train loss:0.8129522640656444\n",
      "train loss:0.8078648194629426\n",
      "train loss:0.9335674534270373\n",
      "train loss:0.9022616616981253\n",
      "train loss:0.8262374754752305\n",
      "train loss:1.076663484466101\n",
      "train loss:0.9903642976241368\n",
      "train loss:0.9219776109771669\n",
      "train loss:0.9032655883355555\n",
      "train loss:0.9047108669752844\n",
      "train loss:1.047699984148239\n",
      "train loss:0.8506291921951982\n",
      "train loss:0.9516883262705781\n",
      "train loss:0.8706371133062767\n",
      "train loss:0.826125998666804\n",
      "train loss:0.8655801068351647\n",
      "train loss:0.8759016478454837\n",
      "train loss:0.8514230273291755\n",
      "train loss:0.8514674041897287\n",
      "train loss:0.8663767277109714\n",
      "train loss:0.8064935804526786\n",
      "train loss:1.0139950804967892\n",
      "train loss:0.7734346362717445\n",
      "train loss:0.9216724385725104\n",
      "train loss:0.8061934426871126\n",
      "train loss:0.7645497559646351\n",
      "train loss:1.0502640877800369\n",
      "train loss:0.7900048379152306\n",
      "train loss:0.8895167301310494\n",
      "train loss:0.9461975521982279\n",
      "train loss:0.8312427109250915\n",
      "train loss:0.995320894288517\n",
      "train loss:0.9183402707931395\n",
      "train loss:0.8777568918323009\n",
      "train loss:0.8608495060497146\n",
      "train loss:0.8230650317599553\n",
      "train loss:0.98845859681587\n",
      "train loss:0.9332433140553537\n",
      "train loss:0.844318052986452\n",
      "train loss:0.9285609070650088\n",
      "train loss:0.9009993671246377\n",
      "train loss:0.770270127491599\n",
      "train loss:0.9031193027948222\n",
      "train loss:0.8159795056601196\n",
      "train loss:0.74045613261849\n",
      "train loss:0.893019045853449\n",
      "train loss:0.8025469563806246\n",
      "train loss:0.7902614540615431\n",
      "train loss:0.8965262739557451\n",
      "train loss:0.8738198245873064\n",
      "train loss:0.8673251981927608\n",
      "train loss:0.9140922865339962\n",
      "train loss:0.8573083351026659\n",
      "train loss:0.8798969725816498\n",
      "train loss:0.846951369060437\n",
      "train loss:0.7969189243601308\n",
      "train loss:0.7695842973936918\n",
      "train loss:0.9053384432252362\n",
      "train loss:0.880032958006375\n",
      "train loss:0.777122124463411\n",
      "train loss:0.8181642241487748\n",
      "train loss:0.7152266805505062\n",
      "train loss:0.8165639583987913\n",
      "train loss:0.893048805160443\n",
      "train loss:0.9282504463678003\n",
      "train loss:0.9005733639678586\n",
      "train loss:0.9220556989879838\n",
      "train loss:0.9454373859927866\n",
      "train loss:0.8549675651635914\n",
      "train loss:0.923513609843505\n",
      "train loss:0.9936352967928681\n",
      "train loss:0.7939310474172063\n",
      "train loss:0.9059856536320224\n",
      "train loss:0.9909110827936565\n",
      "train loss:0.849990453272844\n",
      "train loss:0.905241315831432\n",
      "train loss:0.9061421121252721\n",
      "train loss:0.9109928748532655\n",
      "train loss:0.8044158008973337\n",
      "train loss:0.9416614526110234\n",
      "train loss:0.8952399589682557\n",
      "train loss:0.9178741439718059\n",
      "train loss:0.9183661387912957\n",
      "train loss:0.9589929869427148\n",
      "train loss:0.8021190164145553\n",
      "train loss:0.8736154685274488\n",
      "train loss:0.8976997992746546\n",
      "train loss:0.7704031701428841\n",
      "train loss:0.7808499287851997\n",
      "train loss:0.9338217127740933\n",
      "train loss:1.0083190890075784\n",
      "train loss:0.9750520980288903\n",
      "train loss:0.9217236039700413\n",
      "train loss:0.9909378683571944\n",
      "train loss:1.010658182382788\n",
      "train loss:0.8930119851256477\n",
      "train loss:0.8161160157407388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7982467118449013\n",
      "train loss:0.9647110091153148\n",
      "train loss:0.7898191203836753\n",
      "train loss:0.9025001163591267\n",
      "train loss:0.7367227243027682\n",
      "train loss:0.9191986768728267\n",
      "train loss:0.9727882506151323\n",
      "train loss:0.8790825588934031\n",
      "train loss:0.8330675592513783\n",
      "train loss:0.8973977693681594\n",
      "train loss:0.8606365771300808\n",
      "train loss:0.9323100260237709\n",
      "train loss:0.7819361665031295\n",
      "train loss:0.7942652456496332\n",
      "train loss:0.8710365937471534\n",
      "train loss:0.8089105904502355\n",
      "train loss:0.8186868068157881\n",
      "train loss:0.8613015164304898\n",
      "train loss:0.8995393475489515\n",
      "train loss:0.9209355439849226\n",
      "train loss:0.9679814381642928\n",
      "train loss:0.9390097556495146\n",
      "train loss:1.0813865383764993\n",
      "train loss:0.8777054347180041\n",
      "train loss:0.8965064942886665\n",
      "train loss:0.8599789608065016\n",
      "train loss:1.0767589441519063\n",
      "train loss:0.7098991378516204\n",
      "train loss:0.8812613296432515\n",
      "train loss:0.7210016215635054\n",
      "train loss:1.011490078557975\n",
      "train loss:0.9031556408456549\n",
      "train loss:0.9340578399666307\n",
      "train loss:0.7960277942811063\n",
      "train loss:0.9302935539946904\n",
      "train loss:0.9137876171610578\n",
      "train loss:0.9313226395167792\n",
      "train loss:0.78306800645181\n",
      "train loss:0.7849279125285552\n",
      "train loss:0.8689608062425657\n",
      "train loss:0.843259083726405\n",
      "train loss:0.6715281324903297\n",
      "train loss:0.9210299054377492\n",
      "train loss:0.8609516916645806\n",
      "train loss:0.8967554672195157\n",
      "train loss:0.9291614539506231\n",
      "train loss:0.9410477528934916\n",
      "train loss:0.8308113223896444\n",
      "train loss:0.8738379877106115\n",
      "train loss:0.9762329128697109\n",
      "train loss:1.0355935615337963\n",
      "train loss:0.95726955274089\n",
      "train loss:0.8644175704257168\n",
      "train loss:0.8651949843688052\n",
      "train loss:1.005448787602255\n",
      "train loss:0.85154766335518\n",
      "train loss:1.0579160955073146\n",
      "train loss:0.957720399002509\n",
      "train loss:0.9578835666580136\n",
      "train loss:0.9423445305042939\n",
      "train loss:0.7866697519947313\n",
      "train loss:0.8595294645101201\n",
      "train loss:0.7964110239948909\n",
      "train loss:0.7759356165051154\n",
      "train loss:0.8729909492124797\n",
      "train loss:0.7522243213085315\n",
      "train loss:1.0065927851536933\n",
      "train loss:0.8076847788499198\n",
      "train loss:0.9009459710598152\n",
      "train loss:0.9402256657282991\n",
      "train loss:0.8635023792516964\n",
      "train loss:0.9427020067959211\n",
      "train loss:0.7408806149606871\n",
      "train loss:1.0280155300795841\n",
      "train loss:0.9417600946444279\n",
      "train loss:0.8886284457712437\n",
      "train loss:0.9426456067468731\n",
      "train loss:0.995041179895138\n",
      "train loss:1.0986760735413816\n",
      "train loss:0.9470270846847917\n",
      "train loss:0.8863373728163626\n",
      "train loss:0.795494687086236\n",
      "train loss:0.782648829451871\n",
      "train loss:0.8299192825477316\n",
      "train loss:0.8684244035660111\n",
      "train loss:0.9897214762577824\n",
      "train loss:0.6094165173077482\n",
      "train loss:0.7596009855052295\n",
      "train loss:1.0104052610591963\n",
      "train loss:0.8187629216650341\n",
      "train loss:0.9615579360252928\n",
      "train loss:0.965397249715746\n",
      "train loss:0.9464257535978261\n",
      "train loss:0.9103233790534996\n",
      "train loss:0.8124687586512154\n",
      "train loss:1.0000862076787513\n",
      "train loss:1.0177357128638536\n",
      "train loss:0.9903436370097354\n",
      "train loss:0.8121915900177744\n",
      "train loss:1.0505703272018998\n",
      "train loss:0.9125918917238177\n",
      "train loss:0.7980768537367063\n",
      "train loss:0.9876181599335642\n",
      "train loss:0.8343946134212807\n",
      "train loss:0.823092144147617\n",
      "train loss:0.8823912930814631\n",
      "train loss:0.9304027457738323\n",
      "train loss:0.8924352293434273\n",
      "train loss:0.9728357002152456\n",
      "train loss:0.9321732544628953\n",
      "train loss:0.8291398822694199\n",
      "train loss:0.968008493521765\n",
      "train loss:0.8539687372685003\n",
      "train loss:0.8446711469747945\n",
      "train loss:0.7988566067230336\n",
      "train loss:0.9607371346198893\n",
      "train loss:1.102907246742799\n",
      "train loss:0.9690248348908135\n",
      "train loss:0.913484589569065\n",
      "train loss:0.7947949648824103\n",
      "train loss:0.9075996758341894\n",
      "train loss:0.7474885117544601\n",
      "train loss:0.9727149053487496\n",
      "train loss:0.9530191489038029\n",
      "train loss:0.9568764298406702\n",
      "train loss:0.940309307917558\n",
      "train loss:0.9048539979492299\n",
      "train loss:0.6745149963953214\n",
      "train loss:0.8137887065303847\n",
      "train loss:0.9964235023348119\n",
      "train loss:0.9667327947673495\n",
      "train loss:0.8789388371729521\n",
      "train loss:1.0058827607489818\n",
      "train loss:1.0797178927519189\n",
      "train loss:0.7916541563453863\n",
      "train loss:0.8980733826617204\n",
      "train loss:1.0305065189201088\n",
      "train loss:0.8633983521643459\n",
      "train loss:1.117868152711965\n",
      "train loss:0.8203760829347524\n",
      "train loss:0.7894823574232335\n",
      "train loss:0.8058493000145127\n",
      "train loss:1.1347149002093737\n",
      "train loss:0.9431002645532405\n",
      "train loss:0.8038877010922403\n",
      "train loss:0.9826089450573764\n",
      "train loss:0.9138794197199027\n",
      "train loss:0.7688991162178611\n",
      "train loss:0.8818830282926946\n",
      "train loss:0.8337598293704735\n",
      "train loss:0.7512607378734897\n",
      "train loss:0.821336528816218\n",
      "train loss:0.9048485000259826\n",
      "train loss:1.1708604990088247\n",
      "train loss:0.8946891210301123\n",
      "train loss:0.8645775772488936\n",
      "train loss:0.8268717119388667\n",
      "train loss:0.9002294969941262\n",
      "train loss:0.8855120922485404\n",
      "train loss:0.692754968567199\n",
      "train loss:0.8831006229161654\n",
      "train loss:0.9489358907841189\n",
      "train loss:0.8722005174342344\n",
      "train loss:0.9968717711661575\n",
      "train loss:0.914640250333648\n",
      "train loss:0.9185841062623874\n",
      "train loss:0.8790050591504013\n",
      "train loss:0.8365947049485831\n",
      "train loss:0.9033704805104751\n",
      "train loss:0.9381190892254365\n",
      "train loss:0.7936096465811943\n",
      "train loss:0.7704538610070085\n",
      "train loss:0.8591943228747561\n",
      "train loss:0.8694057048845143\n",
      "train loss:0.8326478480233745\n",
      "train loss:0.8245494214119584\n",
      "train loss:1.0037456259091484\n",
      "train loss:0.8295850786392853\n",
      "train loss:1.0640065730577024\n",
      "train loss:0.8350485462860163\n",
      "train loss:0.9433520903031831\n",
      "train loss:0.9622650918336513\n",
      "train loss:0.950462436058674\n",
      "train loss:0.9699429156686847\n",
      "train loss:0.8478099081584659\n",
      "train loss:0.9025923092081649\n",
      "train loss:0.9129670094286041\n",
      "train loss:1.0213763851141784\n",
      "train loss:0.838888873484488\n",
      "train loss:0.9066750833887528\n",
      "train loss:0.6914475307856346\n",
      "train loss:0.7699329606883845\n",
      "train loss:1.0710052323648227\n",
      "train loss:1.009784270871646\n",
      "train loss:0.813960675417283\n",
      "train loss:0.9008022354160765\n",
      "train loss:0.838129905621339\n",
      "train loss:0.70292261485075\n",
      "train loss:0.9909196410929557\n",
      "train loss:0.8023499820384354\n",
      "train loss:0.9341442444364857\n",
      "train loss:1.1085932917638521\n",
      "train loss:0.7464587542537039\n",
      "train loss:0.8463891693517088\n",
      "train loss:0.7576075916936271\n",
      "train loss:0.9145079673992993\n",
      "train loss:0.9249268923381017\n",
      "train loss:1.0241864835709473\n",
      "train loss:0.8893023601017621\n",
      "train loss:0.7296294751015813\n",
      "train loss:0.8882531281747397\n",
      "train loss:0.9503387114042997\n",
      "train loss:0.8736150280752252\n",
      "train loss:1.032341746820834\n",
      "train loss:0.7560259596735648\n",
      "train loss:0.8821570329369065\n",
      "train loss:1.0094929740500922\n",
      "train loss:0.8793539914330694\n",
      "train loss:0.8409401130947497\n",
      "train loss:0.9481636038681345\n",
      "train loss:0.936870259676887\n",
      "train loss:0.8820178735960146\n",
      "train loss:1.0453426135954857\n",
      "train loss:1.069452889539796\n",
      "train loss:0.8797960275916151\n",
      "train loss:0.8927512035379326\n",
      "train loss:0.8864152649616835\n",
      "train loss:0.7693644976188193\n",
      "train loss:0.9353696840538551\n",
      "train loss:0.8354993987624725\n",
      "train loss:0.9708471110853604\n",
      "train loss:0.9208507472619583\n",
      "train loss:1.042638622035181\n",
      "train loss:0.852940232386199\n",
      "train loss:0.8527537447010216\n",
      "train loss:0.8479876751441637\n",
      "train loss:0.9488621608501536\n",
      "train loss:0.7615081745103356\n",
      "train loss:1.002102196325675\n",
      "train loss:0.8912784813686533\n",
      "train loss:0.8541970599880048\n",
      "train loss:1.035984389474632\n",
      "train loss:0.7977639919070484\n",
      "train loss:1.0521489414499834\n",
      "train loss:0.7900277141394768\n",
      "train loss:0.8646208656390061\n",
      "train loss:0.9430079911428311\n",
      "train loss:0.9112916865898589\n",
      "train loss:0.8455578959141447\n",
      "train loss:0.8766180935530511\n",
      "train loss:0.9412579405677068\n",
      "train loss:0.9351246146225253\n",
      "train loss:0.9909838373591217\n",
      "train loss:0.884094541648483\n",
      "train loss:0.7647604035506623\n",
      "train loss:0.8304384346367165\n",
      "train loss:0.9205927899274475\n",
      "train loss:1.0077108152515881\n",
      "train loss:0.908732732803895\n",
      "train loss:0.8401091758729473\n",
      "train loss:0.8879890430894362\n",
      "train loss:0.8088946294458345\n",
      "train loss:0.8197063401422373\n",
      "train loss:0.9882213480208066\n",
      "train loss:0.9260914341058788\n",
      "train loss:0.6992828605362132\n",
      "train loss:0.8844216902361347\n",
      "train loss:0.8647960544769419\n",
      "train loss:0.8271717894181677\n",
      "train loss:0.896288355202063\n",
      "train loss:0.860217152701988\n",
      "train loss:0.9020977022642067\n",
      "train loss:0.7990027499507932\n",
      "train loss:0.8158403005820755\n",
      "train loss:0.924470791335198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7888279796641174\n",
      "train loss:0.8848988253108777\n",
      "train loss:0.8942073672165104\n",
      "train loss:0.9125337946275343\n",
      "train loss:0.8607649159626622\n",
      "train loss:0.7575201981247113\n",
      "train loss:0.9254239342566006\n",
      "train loss:0.7182327658181389\n",
      "train loss:0.7783139056731607\n",
      "train loss:0.8781190676848637\n",
      "train loss:0.8688025487170491\n",
      "train loss:0.9086278718392619\n",
      "train loss:1.0048433132287662\n",
      "train loss:0.9068920904796659\n",
      "train loss:1.1143058838294748\n",
      "train loss:0.9159101155233672\n",
      "train loss:0.7364295843801991\n",
      "train loss:0.8074970139037144\n",
      "train loss:0.890012745016411\n",
      "train loss:1.045587287944584\n",
      "train loss:0.8641235070530613\n",
      "train loss:0.9255131360809773\n",
      "train loss:0.9401261826597661\n",
      "train loss:0.8250938887607571\n",
      "train loss:0.80596716886899\n",
      "train loss:0.9285860657618414\n",
      "train loss:1.040124762244116\n",
      "train loss:1.065578663287934\n",
      "train loss:0.8971314301211575\n",
      "train loss:0.9638783793627804\n",
      "train loss:0.7634854736723048\n",
      "train loss:0.8163065239728815\n",
      "train loss:0.7607998676655003\n",
      "train loss:0.851829413860123\n",
      "train loss:0.8196052884479452\n",
      "train loss:0.9587549150575687\n",
      "train loss:0.904086476835063\n",
      "train loss:0.894915399238573\n",
      "train loss:0.8482806578643948\n",
      "train loss:0.8284417380475171\n",
      "train loss:1.0447300882109807\n",
      "train loss:0.8551458512237958\n",
      "train loss:0.852756604671844\n",
      "train loss:0.9869850676312312\n",
      "train loss:0.7325421581121434\n",
      "train loss:0.7936390959203986\n",
      "train loss:1.025564078646386\n",
      "train loss:0.9645231991947877\n",
      "train loss:0.9077643500884787\n",
      "train loss:0.8958862028932313\n",
      "train loss:0.844461910421807\n",
      "train loss:0.9628521656962229\n",
      "train loss:0.9651925628347949\n",
      "train loss:0.7987558303010716\n",
      "train loss:0.9616138262568396\n",
      "train loss:1.0514171874982963\n",
      "train loss:0.9251527183590256\n",
      "train loss:0.9078370966552192\n",
      "train loss:0.9123298989186328\n",
      "train loss:0.9860968643699606\n",
      "train loss:0.746919366457676\n",
      "train loss:1.0045322071417957\n",
      "train loss:0.9110401679694539\n",
      "train loss:1.071330702410612\n",
      "train loss:0.8291009929548785\n",
      "train loss:0.8417788334219871\n",
      "train loss:0.8430279308306835\n",
      "train loss:0.997142458508162\n",
      "train loss:0.9567853161591671\n",
      "train loss:0.949959095126737\n",
      "train loss:0.8511758383179874\n",
      "train loss:0.8408320025849566\n",
      "train loss:0.8282791931795696\n",
      "train loss:0.821728234626237\n",
      "train loss:0.7654855005164365\n",
      "train loss:0.8006918945575245\n",
      "train loss:1.0088373492057006\n",
      "train loss:0.8331026047435968\n",
      "train loss:0.9098728493539409\n",
      "train loss:0.9482605966845784\n",
      "train loss:1.0236678844252094\n",
      "train loss:0.9432285789233086\n",
      "train loss:0.9284478848677483\n",
      "train loss:0.9009019114607801\n",
      "train loss:0.8671886952755641\n",
      "train loss:0.924652189453189\n",
      "train loss:1.033474753814821\n",
      "train loss:0.8725251188579374\n",
      "train loss:0.9045838897809709\n",
      "train loss:0.9040483962174883\n",
      "train loss:0.8822283482559965\n",
      "train loss:0.9483345561803325\n",
      "train loss:0.9543006213625449\n",
      "train loss:0.8307476831850369\n",
      "train loss:0.9201958427019664\n",
      "train loss:0.9000632242984934\n",
      "train loss:0.8516664427118161\n",
      "train loss:0.9379331904956336\n",
      "train loss:0.938459487343768\n",
      "train loss:0.8511582998473821\n",
      "train loss:0.9475725281085505\n",
      "train loss:0.8983436004446316\n",
      "train loss:1.1518431990818487\n",
      "train loss:0.9227470769531166\n",
      "train loss:0.8399682267795257\n",
      "train loss:0.8347425068242541\n",
      "train loss:0.8549380775163025\n",
      "train loss:0.8560408841911067\n",
      "train loss:0.794584665646696\n",
      "train loss:0.806751854790382\n",
      "train loss:0.7956234643564016\n",
      "train loss:0.6462925552441297\n",
      "train loss:0.7908953890334521\n",
      "train loss:0.861805909613179\n",
      "train loss:0.7537265186895477\n",
      "train loss:0.8118559068080872\n",
      "train loss:0.9401848314987586\n",
      "train loss:0.7059805250448982\n",
      "train loss:1.023468521959885\n",
      "train loss:0.8069060518152372\n",
      "train loss:0.8038896253935444\n",
      "train loss:0.8995016707355701\n",
      "train loss:0.8344573503074609\n",
      "train loss:0.8434091431303201\n",
      "train loss:0.9607769472670695\n",
      "train loss:0.8435613272644933\n",
      "train loss:0.8579820940420939\n",
      "train loss:0.8377013846562034\n",
      "train loss:0.8203465138510917\n",
      "train loss:0.7698303481682873\n",
      "train loss:0.8375635521452135\n",
      "train loss:1.0402903481035666\n",
      "train loss:0.9415776204002484\n",
      "train loss:0.9745165247036676\n",
      "train loss:0.8429415884560963\n",
      "train loss:0.9411020548115829\n",
      "train loss:0.9456070305321651\n",
      "train loss:0.856580777883873\n",
      "train loss:0.7717890830815461\n",
      "train loss:0.9326103425942353\n",
      "train loss:0.8796323295976199\n",
      "train loss:0.7535343809079573\n",
      "train loss:0.8880140806854608\n",
      "train loss:0.7372900398709585\n",
      "train loss:0.8335406296972279\n",
      "train loss:0.9989619047302871\n",
      "train loss:1.1303417449509745\n",
      "train loss:0.9190609970314473\n",
      "train loss:0.8398868261296335\n",
      "train loss:0.8372213065518714\n",
      "train loss:0.9251526296723253\n",
      "train loss:0.8057591488787041\n",
      "train loss:0.8539334974329219\n",
      "train loss:0.865038445793944\n",
      "train loss:0.7734116980518831\n",
      "train loss:0.8711174643983708\n",
      "train loss:0.9521406767877865\n",
      "train loss:0.7681396219493203\n",
      "train loss:0.7777883655470341\n",
      "train loss:0.8583491247211777\n",
      "train loss:1.0806152110070664\n",
      "train loss:0.8758700736851301\n",
      "train loss:0.8744047297478911\n",
      "train loss:0.8435573890282899\n",
      "train loss:0.9699346541299176\n",
      "train loss:0.9564680048100471\n",
      "train loss:0.8705369019708806\n",
      "train loss:0.9282896820318947\n",
      "train loss:0.992761746176415\n",
      "train loss:0.879652375217197\n",
      "train loss:0.92691288553782\n",
      "train loss:0.9162722501582055\n",
      "=== epoch:15, train acc:0.994, test acc:0.992 ===\n",
      "train loss:0.8432008339898941\n",
      "train loss:0.9127141292098433\n",
      "train loss:0.7777402841468318\n",
      "train loss:0.9032777563627864\n",
      "train loss:0.9917817923517738\n",
      "train loss:0.8197634864836567\n",
      "train loss:0.9529947718897889\n",
      "train loss:0.9317553246308021\n",
      "train loss:0.8923397539170961\n",
      "train loss:0.9438123623527714\n",
      "train loss:0.7674784708229493\n",
      "train loss:0.8954789505192542\n",
      "train loss:0.8561447955370367\n",
      "train loss:0.8668883341965361\n",
      "train loss:0.9966508179530419\n",
      "train loss:0.9393322772385844\n",
      "train loss:1.039182281405335\n",
      "train loss:0.7856089523964392\n",
      "train loss:0.7403162242770879\n",
      "train loss:0.7100485332305169\n",
      "train loss:1.0405794293045225\n",
      "train loss:0.9479318126784159\n",
      "train loss:0.8777522885356719\n",
      "train loss:0.8178502482170991\n",
      "train loss:0.9050628907961046\n",
      "train loss:0.8503448755383838\n",
      "train loss:0.7677023970111476\n",
      "train loss:0.8188585678055668\n",
      "train loss:0.873969696393419\n",
      "train loss:1.0562832548152565\n",
      "train loss:0.9468521071625993\n",
      "train loss:0.8259900718828859\n",
      "train loss:0.9042821064123769\n",
      "train loss:0.8278606067716109\n",
      "train loss:0.8631139126332767\n",
      "train loss:0.754882621843285\n",
      "train loss:0.7549790969068433\n",
      "train loss:0.7747051962143344\n",
      "train loss:0.9358632245883274\n",
      "train loss:0.8796208431520042\n",
      "train loss:0.95764297486114\n",
      "train loss:0.907560010100181\n",
      "train loss:0.7258110150054351\n",
      "train loss:0.8593311232925263\n",
      "train loss:1.01424400978113\n",
      "train loss:0.7428649555523629\n",
      "train loss:0.8392701599372514\n",
      "train loss:0.751454829347964\n",
      "train loss:0.803811945646249\n",
      "train loss:0.7657478646417992\n",
      "train loss:0.8136247868506834\n",
      "train loss:0.8807084373045632\n",
      "train loss:0.9329830341591518\n",
      "train loss:0.9755476092690966\n",
      "train loss:1.0869612244443592\n",
      "train loss:0.8015146333293925\n",
      "train loss:0.9100407759013751\n",
      "train loss:0.8137737736993647\n",
      "train loss:0.815762982708379\n",
      "train loss:0.7987637650645774\n",
      "train loss:0.9808026141197633\n",
      "train loss:0.913126834906267\n",
      "train loss:1.0245789601941622\n",
      "train loss:0.9352087865863951\n",
      "train loss:0.8047152196609701\n",
      "train loss:0.9348572852647942\n",
      "train loss:0.8190830718885325\n",
      "train loss:0.9795487562841937\n",
      "train loss:0.7849079126061624\n",
      "train loss:0.9405349482942471\n",
      "train loss:0.8214529406941428\n",
      "train loss:0.8245695090769621\n",
      "train loss:1.0210977106648524\n",
      "train loss:1.0474387540611039\n",
      "train loss:0.7734348359736472\n",
      "train loss:0.8592530431142223\n",
      "train loss:0.7282669078152133\n",
      "train loss:1.0066488338409356\n",
      "train loss:0.921862782274375\n",
      "train loss:0.7392817949721997\n",
      "train loss:0.9521880421304582\n",
      "train loss:0.8436930352381559\n",
      "train loss:0.9172927476816024\n",
      "train loss:0.7356777527543277\n",
      "train loss:0.7858132946190851\n",
      "train loss:0.847825047459676\n",
      "train loss:0.892841358322104\n",
      "train loss:0.8641009425175327\n",
      "train loss:0.8597642172404041\n",
      "train loss:0.8956652149237183\n",
      "train loss:0.8778819316349724\n",
      "train loss:0.8890245526707257\n",
      "train loss:0.8755626007333632\n",
      "train loss:0.9426277335231892\n",
      "train loss:0.7236541875270642\n",
      "train loss:0.800703161112003\n",
      "train loss:0.8705188300536687\n",
      "train loss:0.8389758374180706\n",
      "train loss:0.8390229357404694\n",
      "train loss:0.8605552473335901\n",
      "train loss:1.0560132402063096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7288281055385282\n",
      "train loss:0.9105654295045622\n",
      "train loss:0.946931891288359\n",
      "train loss:0.7836160671815859\n",
      "train loss:0.8284240306127748\n",
      "train loss:0.9598358752742742\n",
      "train loss:0.8763780223298744\n",
      "train loss:0.8072243922543406\n",
      "train loss:1.0522033725598798\n",
      "train loss:0.8271361993004857\n",
      "train loss:0.8185968673704308\n",
      "train loss:0.8632388169920531\n",
      "train loss:0.7466601490754162\n",
      "train loss:0.8537352993244351\n",
      "train loss:0.8291516746913772\n",
      "train loss:0.9050948678439176\n",
      "train loss:0.7746489603389309\n",
      "train loss:0.9312085831640838\n",
      "train loss:0.970466665060932\n",
      "train loss:0.6201324949333212\n",
      "train loss:0.9299423444750182\n",
      "train loss:0.8216889170246264\n",
      "train loss:0.850589088129762\n",
      "train loss:0.8669966754251361\n",
      "train loss:0.8632232541630516\n",
      "train loss:0.8740382236821566\n",
      "train loss:0.9631871178684542\n",
      "train loss:0.9437869030752506\n",
      "train loss:0.8030456763096712\n",
      "train loss:0.9476574274657814\n",
      "train loss:0.7432747466841938\n",
      "train loss:0.6640677107275547\n",
      "train loss:1.1050460488729896\n",
      "train loss:0.8494883602487151\n",
      "train loss:0.7789997560652996\n",
      "train loss:0.8347844662993207\n",
      "train loss:0.9274217232664812\n",
      "train loss:0.7766557193205841\n",
      "train loss:0.9047428922546245\n",
      "train loss:0.8426576251362907\n",
      "train loss:0.9977401544234574\n",
      "train loss:0.9183127679902605\n",
      "train loss:0.9789866224772003\n",
      "train loss:0.9841277784206416\n",
      "train loss:0.7852057377565734\n",
      "train loss:0.891464207189151\n",
      "train loss:0.879322902506279\n",
      "train loss:0.8051875255950282\n",
      "train loss:1.0622043695241064\n",
      "train loss:0.9534207928802441\n",
      "train loss:0.9140380019116308\n",
      "train loss:0.8478276511019511\n",
      "train loss:1.1621499612424115\n",
      "train loss:0.8568509649917415\n",
      "train loss:0.8961100553414192\n",
      "train loss:0.820135722883093\n",
      "train loss:0.9456341513604362\n",
      "train loss:0.9220687620416325\n",
      "train loss:0.8458489298233607\n",
      "train loss:0.8473578987281357\n",
      "train loss:0.8078753383998764\n",
      "train loss:0.8121786960688415\n",
      "train loss:0.8889286705175193\n",
      "train loss:0.9863818901918094\n",
      "train loss:0.8741516732841146\n",
      "train loss:0.9153402209515988\n",
      "train loss:0.810444946534914\n",
      "train loss:0.8267980697275532\n",
      "train loss:0.9471736302968885\n",
      "train loss:0.8769345992835667\n",
      "train loss:0.8634668622853421\n",
      "train loss:1.0090098805633647\n",
      "train loss:0.8855361931934442\n",
      "train loss:0.9489069883899801\n",
      "train loss:0.7858105960819911\n",
      "train loss:0.9137159397838326\n",
      "train loss:0.9014246423680712\n",
      "train loss:0.9465324051701655\n",
      "train loss:0.900729182251228\n",
      "train loss:0.893995261612155\n",
      "train loss:0.8291220652686064\n",
      "train loss:0.9194256469771169\n",
      "train loss:0.7547024720322608\n",
      "train loss:0.9556430051488237\n",
      "train loss:0.8517056629296129\n",
      "train loss:0.9193016704015905\n",
      "train loss:0.8032970631771584\n",
      "train loss:0.8795535716856133\n",
      "train loss:0.9114039601535323\n",
      "train loss:0.7228401978683746\n",
      "train loss:0.9138037450841349\n",
      "train loss:0.7776418030258092\n",
      "train loss:0.9968755320901608\n",
      "train loss:0.9075681737827886\n",
      "train loss:0.9697185121550166\n",
      "train loss:0.8260125627077665\n",
      "train loss:0.9115088871461626\n",
      "train loss:1.015232870135599\n",
      "train loss:0.8076676200102763\n",
      "train loss:0.9766854066250904\n",
      "train loss:1.0136673998362364\n",
      "train loss:0.7374874931637854\n",
      "train loss:0.6783466477424805\n",
      "train loss:0.8604834680127699\n",
      "train loss:0.8009545672268951\n",
      "train loss:1.0322373103129607\n",
      "train loss:0.8347603462558385\n",
      "train loss:0.8310923690278719\n",
      "train loss:0.8340162850409325\n",
      "train loss:1.0285957920564395\n",
      "train loss:1.0200312356600794\n",
      "train loss:0.9869055685255118\n",
      "train loss:1.0443098108155837\n",
      "train loss:0.8741673830280314\n",
      "train loss:0.8998725809845047\n",
      "train loss:0.9303678361231097\n",
      "train loss:1.0257481355848947\n",
      "train loss:0.7693148533671581\n",
      "train loss:0.8888549905552985\n",
      "train loss:0.8670842213097534\n",
      "train loss:0.9913216565578971\n",
      "train loss:0.8287810650502374\n",
      "train loss:0.7831047484534923\n",
      "train loss:0.7759265565848031\n",
      "train loss:0.9142713186805284\n",
      "train loss:0.9361930729994985\n",
      "train loss:0.7479979213190531\n",
      "train loss:0.8854246904053663\n",
      "train loss:0.8221088483048535\n",
      "train loss:1.0200906550950941\n",
      "train loss:1.0661308180148588\n",
      "train loss:0.9310005652070221\n",
      "train loss:1.0259405763324312\n",
      "train loss:0.9653683074558169\n",
      "train loss:0.9130649135359605\n",
      "train loss:0.8609698790676245\n",
      "train loss:0.9263511779671008\n",
      "train loss:0.8725441820376605\n",
      "train loss:0.9155611226756579\n",
      "train loss:0.9783926287346212\n",
      "train loss:0.837349989954812\n",
      "train loss:0.9262000778853828\n",
      "train loss:1.026474036006504\n",
      "train loss:0.7505788955523056\n",
      "train loss:0.8310440653912989\n",
      "train loss:0.8566289054241492\n",
      "train loss:0.9118261317502907\n",
      "train loss:0.8464632697463812\n",
      "train loss:0.8977057175944502\n",
      "train loss:1.0661420036868927\n",
      "train loss:0.8319784223973494\n",
      "train loss:0.8408681666335573\n",
      "train loss:1.05652277359286\n",
      "train loss:0.9022003641869583\n",
      "train loss:0.6315319041391944\n",
      "train loss:0.8268580680375682\n",
      "train loss:0.9258353635665109\n",
      "train loss:0.8217452400761921\n",
      "train loss:0.9773387754553221\n",
      "train loss:0.7049601459143434\n",
      "train loss:0.92126056778744\n",
      "train loss:0.8499705235267322\n",
      "train loss:0.8134412676114898\n",
      "train loss:0.8248865899481885\n",
      "train loss:0.8466072927829726\n",
      "train loss:0.7600383501260937\n",
      "train loss:0.7587649373531984\n",
      "train loss:0.809879926345414\n",
      "train loss:0.7854173463916956\n",
      "train loss:0.9214492179838174\n",
      "train loss:0.9642927100307775\n",
      "train loss:0.7751458789037273\n",
      "train loss:0.7967040374978516\n",
      "train loss:0.8117877213706496\n",
      "train loss:0.9439154247079924\n",
      "train loss:0.8712733911379077\n",
      "train loss:0.6813767169465044\n",
      "train loss:0.7621933114355578\n",
      "train loss:0.8659971267194684\n",
      "train loss:0.8290569890847838\n",
      "train loss:0.8755979118493394\n",
      "train loss:0.750840467825073\n",
      "train loss:0.9191220323493279\n",
      "train loss:0.8419074125936413\n",
      "train loss:0.7349734362749141\n",
      "train loss:0.8956796804347643\n",
      "train loss:0.9678316756123171\n",
      "train loss:0.6019940555330752\n",
      "train loss:0.9247266459344958\n",
      "train loss:0.854785155208141\n",
      "train loss:0.8337418685705839\n",
      "train loss:0.9071077944861505\n",
      "train loss:0.837769441266853\n",
      "train loss:0.9180366205211982\n",
      "train loss:0.6958887552048542\n",
      "train loss:0.9546225218920363\n",
      "train loss:0.8165749168754899\n",
      "train loss:0.8992235457833835\n",
      "train loss:0.810777396475477\n",
      "train loss:0.8634738212849221\n",
      "train loss:0.908021627822365\n",
      "train loss:0.9008234201982248\n",
      "train loss:0.8482263581689564\n",
      "train loss:0.7999922853168547\n",
      "train loss:0.6745045310359091\n",
      "train loss:0.9867652449974256\n",
      "train loss:0.8591750018400045\n",
      "train loss:0.9027029806362863\n",
      "train loss:1.012916367600768\n",
      "train loss:0.8491939318117171\n",
      "train loss:0.8308985714907391\n",
      "train loss:0.8566823539677374\n",
      "train loss:0.8526332508777756\n",
      "train loss:0.9385178722083916\n",
      "train loss:0.9903582235003597\n",
      "train loss:0.9336412234736362\n",
      "train loss:0.7848683157494524\n",
      "train loss:0.8120771783710304\n",
      "train loss:1.035235564084056\n",
      "train loss:0.7846210027107852\n",
      "train loss:0.9224141069199727\n",
      "train loss:0.8111826664966209\n",
      "train loss:1.001150845593549\n",
      "train loss:0.8776242089237997\n",
      "train loss:0.6848217782327243\n",
      "train loss:0.8659427075871011\n",
      "train loss:0.7556634480609344\n",
      "train loss:1.0480129379894552\n",
      "train loss:0.9439324933314319\n",
      "train loss:0.859745567053633\n",
      "train loss:0.7813149324258255\n",
      "train loss:0.803652579804063\n",
      "train loss:0.6568936116429538\n",
      "train loss:0.8824320265403759\n",
      "train loss:0.8732381628211193\n",
      "train loss:0.8833797267497548\n",
      "train loss:0.8788685946318483\n",
      "train loss:1.1480777627881378\n",
      "train loss:0.8011548344066067\n",
      "train loss:0.8803393786568523\n",
      "train loss:0.8693917169626201\n",
      "train loss:0.953348371371106\n",
      "train loss:0.8512526540682033\n",
      "train loss:0.9244882727240618\n",
      "train loss:0.8561519627787904\n",
      "train loss:0.8917486949092176\n",
      "train loss:0.854663449827646\n",
      "train loss:0.7403113034626216\n",
      "train loss:0.9305780992145738\n",
      "train loss:0.9614448533939489\n",
      "train loss:1.0092696703175421\n",
      "train loss:0.8510733582834287\n",
      "train loss:0.8371595158055544\n",
      "train loss:0.8698628030303466\n",
      "train loss:0.9599683260386488\n",
      "train loss:0.8844351481933375\n",
      "train loss:0.8757416506754017\n",
      "train loss:0.7631308135233686\n",
      "train loss:0.866611267210527\n",
      "train loss:0.787879468620153\n",
      "train loss:0.7098305106556632\n",
      "train loss:1.0641328971423227\n",
      "train loss:0.8329108707599329\n",
      "train loss:0.9681911488474222\n",
      "train loss:0.9315736056504873\n",
      "train loss:0.8879865987330666\n",
      "train loss:0.6895204634408594\n",
      "train loss:0.8540463658256833\n",
      "train loss:0.8539551933352126\n",
      "train loss:0.8421981038811138\n",
      "train loss:1.0462844756846932\n",
      "train loss:0.7778864893963404\n",
      "train loss:0.8808930256812896\n",
      "train loss:0.7263297757367053\n",
      "train loss:0.9202268740390863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9613757770531471\n",
      "train loss:0.8686928132477411\n",
      "train loss:1.0382310976775218\n",
      "train loss:0.8763499572194668\n",
      "train loss:0.9862691434287075\n",
      "train loss:1.2242520289656094\n",
      "train loss:0.8398043703701107\n",
      "train loss:0.7887599963095372\n",
      "train loss:0.8826688666680085\n",
      "train loss:0.773186845028897\n",
      "train loss:0.9930105458861196\n",
      "train loss:0.8082747182386444\n",
      "train loss:1.0742021241513044\n",
      "train loss:0.8956612456180462\n",
      "train loss:0.8595692989443191\n",
      "train loss:0.7426089922491828\n",
      "train loss:0.8340747548469749\n",
      "train loss:0.8741040628878853\n",
      "train loss:1.039910229048169\n",
      "train loss:0.7986035269406009\n",
      "train loss:1.0018888008946747\n",
      "train loss:0.8593217755039352\n",
      "train loss:0.9596665990589963\n",
      "train loss:0.7692958418099157\n",
      "train loss:0.9447908583375622\n",
      "train loss:0.9435212330931558\n",
      "train loss:0.9238683383592391\n",
      "train loss:1.0339613448480955\n",
      "train loss:0.7335912593308873\n",
      "train loss:0.8414050353431896\n",
      "train loss:0.8967988309210537\n",
      "train loss:0.8391692892231497\n",
      "train loss:0.6656549713479113\n",
      "train loss:0.847264851122395\n",
      "train loss:0.97646979431479\n",
      "train loss:0.8377688423475756\n",
      "train loss:0.8738961612494264\n",
      "train loss:0.7316733632213693\n",
      "train loss:0.9209073803460412\n",
      "train loss:0.7887411923667083\n",
      "train loss:0.655294053151011\n",
      "train loss:0.7139131207590164\n",
      "train loss:0.8947959158493402\n",
      "train loss:0.9095441631492632\n",
      "train loss:0.910594637529574\n",
      "train loss:0.8213173901145531\n",
      "train loss:0.8404395315973088\n",
      "train loss:0.7669613190354275\n",
      "train loss:0.9263749915997493\n",
      "train loss:0.7674731140604182\n",
      "train loss:0.9375610676102284\n",
      "train loss:0.9305123917490874\n",
      "train loss:0.7982910455265724\n",
      "train loss:0.8548834620519264\n",
      "train loss:1.0536984163143694\n",
      "train loss:0.933715109593197\n",
      "train loss:0.711735582238161\n",
      "train loss:0.8687196887479567\n",
      "train loss:0.6722501233928811\n",
      "train loss:0.9548805382116522\n",
      "train loss:0.7652727455380338\n",
      "train loss:0.8300648376580678\n",
      "train loss:0.8846787507450743\n",
      "train loss:0.8043910434644566\n",
      "train loss:0.7750657247922628\n",
      "train loss:0.9041467758012718\n",
      "train loss:0.9034765991999888\n",
      "train loss:0.7083870984457977\n",
      "train loss:0.8826236570800993\n",
      "train loss:0.9731996779599414\n",
      "train loss:0.8386144297180459\n",
      "train loss:0.8841246290960447\n",
      "train loss:0.927328379491982\n",
      "train loss:0.9048299041995356\n",
      "train loss:0.960446455351731\n",
      "train loss:0.9132723866741317\n",
      "train loss:0.8531609600544825\n",
      "train loss:0.8896006033228058\n",
      "train loss:0.94479871940574\n",
      "train loss:0.7820864667680383\n",
      "train loss:0.9452314026881882\n",
      "train loss:0.8449934561214217\n",
      "train loss:0.7523524255761407\n",
      "train loss:0.9187463543141274\n",
      "train loss:0.885923500462538\n",
      "train loss:0.9927902760325186\n",
      "train loss:0.9475015610923656\n",
      "train loss:0.788677565788841\n",
      "train loss:0.8055679200017161\n",
      "train loss:0.7838981224144094\n",
      "train loss:0.7727329214204931\n",
      "train loss:0.8071603344483149\n",
      "train loss:0.8558006770860714\n",
      "train loss:0.897380593885407\n",
      "train loss:0.7457758438336285\n",
      "train loss:0.6922265083905899\n",
      "train loss:0.8352541629659324\n",
      "train loss:0.8171218953906859\n",
      "train loss:0.8992582621985818\n",
      "train loss:0.7365210837858618\n",
      "train loss:0.8620864354998773\n",
      "train loss:1.0290634658537956\n",
      "train loss:1.0905016977931232\n",
      "train loss:0.9372639293271287\n",
      "train loss:0.8367409440844947\n",
      "train loss:0.9471773305617774\n",
      "train loss:0.7115032388984954\n",
      "train loss:0.9737427506922823\n",
      "train loss:1.0075456083170935\n",
      "train loss:0.8637126627674161\n",
      "train loss:0.9854751151769725\n",
      "train loss:0.7932731066575713\n",
      "train loss:0.6979053950150903\n",
      "train loss:0.8327376496010663\n",
      "train loss:0.7977722906796961\n",
      "train loss:0.9449510258777266\n",
      "train loss:0.8166492829150327\n",
      "train loss:0.7863311513315344\n",
      "train loss:0.9239936727733133\n",
      "train loss:0.8211481985514868\n",
      "train loss:0.7852835664141655\n",
      "train loss:0.7736321673367484\n",
      "train loss:0.8441168627417265\n",
      "train loss:0.953175820979504\n",
      "train loss:0.7214910963394336\n",
      "train loss:0.7694874980857465\n",
      "train loss:1.0391706837797117\n",
      "train loss:0.911620622054084\n",
      "train loss:0.9930242514480002\n",
      "train loss:0.875329774650938\n",
      "train loss:0.9170899081815387\n",
      "train loss:0.9012673098466223\n",
      "train loss:0.7929853583583799\n",
      "train loss:0.9292021793446554\n",
      "train loss:0.7531671965667189\n",
      "train loss:0.9149618132973093\n",
      "train loss:0.8446339131982756\n",
      "train loss:0.8512548358392393\n",
      "train loss:0.8517392251150426\n",
      "train loss:1.1355343468907786\n",
      "train loss:0.7581301194264146\n",
      "train loss:1.0068749974355053\n",
      "train loss:0.8546627335573517\n",
      "train loss:0.8470196976325763\n",
      "train loss:0.9206455620931828\n",
      "train loss:0.8829273673052969\n",
      "train loss:0.9795734631662676\n",
      "train loss:0.8464260680622142\n",
      "train loss:0.945285700943173\n",
      "train loss:0.8947446365469075\n",
      "train loss:0.9942739748779309\n",
      "train loss:0.8047949662674897\n",
      "train loss:0.758525625824468\n",
      "train loss:0.9318116995965863\n",
      "train loss:0.8703853156496036\n",
      "train loss:0.7804147010515742\n",
      "train loss:1.0605010872189866\n",
      "train loss:0.9633022885074147\n",
      "train loss:0.8424189211870619\n",
      "train loss:0.8346837479326952\n",
      "train loss:0.7731068350565278\n",
      "train loss:0.8918198232220298\n",
      "train loss:0.8544446638991603\n",
      "train loss:1.0754531584892508\n",
      "train loss:0.855773667505272\n",
      "train loss:0.7330781598019763\n",
      "train loss:0.7963034683417446\n",
      "train loss:0.7442498917356555\n",
      "train loss:0.8786876087738222\n",
      "train loss:0.8210571779043037\n",
      "train loss:0.90209475654445\n",
      "train loss:0.7407889295217206\n",
      "train loss:0.9538516385114238\n",
      "train loss:0.913694805156142\n",
      "train loss:0.8307675632380976\n",
      "train loss:0.5503177445929327\n",
      "train loss:0.8017442064574044\n",
      "train loss:1.042254361040789\n",
      "train loss:0.9190297485401279\n",
      "train loss:0.9916307496876436\n",
      "train loss:0.76266337004568\n",
      "train loss:0.9059755507081051\n",
      "train loss:0.8450499834144712\n",
      "train loss:0.8845882232925157\n",
      "train loss:0.8536058383482282\n",
      "train loss:0.8294413742860164\n",
      "train loss:0.9368834844398283\n",
      "train loss:0.6844554919619843\n",
      "train loss:0.8353705573389495\n",
      "train loss:0.8644109333209787\n",
      "train loss:0.9561726863888738\n",
      "train loss:0.8293148067925123\n",
      "train loss:0.7976637695454017\n",
      "train loss:0.7628817719206203\n",
      "train loss:0.9266259565252294\n",
      "train loss:0.8408609005441225\n",
      "train loss:0.7189559959215813\n",
      "train loss:0.9235525759598814\n",
      "train loss:0.9277273170465322\n",
      "train loss:0.7373473484678008\n",
      "train loss:0.9172463770340856\n",
      "train loss:0.9031442079899424\n",
      "train loss:0.928348570073175\n",
      "train loss:0.8870898629005461\n",
      "train loss:0.8823488621602644\n",
      "train loss:0.9695205539454405\n",
      "train loss:0.9549333351728518\n",
      "train loss:0.8241565430911386\n",
      "train loss:0.7898491543928381\n",
      "train loss:0.8653999259463931\n",
      "train loss:0.9960249473476179\n",
      "train loss:0.9440588290721196\n",
      "train loss:0.970663921462985\n",
      "train loss:0.906075985751707\n",
      "train loss:0.8100904242624946\n",
      "train loss:0.9101278982390754\n",
      "train loss:0.9427880110390096\n",
      "train loss:0.8431872890117795\n",
      "train loss:0.9920892212154752\n",
      "train loss:1.1015134694109168\n",
      "train loss:0.7801857426801074\n",
      "train loss:0.7265298734594086\n",
      "train loss:0.9546413843879451\n",
      "train loss:0.8404472425997086\n",
      "=== epoch:16, train acc:0.997, test acc:0.99 ===\n",
      "train loss:1.0676705105580415\n",
      "train loss:0.9262447704563331\n",
      "train loss:0.895556159616024\n",
      "train loss:0.921582822404234\n",
      "train loss:0.847660718116898\n",
      "train loss:0.9210423651333559\n",
      "train loss:0.9288004844330184\n",
      "train loss:0.8833405432467839\n",
      "train loss:1.0024942909310948\n",
      "train loss:0.8718394552293716\n",
      "train loss:0.9508860286942188\n",
      "train loss:1.015759402194075\n",
      "train loss:0.8395797230596963\n",
      "train loss:0.9294868363981386\n",
      "train loss:0.87772682660816\n",
      "train loss:0.7948212715374292\n",
      "train loss:0.813510367322621\n",
      "train loss:0.9240638168272565\n",
      "train loss:0.8465397256610657\n",
      "train loss:0.9555075506747436\n",
      "train loss:0.8467374598215504\n",
      "train loss:0.7021425049652612\n",
      "train loss:0.851270079597941\n",
      "train loss:0.6906708130898616\n",
      "train loss:0.9635164394650834\n",
      "train loss:0.8322886521282402\n",
      "train loss:0.9316252837467119\n",
      "train loss:0.8277157606525067\n",
      "train loss:0.8256340794323417\n",
      "train loss:0.9481573582206231\n",
      "train loss:0.8937384996030527\n",
      "train loss:0.7106029629714762\n",
      "train loss:0.8196738625030378\n",
      "train loss:0.8774003246237768\n",
      "train loss:0.8295098500651085\n",
      "train loss:0.7802277458893775\n",
      "train loss:1.16222386260951\n",
      "train loss:0.890090393227788\n",
      "train loss:0.9039714695413139\n",
      "train loss:0.9405512636730541\n",
      "train loss:0.9392282273807884\n",
      "train loss:0.7991222566170619\n",
      "train loss:0.9891514581745446\n",
      "train loss:0.8944852527416155\n",
      "train loss:0.8223627504302503\n",
      "train loss:0.861722713824569\n",
      "train loss:0.8146024561845181\n",
      "train loss:0.8366250493978251\n",
      "train loss:0.8193122830603595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8261645722123102\n",
      "train loss:0.9434482676969648\n",
      "train loss:0.7836866351927354\n",
      "train loss:0.9659963968474594\n",
      "train loss:0.8846751745769964\n",
      "train loss:0.9275427108055788\n",
      "train loss:0.9213920860203839\n",
      "train loss:0.8861736714765658\n",
      "train loss:0.7913504048564165\n",
      "train loss:0.8019134232206855\n",
      "train loss:0.8662913686109662\n",
      "train loss:0.7843705357567978\n",
      "train loss:0.9238522770210096\n",
      "train loss:0.8828309665963762\n",
      "train loss:0.9646129583037536\n",
      "train loss:0.9359629735749695\n",
      "train loss:0.9556789214791721\n",
      "train loss:0.8266171570863942\n",
      "train loss:0.8379626240869088\n",
      "train loss:0.8278641219717929\n",
      "train loss:0.8894461272086709\n",
      "train loss:0.982934504846351\n",
      "train loss:0.9234028085292253\n",
      "train loss:0.9186113543686626\n",
      "train loss:0.8242366899392107\n",
      "train loss:0.7709707582545614\n",
      "train loss:0.789222224322479\n",
      "train loss:0.755960049060361\n",
      "train loss:0.9673689814755443\n",
      "train loss:0.7399059569678867\n",
      "train loss:0.8596109615035192\n",
      "train loss:0.8042301556592578\n",
      "train loss:0.8581120318311348\n",
      "train loss:0.874075520815725\n",
      "train loss:0.742644700081375\n",
      "train loss:0.8784090637154912\n",
      "train loss:0.8899880482470475\n",
      "train loss:0.8298629861025444\n",
      "train loss:0.7963613584263177\n",
      "train loss:0.768481721339985\n",
      "train loss:1.0103093819007605\n",
      "train loss:0.8338101042371073\n",
      "train loss:0.893116886597459\n",
      "train loss:1.068641246317552\n",
      "train loss:0.7011655617737093\n",
      "train loss:0.8538434333869337\n",
      "train loss:0.9004233046042418\n",
      "train loss:0.9932771348987209\n",
      "train loss:0.9080625878858488\n",
      "train loss:0.76949140282992\n",
      "train loss:0.7959584261825218\n",
      "train loss:0.8373148197525941\n",
      "train loss:0.8732801810043057\n",
      "train loss:0.8772687246030262\n",
      "train loss:1.0967672321414261\n",
      "train loss:0.8558303832124432\n",
      "train loss:0.8811299211024775\n",
      "train loss:0.9460317845821613\n",
      "train loss:0.856513082171126\n",
      "train loss:0.9156919816309099\n",
      "train loss:0.8025035520202102\n",
      "train loss:0.8659270700701878\n",
      "train loss:0.9997594167907004\n",
      "train loss:0.9630395736343088\n",
      "train loss:0.8972558790033789\n",
      "train loss:0.9016333348730307\n",
      "train loss:0.7150893542193545\n",
      "train loss:0.9416471997650255\n",
      "train loss:0.893561030326193\n",
      "train loss:0.9367595857621202\n",
      "train loss:0.9451264307483237\n",
      "train loss:0.6415323346422003\n",
      "train loss:0.8570019491656509\n",
      "train loss:0.9407421062375383\n",
      "train loss:0.9137739900113822\n",
      "train loss:1.0264867840401395\n",
      "train loss:0.719676308662314\n",
      "train loss:1.0488375384866122\n",
      "train loss:0.8767590840740789\n",
      "train loss:0.7863331034573616\n",
      "train loss:0.887822307605203\n",
      "train loss:0.9384192384401547\n",
      "train loss:0.8010243750981225\n",
      "train loss:0.7089687179851536\n",
      "train loss:0.8735677070555156\n",
      "train loss:0.9169039529583679\n",
      "train loss:0.7321385449926079\n",
      "train loss:1.0129311404145023\n",
      "train loss:0.860836355924957\n",
      "train loss:0.9251493358154199\n",
      "train loss:0.6964033924893808\n",
      "train loss:0.8654100474261148\n",
      "train loss:1.043237519993967\n",
      "train loss:0.9372355197820137\n",
      "train loss:0.8389774935747393\n",
      "train loss:0.809339454087669\n",
      "train loss:1.0006284092401025\n",
      "train loss:0.8673673603475173\n",
      "train loss:0.7812980689903374\n",
      "train loss:0.9258711421377284\n",
      "train loss:0.9208976825177966\n",
      "train loss:0.851579632852065\n",
      "train loss:0.9278992627999068\n",
      "train loss:0.7821500996697135\n",
      "train loss:0.7907249083364337\n",
      "train loss:1.0645946838242728\n",
      "train loss:0.7905192290344893\n",
      "train loss:0.9240038176939018\n",
      "train loss:0.8922732544694355\n",
      "train loss:0.7331548568409064\n",
      "train loss:0.886715169708392\n",
      "train loss:0.8291187203273808\n",
      "train loss:0.8031420943877915\n",
      "train loss:0.9120314425390649\n",
      "train loss:0.8827840938826056\n",
      "train loss:0.7520861499393827\n",
      "train loss:0.7967661606914317\n",
      "train loss:0.9269065316010492\n",
      "train loss:0.8167125197550332\n",
      "train loss:0.862047005636336\n",
      "train loss:1.0586575030489596\n",
      "train loss:0.7782296778969695\n",
      "train loss:0.7248953316942724\n",
      "train loss:0.8841668886315328\n",
      "train loss:0.7012090902369973\n",
      "train loss:0.9369901227367812\n",
      "train loss:0.8213360159652554\n",
      "train loss:0.8326226276967503\n",
      "train loss:0.9089026354649619\n",
      "train loss:0.7281055412548545\n",
      "train loss:0.7791508609963933\n",
      "train loss:0.7970559083209907\n",
      "train loss:0.9784390696596453\n",
      "train loss:0.9559256615526678\n",
      "train loss:0.7690214545512032\n",
      "train loss:0.9138438491981412\n",
      "train loss:0.8993307322356877\n",
      "train loss:0.8239688215471276\n",
      "train loss:0.8317819649393027\n",
      "train loss:0.9877870570862963\n",
      "train loss:0.8051150394014236\n",
      "train loss:0.9464867922433642\n",
      "train loss:0.8244156424619797\n",
      "train loss:0.743424837512872\n",
      "train loss:0.7805275157931778\n",
      "train loss:0.8969025092969445\n",
      "train loss:0.8403875849669221\n",
      "train loss:0.8572142441601512\n",
      "train loss:0.9602161726507543\n",
      "train loss:0.9063777292910448\n",
      "train loss:0.9322023519585784\n",
      "train loss:0.8184633629132905\n",
      "train loss:1.0053793385874183\n",
      "train loss:0.9271177175570101\n",
      "train loss:0.9033649958294693\n",
      "train loss:0.7950883649846979\n",
      "train loss:0.941779268979039\n",
      "train loss:0.8704820796081798\n",
      "train loss:0.8134797374672637\n",
      "train loss:0.8435913400920839\n",
      "train loss:0.9921775752286319\n",
      "train loss:0.9989197507026613\n",
      "train loss:0.7605706110806095\n",
      "train loss:0.8391503468579425\n",
      "train loss:0.8553868404487938\n",
      "train loss:0.8409735918869721\n",
      "train loss:0.9122551492044143\n",
      "train loss:0.9314044393506237\n",
      "train loss:0.9413019082531736\n",
      "train loss:0.9445706973063808\n",
      "train loss:0.8597021885068301\n",
      "train loss:0.857622790653633\n",
      "train loss:0.8501812902327347\n",
      "train loss:0.7814568166034601\n",
      "train loss:0.9860271668839704\n",
      "train loss:0.9459855607171959\n",
      "train loss:0.8900758324784128\n",
      "train loss:0.7989274510441079\n",
      "train loss:0.8922659482838968\n",
      "train loss:1.008721939511218\n",
      "train loss:0.9008160156519387\n",
      "train loss:0.7974390749664757\n",
      "train loss:0.853916539738741\n",
      "train loss:0.8627657400396679\n",
      "train loss:1.0190984832133638\n",
      "train loss:0.8988282430994994\n",
      "train loss:0.9405184135488592\n",
      "train loss:0.8785119537593242\n",
      "train loss:0.8251331570879483\n",
      "train loss:0.7399506321841598\n",
      "train loss:0.8136905503779794\n",
      "train loss:0.8974301738131821\n",
      "train loss:0.9148809763144099\n",
      "train loss:0.7256968917514678\n",
      "train loss:0.8877713872042793\n",
      "train loss:0.9058256464783341\n",
      "train loss:0.7499953448346872\n",
      "train loss:0.9129318384801131\n",
      "train loss:0.810786182725885\n",
      "train loss:0.7148367402922399\n",
      "train loss:0.8449039412389884\n",
      "train loss:0.8658991033967856\n",
      "train loss:0.9433449532346788\n",
      "train loss:0.8208653953158037\n",
      "train loss:0.8464995692505631\n",
      "train loss:0.8747715126930635\n",
      "train loss:0.9453235782315066\n",
      "train loss:0.763461963602891\n",
      "train loss:0.6989832134949334\n",
      "train loss:0.7861651199680315\n",
      "train loss:0.8850917074593475\n",
      "train loss:0.8394332401177668\n",
      "train loss:0.909501753917627\n",
      "train loss:0.9091822574342647\n",
      "train loss:0.8070242728326718\n",
      "train loss:0.8517058033791646\n",
      "train loss:0.9325623840728556\n",
      "train loss:0.9819150108423499\n",
      "train loss:0.8759141959329412\n",
      "train loss:0.6776642429683716\n",
      "train loss:0.8200334547117835\n",
      "train loss:0.9243624705118962\n",
      "train loss:0.91653607592706\n",
      "train loss:0.9533684998858805\n",
      "train loss:0.8508347919206724\n",
      "train loss:0.9017351601200115\n",
      "train loss:0.8370893658758597\n",
      "train loss:0.9307678454701047\n",
      "train loss:0.8835622021734477\n",
      "train loss:0.9483922541091271\n",
      "train loss:0.9263909374377143\n",
      "train loss:0.8965865199172106\n",
      "train loss:0.8558322715979411\n",
      "train loss:0.9670203976326731\n",
      "train loss:0.9063889989478171\n",
      "train loss:0.8736920272403523\n",
      "train loss:1.0230544777030837\n",
      "train loss:0.8814831846684816\n",
      "train loss:0.9114343502789031\n",
      "train loss:0.8395580280308973\n",
      "train loss:0.7610865636321038\n",
      "train loss:0.8185840198403195\n",
      "train loss:0.8244695083460304\n",
      "train loss:0.9470592744512863\n",
      "train loss:0.8786148607326978\n",
      "train loss:0.8114897360740443\n",
      "train loss:1.0144858420220058\n",
      "train loss:0.8797240141265698\n",
      "train loss:0.9629021245780638\n",
      "train loss:0.7035351964651181\n",
      "train loss:0.7764540685441829\n",
      "train loss:0.852864394310395\n",
      "train loss:0.6334103599556898\n",
      "train loss:0.9823659932067217\n",
      "train loss:0.9408506863652016\n",
      "train loss:0.8606951138997794\n",
      "train loss:0.892953976505421\n",
      "train loss:0.944378394601153\n",
      "train loss:0.9061065143173288\n",
      "train loss:1.0812178810337336\n",
      "train loss:0.8180213115924978\n",
      "train loss:0.9424227389040317\n",
      "train loss:1.0203053422988455\n",
      "train loss:0.8164134977670124\n",
      "train loss:0.8598949103653069\n",
      "train loss:0.7582149974334235\n",
      "train loss:0.9036641082795424\n",
      "train loss:0.8949441558626091\n",
      "train loss:0.9882561666749882\n",
      "train loss:0.670555557819459\n",
      "train loss:0.9400555223362672\n",
      "train loss:0.8494727100633784\n",
      "train loss:0.8384733734461532\n",
      "train loss:0.7666470033002477\n",
      "train loss:0.8479552128911643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8774235427846442\n",
      "train loss:1.001736161034909\n",
      "train loss:0.9084966997592729\n",
      "train loss:0.9019768014350181\n",
      "train loss:0.858160703618331\n",
      "train loss:1.1136070121124815\n",
      "train loss:1.0631818596424014\n",
      "train loss:0.8128408607443066\n",
      "train loss:0.8423861821294925\n",
      "train loss:0.8572895119991019\n",
      "train loss:0.9347436578988189\n",
      "train loss:0.8963546656784993\n",
      "train loss:0.8414018523661997\n",
      "train loss:0.8535035790488545\n",
      "train loss:0.8151121269276855\n",
      "train loss:0.9034677302402564\n",
      "train loss:0.8626837715568472\n",
      "train loss:0.899861137242184\n",
      "train loss:0.8307203605737868\n",
      "train loss:0.8622072692981537\n",
      "train loss:0.952016176726202\n",
      "train loss:0.7448786273912984\n",
      "train loss:0.8943487211392374\n",
      "train loss:0.7268084766785989\n",
      "train loss:0.7149770975537798\n",
      "train loss:0.841747176043142\n",
      "train loss:0.9892841261037808\n",
      "train loss:0.9346327780040227\n",
      "train loss:0.9176226572628912\n",
      "train loss:0.8003182111973576\n",
      "train loss:1.0462562476245034\n",
      "train loss:0.7925224036787166\n",
      "train loss:0.9768225888436071\n",
      "train loss:0.9988315238253156\n",
      "train loss:0.7738890242746812\n",
      "train loss:0.9813191498298351\n",
      "train loss:0.7974782710959688\n",
      "train loss:0.8955191906519768\n",
      "train loss:0.8366795514892614\n",
      "train loss:0.7937499795231545\n",
      "train loss:0.8760334315581528\n",
      "train loss:0.9689278773077779\n",
      "train loss:0.7138733074730631\n",
      "train loss:0.8852338516710945\n",
      "train loss:0.8221735500192228\n",
      "train loss:0.708031423573291\n",
      "train loss:0.8891630540731512\n",
      "train loss:0.7619830800919095\n",
      "train loss:0.9465998679844396\n",
      "train loss:1.0554979547881829\n",
      "train loss:0.9734702910991234\n",
      "train loss:0.9157979152494136\n",
      "train loss:0.8741219467985003\n",
      "train loss:1.0416510635198992\n",
      "train loss:1.0451257916829042\n",
      "train loss:0.8664332007395052\n",
      "train loss:0.9822535013721959\n",
      "train loss:0.8846235187308803\n",
      "train loss:0.952540454773378\n",
      "train loss:0.9372582730826262\n",
      "train loss:0.8736376643455768\n",
      "train loss:0.9464929889619786\n",
      "train loss:0.6697418919168263\n",
      "train loss:0.8363886377784732\n",
      "train loss:0.9369497819166227\n",
      "train loss:0.8331105526835648\n",
      "train loss:0.8745206624147773\n",
      "train loss:1.0380990258723386\n",
      "train loss:0.9298134141108624\n",
      "train loss:0.9266421728675848\n",
      "train loss:0.8407387818491648\n",
      "train loss:0.8110252470967017\n",
      "train loss:0.8133531666729924\n",
      "train loss:0.8070176371962969\n",
      "train loss:0.8713973538788403\n",
      "train loss:0.8465927086862511\n",
      "train loss:0.7795975967185772\n",
      "train loss:0.9827267144769516\n",
      "train loss:0.8247353480169469\n",
      "train loss:0.8805212814041249\n",
      "train loss:0.8139927692149979\n",
      "train loss:0.8609511038889679\n",
      "train loss:0.926391027771476\n",
      "train loss:0.9106338005755761\n",
      "train loss:0.7730052707483169\n",
      "train loss:0.6541512175249167\n",
      "train loss:0.9723042169751747\n",
      "train loss:0.8991310847485096\n",
      "train loss:0.9700466188052924\n",
      "train loss:0.934629266690396\n",
      "train loss:0.780829578795528\n",
      "train loss:0.832764209138826\n",
      "train loss:0.8172133354720071\n",
      "train loss:0.9473399096476557\n",
      "train loss:0.7443031779828749\n",
      "train loss:0.8189862518720894\n",
      "train loss:0.8071732785159901\n",
      "train loss:0.8712385803816134\n",
      "train loss:0.8001723808042991\n",
      "train loss:0.7314415398684521\n",
      "train loss:0.8929409106773015\n",
      "train loss:0.8275209929188615\n",
      "train loss:0.8063020493393878\n",
      "train loss:0.7617833904066826\n",
      "train loss:0.8360552132227943\n",
      "train loss:0.9602261236524393\n",
      "train loss:0.9448669493047801\n",
      "train loss:0.8170478896697372\n",
      "train loss:0.8323946479561394\n",
      "train loss:0.8059275001374766\n",
      "train loss:0.9383795624321736\n",
      "train loss:1.0061208738409584\n",
      "train loss:1.0051257946167567\n",
      "train loss:1.0208724524408097\n",
      "train loss:0.8026780592820478\n",
      "train loss:0.9507331280042041\n",
      "train loss:0.8124651426633902\n",
      "train loss:0.9743912625581969\n",
      "train loss:0.8897989999134168\n",
      "train loss:1.023849488024878\n",
      "train loss:1.1073261273639614\n",
      "train loss:0.8940176651846302\n",
      "train loss:0.9108404273470364\n",
      "train loss:0.9599966686544577\n",
      "train loss:0.9671118125044054\n",
      "train loss:0.6880247656036715\n",
      "train loss:0.892579880545583\n",
      "train loss:0.807995154786356\n",
      "train loss:1.023577225968411\n",
      "train loss:0.6890845702317976\n",
      "train loss:0.9382186633148305\n",
      "train loss:0.6772497496645561\n",
      "train loss:0.7481974891097513\n",
      "train loss:0.9305529144767277\n",
      "train loss:0.8363825614242206\n",
      "train loss:0.7672782816863912\n",
      "train loss:0.8188207602334668\n",
      "train loss:0.8910588534257138\n",
      "train loss:0.8502876684817909\n",
      "train loss:0.8379799322523774\n",
      "train loss:0.8642826765911851\n",
      "train loss:0.936734930531832\n",
      "train loss:1.0887015610813984\n",
      "train loss:0.8100463496589733\n",
      "train loss:0.9354679326651985\n",
      "train loss:0.9019107202340244\n",
      "train loss:0.7870632938117401\n",
      "train loss:0.8640417372930449\n",
      "train loss:0.9174322256493306\n",
      "train loss:0.8840608333142502\n",
      "train loss:0.7117236065565008\n",
      "train loss:0.8435102494279905\n",
      "train loss:0.8331484219062061\n",
      "train loss:0.800656722699964\n",
      "train loss:0.9573514560572954\n",
      "train loss:1.0255688347953347\n",
      "train loss:0.8771677695193151\n",
      "train loss:0.8905834861496619\n",
      "train loss:0.8465286138602747\n",
      "train loss:0.8634252441368159\n",
      "train loss:1.0228878340938108\n",
      "train loss:1.0413595081239755\n",
      "train loss:0.8318383776218415\n",
      "train loss:0.8667052609891013\n",
      "train loss:0.9039543675888444\n",
      "train loss:1.06637443600695\n",
      "train loss:0.9239586343921455\n",
      "train loss:0.8512806772878517\n",
      "train loss:0.7410361114973285\n",
      "train loss:0.9162561190253017\n",
      "train loss:0.836991185964369\n",
      "train loss:0.8533204646177542\n",
      "train loss:0.627244588029006\n",
      "train loss:0.8011369551318288\n",
      "train loss:0.7795061173134699\n",
      "train loss:0.9010756536005586\n",
      "train loss:0.8974091695774925\n",
      "train loss:1.0861805320918512\n",
      "train loss:0.829978208988948\n",
      "train loss:0.9178436735127012\n",
      "train loss:0.8786970821193028\n",
      "train loss:1.0041776779766642\n",
      "train loss:0.9415174147219021\n",
      "train loss:0.9021986100542319\n",
      "train loss:1.1829312404787862\n",
      "train loss:0.9249999720356105\n",
      "train loss:0.9978835767920698\n",
      "train loss:0.9144708125459396\n",
      "train loss:0.8272392235791088\n",
      "train loss:0.7829736545377328\n",
      "train loss:0.9441002069332147\n",
      "train loss:0.7537021065544518\n",
      "train loss:0.8086148221834805\n",
      "train loss:0.9725710284140533\n",
      "train loss:0.9698445169979901\n",
      "train loss:1.0203132484287742\n",
      "train loss:0.9903682405111014\n",
      "train loss:0.8441920247882447\n",
      "train loss:0.7419401969703087\n",
      "train loss:1.0061491915198177\n",
      "train loss:0.8733513887937359\n",
      "train loss:0.8518559014203348\n",
      "train loss:0.7673480241862595\n",
      "train loss:1.0201527209009278\n",
      "train loss:0.9575484677188169\n",
      "train loss:0.7979710603716756\n",
      "train loss:0.9316468964508176\n",
      "train loss:0.70096776556569\n",
      "train loss:0.808266609486979\n",
      "train loss:0.7447176703304059\n",
      "train loss:0.9540824246933289\n",
      "train loss:1.0055641198579794\n",
      "train loss:0.9200738495888453\n",
      "train loss:0.8300222860720001\n",
      "train loss:0.7890534548714379\n",
      "train loss:1.0088625229800714\n",
      "train loss:0.9489170524773312\n",
      "train loss:1.0418434338553015\n",
      "train loss:0.8096118720887907\n",
      "train loss:0.8142164231710918\n",
      "train loss:0.797360658587853\n",
      "train loss:0.7677094495846427\n",
      "train loss:0.9010696260537792\n",
      "train loss:0.7899242554057051\n",
      "train loss:0.9973597369956313\n",
      "train loss:0.9414249459530786\n",
      "train loss:0.9129310532535971\n",
      "train loss:0.8074073326002355\n",
      "train loss:0.8743609458481516\n",
      "train loss:0.9496752913797522\n",
      "train loss:0.9000517012349468\n",
      "train loss:0.899866214582497\n",
      "train loss:0.8853370942750858\n",
      "train loss:0.7498095763166477\n",
      "train loss:0.9434549200583288\n",
      "train loss:0.9734946586401013\n",
      "train loss:0.8117042198469633\n",
      "train loss:0.8148980326603135\n",
      "train loss:0.876143608030635\n",
      "train loss:0.9982975389684806\n",
      "train loss:0.8000723776010745\n",
      "train loss:0.8688266275314608\n",
      "train loss:0.7768159666402706\n",
      "train loss:0.9369713177711826\n",
      "train loss:0.8943757608778806\n",
      "train loss:0.8480212541658011\n",
      "train loss:1.0032687772403721\n",
      "train loss:0.6693084335331134\n",
      "train loss:0.813439927204949\n",
      "train loss:0.9192621383665687\n",
      "train loss:0.8119418015306694\n",
      "train loss:1.0485685932556417\n",
      "train loss:0.8838024594794937\n",
      "train loss:0.8939802712290915\n",
      "train loss:0.8501776024168768\n",
      "train loss:0.7197265044501283\n",
      "train loss:1.097478459065137\n",
      "train loss:0.8376442463334051\n",
      "train loss:0.8704323051713208\n",
      "train loss:0.8255311508416461\n",
      "train loss:0.8958492631457748\n",
      "train loss:0.9426762852570947\n",
      "train loss:0.7703497045846538\n",
      "train loss:0.8746381985764962\n",
      "train loss:0.9339533416908745\n",
      "train loss:0.9653649091957921\n",
      "train loss:0.7331441718389197\n",
      "train loss:0.9452327274083316\n",
      "train loss:0.7790869306505526\n",
      "train loss:0.9953166299700388\n",
      "train loss:0.6847249537767154\n",
      "train loss:0.7976135298468747\n",
      "train loss:0.9684668000467628\n",
      "train loss:0.9364957460790703\n",
      "train loss:0.9156633887321383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8567374401735057\n",
      "=== epoch:17, train acc:0.997, test acc:0.987 ===\n",
      "train loss:1.0159954617355202\n",
      "train loss:0.7837283620570678\n",
      "train loss:0.9012228088264687\n",
      "train loss:0.8743741581628665\n",
      "train loss:0.8398698433326282\n",
      "train loss:0.850984916227032\n",
      "train loss:0.8082268940030037\n",
      "train loss:0.8388568318963823\n",
      "train loss:0.928229947146161\n",
      "train loss:0.9175869638221541\n",
      "train loss:0.9095668232893032\n",
      "train loss:0.7756792620055286\n",
      "train loss:0.9462608919917092\n",
      "train loss:0.9821019680253507\n",
      "train loss:0.8751866855886243\n",
      "train loss:0.8608928093701959\n",
      "train loss:1.0779490552923638\n",
      "train loss:0.9270519334627835\n",
      "train loss:0.7788903757084304\n",
      "train loss:0.8817540992755886\n",
      "train loss:0.7865023566036311\n",
      "train loss:1.0076920395958018\n",
      "train loss:0.7516402012752998\n",
      "train loss:0.960719922007502\n",
      "train loss:0.8121989976242219\n",
      "train loss:0.9427506500953768\n",
      "train loss:0.8773264800007636\n",
      "train loss:0.8103521998240645\n",
      "train loss:0.8781940543813016\n",
      "train loss:0.9035676885071038\n",
      "train loss:0.8638664724687917\n",
      "train loss:0.9748158641170532\n",
      "train loss:0.9815659853675459\n",
      "train loss:0.7985945304210464\n",
      "train loss:0.8184337080635405\n",
      "train loss:0.9116058441949348\n",
      "train loss:0.9373978798415148\n",
      "train loss:0.8704196691174317\n",
      "train loss:0.9071540228735689\n",
      "train loss:1.005422394901973\n",
      "train loss:0.8585718513080175\n",
      "train loss:0.756115807441535\n",
      "train loss:0.9695328007067415\n",
      "train loss:0.7855942157013623\n",
      "train loss:0.8978210720388664\n",
      "train loss:0.8846415173651541\n",
      "train loss:0.8691876552684729\n",
      "train loss:0.8363611749292348\n",
      "train loss:0.9802236370085029\n",
      "train loss:0.8903662150007796\n",
      "train loss:0.8350601700868725\n",
      "train loss:0.9830534764677875\n",
      "train loss:0.8547833229026951\n",
      "train loss:0.8926787820622158\n",
      "train loss:0.8383973629497313\n",
      "train loss:0.8505135430176075\n",
      "train loss:0.9378488938660895\n",
      "train loss:0.8208677544161678\n",
      "train loss:0.8874981060596889\n",
      "train loss:0.7830042944725883\n",
      "train loss:0.8465073264671535\n",
      "train loss:0.7484051277966866\n",
      "train loss:0.6781542471904709\n",
      "train loss:0.7959732449017642\n",
      "train loss:0.977298658512294\n",
      "train loss:0.7878551571310709\n",
      "train loss:1.0143002251636346\n",
      "train loss:0.9374205952873311\n",
      "train loss:0.7789472135238746\n",
      "train loss:0.9154696165894843\n",
      "train loss:0.9672792221186266\n",
      "train loss:1.033968866661637\n",
      "train loss:0.9311655195023236\n",
      "train loss:0.7451368860969523\n",
      "train loss:0.7948817213578727\n",
      "train loss:0.6784312946961627\n",
      "train loss:0.8798881877534557\n",
      "train loss:0.7211450345596424\n",
      "train loss:0.8403810820490883\n",
      "train loss:0.9792931402175593\n",
      "train loss:0.7926043564045107\n",
      "train loss:0.9380655367314271\n",
      "train loss:0.7688663308663695\n",
      "train loss:0.7718921695565214\n",
      "train loss:0.9311876649699325\n",
      "train loss:0.8918697975285024\n",
      "train loss:0.9310454907180464\n",
      "train loss:0.7321118562917205\n",
      "train loss:0.8105822319259556\n",
      "train loss:0.82575924256237\n",
      "train loss:0.7171627952349736\n",
      "train loss:0.7685781421271244\n",
      "train loss:0.693570316311471\n",
      "train loss:0.7235436008736582\n",
      "train loss:0.7749643559048992\n",
      "train loss:0.9810383142689777\n",
      "train loss:0.9293320538716512\n",
      "train loss:0.9598514010013465\n",
      "train loss:0.9940737244688606\n",
      "train loss:0.9540650851586296\n",
      "train loss:0.9986036172143316\n",
      "train loss:0.9506098685439203\n",
      "train loss:0.8811215469145011\n",
      "train loss:0.8706938078919982\n",
      "train loss:0.7895862083883296\n",
      "train loss:0.9501881941197666\n",
      "train loss:0.8611485154770497\n",
      "train loss:0.8560770807899378\n",
      "train loss:0.7610620717676255\n",
      "train loss:0.8939860532493468\n",
      "train loss:0.8711507531308146\n",
      "train loss:0.8322660959949708\n",
      "train loss:0.7655210561549671\n",
      "train loss:0.9663527875898024\n",
      "train loss:0.7079233855977427\n",
      "train loss:0.9153462677718537\n",
      "train loss:0.8118427182580606\n",
      "train loss:0.8515202476850778\n",
      "train loss:0.9830097919738049\n",
      "train loss:0.7951404015128445\n",
      "train loss:1.0154633340704287\n",
      "train loss:0.825949192533474\n",
      "train loss:0.897709299561931\n",
      "train loss:0.9533656955459587\n",
      "train loss:0.8711843338675267\n",
      "train loss:1.0335507483264736\n",
      "train loss:0.9580835725437727\n",
      "train loss:0.822718107898651\n",
      "train loss:0.9246643677022426\n",
      "train loss:0.8137447274543583\n",
      "train loss:0.7458942304086625\n",
      "train loss:0.804622461170675\n",
      "train loss:0.8819588696047163\n",
      "train loss:0.9523612123296569\n",
      "train loss:0.8621561067482595\n",
      "train loss:0.9922104918362554\n",
      "train loss:0.9275573654309699\n",
      "train loss:0.9556367678116896\n",
      "train loss:0.8469686458929894\n",
      "train loss:0.8639939327714242\n",
      "train loss:0.6848427140973743\n",
      "train loss:0.8305903259078994\n",
      "train loss:0.8212777865025527\n",
      "train loss:0.9427486413622016\n",
      "train loss:0.8058005742249189\n",
      "train loss:0.7996596526944727\n",
      "train loss:0.8100910976305475\n",
      "train loss:0.8199067455496301\n",
      "train loss:0.703713378534027\n",
      "train loss:0.9723605649656264\n",
      "train loss:0.8175000081467464\n",
      "train loss:0.7993127092546186\n",
      "train loss:0.8288379943521281\n",
      "train loss:0.737051813152301\n",
      "train loss:0.8319958681859353\n",
      "train loss:0.8563233996777377\n",
      "train loss:0.8114461761293487\n",
      "train loss:0.8627035372912887\n",
      "train loss:0.9165769098474326\n",
      "train loss:0.8150416482539811\n",
      "train loss:0.9899315312359334\n",
      "train loss:0.9184803379580972\n",
      "train loss:0.8002392675215658\n",
      "train loss:0.8558541542142177\n",
      "train loss:0.8382975489294731\n",
      "train loss:0.9079067382391226\n",
      "train loss:0.881083810020612\n",
      "train loss:0.9530589248231849\n",
      "train loss:0.968773193859803\n",
      "train loss:0.797883199642026\n",
      "train loss:0.8152013552115734\n",
      "train loss:0.898039443071643\n",
      "train loss:0.9183087734057443\n",
      "train loss:0.8550947100262161\n",
      "train loss:0.8102899155321981\n",
      "train loss:0.8116432300435773\n",
      "train loss:0.8531028700849113\n",
      "train loss:0.7429464600499013\n",
      "train loss:0.8348299448080688\n",
      "train loss:0.7907128084861098\n",
      "train loss:0.9047031681697912\n",
      "train loss:0.9012757752818412\n",
      "train loss:0.8075612334660378\n",
      "train loss:0.8890228097752595\n",
      "train loss:0.9363769473692298\n",
      "train loss:0.8059236008403572\n",
      "train loss:0.8317290180792337\n",
      "train loss:0.8752252830546009\n",
      "train loss:0.652790889982652\n",
      "train loss:0.8659982020571826\n",
      "train loss:0.9539928324996488\n",
      "train loss:0.8638950437999506\n",
      "train loss:0.8633143444873436\n",
      "train loss:0.733425999962065\n",
      "train loss:0.9148897906596202\n",
      "train loss:0.900744384968961\n",
      "train loss:0.7920661413216101\n",
      "train loss:0.821835007935577\n",
      "train loss:0.9450781985609175\n",
      "train loss:0.9341921074136793\n",
      "train loss:0.9064018130337266\n",
      "train loss:0.9729076212602733\n",
      "train loss:0.8956168117075651\n",
      "train loss:0.9332228117183732\n",
      "train loss:0.8846587575882406\n",
      "train loss:0.8182349700453346\n",
      "train loss:0.8699173364370815\n",
      "train loss:0.7906362754124594\n",
      "train loss:0.8078181680155866\n",
      "train loss:0.8530839273404827\n",
      "train loss:0.8249407338615911\n",
      "train loss:0.9254611517918307\n",
      "train loss:0.975824669619064\n",
      "train loss:0.7667764457173962\n",
      "train loss:0.8577613011327846\n",
      "train loss:0.8556512537210835\n",
      "train loss:0.9297844469233466\n",
      "train loss:0.7782560100545771\n",
      "train loss:0.8050775497368882\n",
      "train loss:1.0267190849816337\n",
      "train loss:0.888190609445043\n",
      "train loss:0.7243008286989387\n",
      "train loss:0.8178338296951131\n",
      "train loss:0.8588134890398834\n",
      "train loss:0.9364080466888304\n",
      "train loss:0.9248671958184491\n",
      "train loss:0.7327298870639638\n",
      "train loss:0.8152498417794863\n",
      "train loss:0.9194852475343324\n",
      "train loss:0.9740007859487614\n",
      "train loss:1.0137670761284945\n",
      "train loss:0.6998346741781778\n",
      "train loss:0.9150642017181143\n",
      "train loss:0.8723195861692155\n",
      "train loss:0.792369312341494\n",
      "train loss:0.9348028235604608\n",
      "train loss:0.752687756376706\n",
      "train loss:0.9399048112204433\n",
      "train loss:0.8539022713013353\n",
      "train loss:0.7899934174076937\n",
      "train loss:0.9130209303906733\n",
      "train loss:0.9049914916418458\n",
      "train loss:0.8549639474826587\n",
      "train loss:0.7715860489742111\n",
      "train loss:0.93471029540306\n",
      "train loss:0.8026525125515724\n",
      "train loss:0.7806582730549709\n",
      "train loss:0.6289329706713586\n",
      "train loss:0.9900714080966266\n",
      "train loss:0.6937528331714624\n",
      "train loss:0.9617102805177418\n",
      "train loss:0.9429446106936201\n",
      "train loss:1.0682889886337668\n",
      "train loss:0.9276947385493343\n",
      "train loss:0.7836844482553871\n",
      "train loss:0.7851701551430894\n",
      "train loss:0.9460568708226275\n",
      "train loss:0.825744995960007\n",
      "train loss:0.9141790575414948\n",
      "train loss:0.940492320241752\n",
      "train loss:0.8256505489102071\n",
      "train loss:0.9789590318168934\n",
      "train loss:0.6969746112142158\n",
      "train loss:1.053283150903653\n",
      "train loss:0.7800140436228876\n",
      "train loss:1.0143663669069938\n",
      "train loss:0.8070873401396536\n",
      "train loss:0.872843009997062\n",
      "train loss:0.8151696152282274\n",
      "train loss:0.8824857442774827\n",
      "train loss:0.844867844815859\n",
      "train loss:0.9721779897484686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.1249050768231097\n",
      "train loss:0.9145229380683045\n",
      "train loss:0.9445159574656846\n",
      "train loss:0.998518651550103\n",
      "train loss:0.8278931809646263\n",
      "train loss:1.0738357536787582\n",
      "train loss:0.8182922394874543\n",
      "train loss:0.7748097281497013\n",
      "train loss:0.849822691863611\n",
      "train loss:1.0356478757704897\n",
      "train loss:0.8030867256966977\n",
      "train loss:0.7505809555359542\n",
      "train loss:0.8968130045940527\n",
      "train loss:0.8006187777536242\n",
      "train loss:0.8860761350703855\n",
      "train loss:1.0044644406551038\n",
      "train loss:0.8622660431079866\n",
      "train loss:0.9515321289936242\n",
      "train loss:0.9309472468870478\n",
      "train loss:0.9470188884636965\n",
      "train loss:0.9016747924023696\n",
      "train loss:0.9895283879046617\n",
      "train loss:0.8598471311792996\n",
      "train loss:0.9402789252799729\n",
      "train loss:0.8149304384864586\n",
      "train loss:0.9485642667185489\n",
      "train loss:0.938314294577266\n",
      "train loss:0.9618703515661218\n",
      "train loss:0.8257959254608431\n",
      "train loss:1.0836775819730469\n",
      "train loss:0.9257195187919769\n",
      "train loss:0.862018359765176\n",
      "train loss:0.9947605902937506\n",
      "train loss:0.784468249712815\n",
      "train loss:0.9742944048740962\n",
      "train loss:0.8337797238350837\n",
      "train loss:1.0319916056797676\n",
      "train loss:0.7720028547617129\n",
      "train loss:0.8036038702735258\n",
      "train loss:0.9979663975495005\n",
      "train loss:1.0128518864324092\n",
      "train loss:0.8103710074165107\n",
      "train loss:0.8601113330862458\n",
      "train loss:0.8702409592822339\n",
      "train loss:0.8122631572903316\n",
      "train loss:0.9011547761097626\n",
      "train loss:0.8857163622769006\n",
      "train loss:0.8530726520879881\n",
      "train loss:0.7255738735662628\n",
      "train loss:0.8539515833748789\n",
      "train loss:0.9411565873062565\n",
      "train loss:0.9432261229220349\n",
      "train loss:0.8822241439509427\n",
      "train loss:0.8801515548338051\n",
      "train loss:0.9489408850861419\n",
      "train loss:0.8595234444337676\n",
      "train loss:0.7454324171861707\n",
      "train loss:0.8787030498714633\n",
      "train loss:0.9072814284461453\n",
      "train loss:1.0137654499733961\n",
      "train loss:0.8657929073507588\n",
      "train loss:0.7318433816113964\n",
      "train loss:0.8490335513405721\n",
      "train loss:0.8456298019724691\n",
      "train loss:0.9615327671999158\n",
      "train loss:0.9276680954896555\n",
      "train loss:0.9585622532917825\n",
      "train loss:0.931477854053535\n",
      "train loss:0.8197934631876507\n",
      "train loss:1.0057442239222434\n",
      "train loss:0.9053438950087778\n",
      "train loss:0.9319977958038612\n",
      "train loss:0.8317954710019607\n",
      "train loss:0.7559761556929483\n",
      "train loss:0.9390581579878492\n",
      "train loss:0.8860709071405006\n",
      "train loss:0.9373907494991408\n",
      "train loss:0.8298561796953955\n",
      "train loss:0.8207939090976837\n",
      "train loss:0.8761242243516675\n",
      "train loss:0.9094027413685147\n",
      "train loss:0.7757752931457156\n",
      "train loss:1.0615872695147817\n",
      "train loss:0.8677830133258878\n",
      "train loss:0.9217153492753822\n",
      "train loss:0.8126485231064362\n",
      "train loss:0.7298875925812328\n",
      "train loss:0.8947567761841997\n",
      "train loss:0.7861078534242829\n",
      "train loss:0.9801282334431004\n",
      "train loss:0.951142023622745\n",
      "train loss:0.8303043506259644\n",
      "train loss:1.015415119859849\n",
      "train loss:0.9674148114008743\n",
      "train loss:0.8116859787588875\n",
      "train loss:0.8192562340026487\n",
      "train loss:1.0750250534108294\n",
      "train loss:0.7171319831027196\n",
      "train loss:0.8458629167110867\n",
      "train loss:0.9057039337846023\n",
      "train loss:0.8804623872994166\n",
      "train loss:1.0839540090973674\n",
      "train loss:0.8833362230419882\n",
      "train loss:0.9193769433204237\n",
      "train loss:0.8104596261428958\n",
      "train loss:0.9065853714005511\n",
      "train loss:0.9518552330037793\n",
      "train loss:0.8220572470815902\n",
      "train loss:0.7460429175867103\n",
      "train loss:0.9403985277709436\n",
      "train loss:0.8613944608580103\n",
      "train loss:0.8189262633932011\n",
      "train loss:0.8818904429915974\n",
      "train loss:1.0290859879827539\n",
      "train loss:1.0258585833731655\n",
      "train loss:0.8509093137869947\n",
      "train loss:0.8877635141939735\n",
      "train loss:0.8309216478940142\n",
      "train loss:0.7414977531011728\n",
      "train loss:1.0188409589993324\n",
      "train loss:0.8430146263181009\n",
      "train loss:0.8338771332552222\n",
      "train loss:0.7898455187120698\n",
      "train loss:0.7763591348140183\n",
      "train loss:0.7328805032032135\n",
      "train loss:0.9435631035303206\n",
      "train loss:0.9196443105219622\n",
      "train loss:1.0800445977023794\n",
      "train loss:0.9955392157129878\n",
      "train loss:0.8358764058385504\n",
      "train loss:0.842874865420735\n",
      "train loss:0.7660415790102327\n",
      "train loss:0.8380389125222293\n",
      "train loss:0.8639540364766986\n",
      "train loss:0.6398005827169517\n",
      "train loss:0.8681721752262487\n",
      "train loss:0.9417528889069803\n",
      "train loss:1.1121732727046816\n",
      "train loss:0.9507234084316367\n",
      "train loss:0.9929440521503079\n",
      "train loss:0.7810652524549541\n",
      "train loss:0.8518812481104409\n",
      "train loss:0.7930277666944826\n",
      "train loss:0.8406580381282484\n",
      "train loss:0.9359884936916452\n",
      "train loss:0.8825988745009784\n",
      "train loss:0.9665592930953254\n",
      "train loss:0.942553277825655\n",
      "train loss:1.0293761675454505\n",
      "train loss:0.8279998771479221\n",
      "train loss:0.8450006784976002\n",
      "train loss:1.0619045040376254\n",
      "train loss:0.837325097105158\n",
      "train loss:0.9630255222715843\n",
      "train loss:0.8836679968801511\n",
      "train loss:0.8748800655497978\n",
      "train loss:0.9430777496708689\n",
      "train loss:0.7341646097738536\n",
      "train loss:0.8871433520836345\n",
      "train loss:0.7260890619225875\n",
      "train loss:0.7950784354540029\n",
      "train loss:0.9078091942470371\n",
      "train loss:0.8378048554409863\n",
      "train loss:0.8590950258782816\n",
      "train loss:0.9251905245744467\n",
      "train loss:0.9780135699054334\n",
      "train loss:0.8677441617980237\n",
      "train loss:0.8444478364518175\n",
      "train loss:0.7879871963678059\n",
      "train loss:0.8162762097522589\n",
      "train loss:0.8776962559032893\n",
      "train loss:0.8303035315851146\n",
      "train loss:0.8759585508586946\n",
      "train loss:0.8142631183897509\n",
      "train loss:0.9496899767986626\n",
      "train loss:0.9199307639063554\n",
      "train loss:0.9036942600080695\n",
      "train loss:0.802979332925675\n",
      "train loss:0.7818377964594192\n",
      "train loss:0.9482157412972023\n",
      "train loss:0.8980172375255573\n",
      "train loss:0.7309220946477422\n",
      "train loss:0.7817787612098108\n",
      "train loss:0.8507316166503179\n",
      "train loss:0.8447489091107734\n",
      "train loss:0.870879969483616\n",
      "train loss:0.9799524861769716\n",
      "train loss:0.8742250193676544\n",
      "train loss:0.8232184226241444\n",
      "train loss:0.8786125704528611\n",
      "train loss:0.883421896676023\n",
      "train loss:0.8727777716933974\n",
      "train loss:0.9569238660887273\n",
      "train loss:0.8520281332713169\n",
      "train loss:0.7028043590986403\n",
      "train loss:0.805501460314189\n",
      "train loss:0.8473074965029882\n",
      "train loss:0.8271791291589925\n",
      "train loss:0.9448317045914988\n",
      "train loss:1.0142695195475826\n",
      "train loss:0.8677124734883919\n",
      "train loss:0.9809139653369522\n",
      "train loss:0.871523456726659\n",
      "train loss:0.7937979184013062\n",
      "train loss:0.7915361863498848\n",
      "train loss:0.7711992163647154\n",
      "train loss:0.6356747310052472\n",
      "train loss:0.8761525499474928\n",
      "train loss:0.7216441783508297\n",
      "train loss:0.8563245923425719\n",
      "train loss:0.7267026051737369\n",
      "train loss:0.7888123059402469\n",
      "train loss:0.8772636516662641\n",
      "train loss:0.8711463021899343\n",
      "train loss:0.9136026051514671\n",
      "train loss:1.1375906960498838\n",
      "train loss:0.8866710849789685\n",
      "train loss:1.0352046694317023\n",
      "train loss:0.7471378544817653\n",
      "train loss:0.8190967491699958\n",
      "train loss:0.8507710767438426\n",
      "train loss:0.9609663610402953\n",
      "train loss:0.8919918049228529\n",
      "train loss:0.9823007111343014\n",
      "train loss:0.9703549405140207\n",
      "train loss:0.7860853670534763\n",
      "train loss:0.8940946486134177\n",
      "train loss:0.835498872583255\n",
      "train loss:0.7273304337929162\n",
      "train loss:0.9227805068500895\n",
      "train loss:0.9933085008384478\n",
      "train loss:0.9357018436931281\n",
      "train loss:0.8150969056785171\n",
      "train loss:0.8004552357838175\n",
      "train loss:0.7097970728309844\n",
      "train loss:0.9022897152986802\n",
      "train loss:0.8438559865502582\n",
      "train loss:0.8387971922146713\n",
      "train loss:0.8871728366943324\n",
      "train loss:0.8447464977153756\n",
      "train loss:0.6917343671527957\n",
      "train loss:0.8787558706346346\n",
      "train loss:0.9150143068850961\n",
      "train loss:0.955582142892129\n",
      "train loss:0.7670781036615182\n",
      "train loss:0.9779116322303838\n",
      "train loss:0.9269516099933164\n",
      "train loss:1.0240567722736444\n",
      "train loss:0.6726801438055019\n",
      "train loss:0.7719784968003163\n",
      "train loss:0.8197858775608888\n",
      "train loss:0.7139050054125791\n",
      "train loss:0.9008104965611543\n",
      "train loss:1.0183186761245622\n",
      "train loss:0.7552676744430664\n",
      "train loss:0.9621958882540637\n",
      "train loss:0.8198244216822255\n",
      "train loss:0.8529478455179419\n",
      "train loss:0.8888255726612196\n",
      "train loss:0.8679714734236896\n",
      "train loss:0.8589179307859091\n",
      "train loss:0.9346348013860986\n",
      "train loss:0.7635600578948712\n",
      "train loss:0.9477975461103862\n",
      "train loss:0.9959654398221955\n",
      "train loss:0.9930459330979324\n",
      "train loss:0.7683825653302415\n",
      "train loss:0.8587349559478085\n",
      "train loss:0.9130641583166472\n",
      "train loss:0.8591202641952309\n",
      "train loss:0.8884248631199442\n",
      "train loss:0.8372964295341745\n",
      "train loss:0.9520997569117732\n",
      "train loss:0.8942286187150341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8460634727974694\n",
      "train loss:0.809708450046417\n",
      "train loss:1.0564338248314933\n",
      "train loss:0.8629173021127877\n",
      "train loss:0.7938264978841201\n",
      "train loss:0.94264237285585\n",
      "train loss:0.949321402299108\n",
      "train loss:0.8084269218599309\n",
      "train loss:0.9098682250938218\n",
      "train loss:0.9001768630314955\n",
      "train loss:0.9856107650542474\n",
      "train loss:0.7276389145407564\n",
      "train loss:1.0907224793202597\n",
      "train loss:0.9937109208133506\n",
      "train loss:0.8745105154544995\n",
      "train loss:0.8506558703473496\n",
      "train loss:0.7786946479378439\n",
      "train loss:0.7199353359832626\n",
      "train loss:0.8599707501549751\n",
      "train loss:0.8386120837817489\n",
      "train loss:0.672888323095957\n",
      "train loss:0.8943188876001461\n",
      "train loss:0.8663863848481779\n",
      "train loss:1.065743063445498\n",
      "train loss:0.9039233602007266\n",
      "train loss:0.8751139712052123\n",
      "train loss:0.8995323745437961\n",
      "train loss:0.8064726536471032\n",
      "train loss:0.8328119966677758\n",
      "train loss:0.8826806296281154\n",
      "train loss:0.871998494033651\n",
      "train loss:0.8950093766319245\n",
      "train loss:0.9931742595241014\n",
      "train loss:0.8646346390282206\n",
      "train loss:0.8871977985918837\n",
      "train loss:0.941172931417761\n",
      "train loss:0.856614866007888\n",
      "train loss:0.6766382115115717\n",
      "train loss:0.9570298144819873\n",
      "train loss:0.809796922827179\n",
      "train loss:0.7909064081259873\n",
      "train loss:0.6637050156506309\n",
      "train loss:0.8430101349319707\n",
      "train loss:0.772599520228369\n",
      "train loss:0.907521928018107\n",
      "train loss:0.8899532707159225\n",
      "train loss:0.8182339314131033\n",
      "train loss:0.92381161770073\n",
      "train loss:0.8604948006339079\n",
      "train loss:0.7634347153354937\n",
      "train loss:0.8644580008579439\n",
      "train loss:0.9317470743885934\n",
      "train loss:0.8864309723084476\n",
      "train loss:0.868609687313747\n",
      "=== epoch:18, train acc:1.0, test acc:0.993 ===\n",
      "train loss:0.8178484772674193\n",
      "train loss:0.8429330794312526\n",
      "train loss:0.8150445793365962\n",
      "train loss:0.8714467402121473\n",
      "train loss:0.9087290842710388\n",
      "train loss:0.861290686513515\n",
      "train loss:1.0136975773148396\n",
      "train loss:0.7489441590294871\n",
      "train loss:0.8024710371582041\n",
      "train loss:0.8453115803560007\n",
      "train loss:0.8791275172887889\n",
      "train loss:0.9869319477454813\n",
      "train loss:0.8754291467954887\n",
      "train loss:0.9723664204211322\n",
      "train loss:0.9252052733776879\n",
      "train loss:0.8698055149930795\n",
      "train loss:0.8993783908187946\n",
      "train loss:0.8714216560582824\n",
      "train loss:1.0559589322683451\n",
      "train loss:0.930513845368983\n",
      "train loss:0.8034582847935832\n",
      "train loss:0.8923117285012768\n",
      "train loss:0.944893643668212\n",
      "train loss:0.8248998376040937\n",
      "train loss:0.8615822177436188\n",
      "train loss:0.8983102695965505\n",
      "train loss:0.8888893231116753\n",
      "train loss:0.9247257800707306\n",
      "train loss:0.8732660103509869\n",
      "train loss:0.8420201681234387\n",
      "train loss:0.8957232313745329\n",
      "train loss:0.7793115775960959\n",
      "train loss:0.9647376797909972\n",
      "train loss:0.8063074931956775\n",
      "train loss:0.9472272390680595\n",
      "train loss:1.0396884485650228\n",
      "train loss:0.7336602695982952\n",
      "train loss:0.8549168664084688\n",
      "train loss:0.954683117064908\n",
      "train loss:0.8259516917142491\n",
      "train loss:0.9374328095975706\n",
      "train loss:0.8807828518402403\n",
      "train loss:0.9318730962074198\n",
      "train loss:0.850990761919214\n",
      "train loss:0.8122514571287064\n",
      "train loss:0.9436662663010128\n",
      "train loss:0.8415836913906309\n",
      "train loss:0.9217770548083177\n",
      "train loss:0.7236348854648448\n",
      "train loss:0.7863972931851066\n",
      "train loss:0.9985576505191065\n",
      "train loss:0.8585550159141375\n",
      "train loss:0.8876391772322733\n",
      "train loss:0.8440292304197307\n",
      "train loss:0.9784753656159165\n",
      "train loss:0.9452749116045122\n",
      "train loss:0.8338127891373638\n",
      "train loss:0.8432336429918916\n",
      "train loss:0.8895719172405796\n",
      "train loss:0.9742435380229533\n",
      "train loss:0.9177373512949388\n",
      "train loss:1.0086949552814235\n",
      "train loss:0.8706261142020665\n",
      "train loss:0.756073364568239\n",
      "train loss:0.8141334781021372\n",
      "train loss:0.699637064367008\n",
      "train loss:0.7667915550280751\n",
      "train loss:0.8569242567834577\n",
      "train loss:0.8639143800621829\n",
      "train loss:0.7821945312182328\n",
      "train loss:1.0598740557985993\n",
      "train loss:0.8581621852331963\n",
      "train loss:0.862333686761867\n",
      "train loss:0.7952754144140877\n",
      "train loss:0.9951656776522009\n",
      "train loss:0.8006782140430498\n",
      "train loss:0.8899703903765986\n",
      "train loss:0.964919604722925\n",
      "train loss:0.87157177768379\n",
      "train loss:1.0990184638904055\n",
      "train loss:0.9378063894105627\n",
      "train loss:0.8290843661373757\n",
      "train loss:0.8843913727208579\n",
      "train loss:0.839214678085119\n",
      "train loss:0.8409964346018477\n",
      "train loss:0.8562245841773595\n",
      "train loss:0.8165629203161856\n",
      "train loss:0.9243929542158158\n",
      "train loss:1.0466182604447856\n",
      "train loss:0.9384565870466878\n",
      "train loss:0.779329723165029\n",
      "train loss:0.8266819876065695\n",
      "train loss:0.8149088891155566\n",
      "train loss:0.994948537235231\n",
      "train loss:0.8337235109944281\n",
      "train loss:1.0178381147209763\n",
      "train loss:0.789140777149029\n",
      "train loss:0.7870297186341846\n",
      "train loss:0.8833549323040301\n",
      "train loss:0.8221437073886985\n",
      "train loss:0.9593536814389831\n",
      "train loss:0.8449957801574486\n",
      "train loss:0.8971389208596057\n",
      "train loss:0.7230168370529761\n",
      "train loss:0.8784821641601122\n",
      "train loss:0.9881142930189621\n",
      "train loss:0.8601371348806647\n",
      "train loss:0.7876411489576788\n",
      "train loss:0.9435904332087824\n",
      "train loss:0.876627435441788\n",
      "train loss:0.9790423708700676\n",
      "train loss:0.9524319221481364\n",
      "train loss:0.8916066519846081\n",
      "train loss:0.8394914779419007\n",
      "train loss:0.7815723357916475\n",
      "train loss:0.8088906226760523\n",
      "train loss:0.7402749030095468\n",
      "train loss:0.9407201535950681\n",
      "train loss:0.9448369027986315\n",
      "train loss:0.7345895788837037\n",
      "train loss:0.9326341295098923\n",
      "train loss:0.6688074895455004\n",
      "train loss:0.8822918357814075\n",
      "train loss:0.8394439041078333\n",
      "train loss:0.9485983038637252\n",
      "train loss:0.9514815634663281\n",
      "train loss:0.8215904282553957\n",
      "train loss:0.849301219846075\n",
      "train loss:0.9324148739600976\n",
      "train loss:1.0116073742699396\n",
      "train loss:0.9086358645326881\n",
      "train loss:0.8667518681578252\n",
      "train loss:0.7939136196680786\n",
      "train loss:0.8510506769938796\n",
      "train loss:0.8287914260883328\n",
      "train loss:0.8794981838859262\n",
      "train loss:0.9885706423362075\n",
      "train loss:0.9199533351774498\n",
      "train loss:0.8539049711825634\n",
      "train loss:0.912761828112264\n",
      "train loss:0.8314086635456025\n",
      "train loss:0.8864652422157849\n",
      "train loss:1.0044366409947125\n",
      "train loss:0.764587247123678\n",
      "train loss:0.8566776550832417\n",
      "train loss:0.9669923909085051\n",
      "train loss:0.8737172494873264\n",
      "train loss:0.8182180066008171\n",
      "train loss:0.9152843656406833\n",
      "train loss:0.8350949248559715\n",
      "train loss:0.6170322642260113\n",
      "train loss:0.8405359187208125\n",
      "train loss:0.9153972461347518\n",
      "train loss:0.9259537338183454\n",
      "train loss:0.7876754692248116\n",
      "train loss:0.7763763199773963\n",
      "train loss:0.8209903970445677\n",
      "train loss:0.9849800128132421\n",
      "train loss:0.9861796508421747\n",
      "train loss:0.9100472407887683\n",
      "train loss:0.8123355811373366\n",
      "train loss:0.8121605656526633\n",
      "train loss:0.8403072289419452\n",
      "train loss:0.8497254450194822\n",
      "train loss:0.8562244464383834\n",
      "train loss:0.7645719483243593\n",
      "train loss:0.8165218944266799\n",
      "train loss:0.9228969427396251\n",
      "train loss:0.8606538702888329\n",
      "train loss:0.9125397239719912\n",
      "train loss:0.8526614223958515\n",
      "train loss:0.8240530647420252\n",
      "train loss:0.9062239208190771\n",
      "train loss:0.7855911492957958\n",
      "train loss:0.8077767686012368\n",
      "train loss:0.9625440956341292\n",
      "train loss:1.0504735361251831\n",
      "train loss:0.9746409608099387\n",
      "train loss:1.0624549129192622\n",
      "train loss:0.9068370317493236\n",
      "train loss:0.8653635269347376\n",
      "train loss:0.945168354380227\n",
      "train loss:0.7747316438391206\n",
      "train loss:0.8458846888814251\n",
      "train loss:0.8704493239371988\n",
      "train loss:1.0751151340087461\n",
      "train loss:0.8368346165615763\n",
      "train loss:0.911182095349183\n",
      "train loss:0.9666816177690256\n",
      "train loss:0.7564305577264473\n",
      "train loss:0.6370565517602504\n",
      "train loss:0.9498249905682984\n",
      "train loss:0.9431064446350692\n",
      "train loss:1.076848989069025\n",
      "train loss:0.7731519147298891\n",
      "train loss:0.7473371983030576\n",
      "train loss:0.9035118377361723\n",
      "train loss:0.7538285780233351\n",
      "train loss:0.8688214900001205\n",
      "train loss:0.7949488363115111\n",
      "train loss:0.8692136777405463\n",
      "train loss:1.085351020772312\n",
      "train loss:0.8631671780851977\n",
      "train loss:0.7840731805425801\n",
      "train loss:0.8939754012336665\n",
      "train loss:0.9148591694801036\n",
      "train loss:0.856410457842307\n",
      "train loss:0.8817689274931618\n",
      "train loss:0.946767858728489\n",
      "train loss:0.9534535807557767\n",
      "train loss:0.8835860656299243\n",
      "train loss:0.8358211371388292\n",
      "train loss:0.9073914770370187\n",
      "train loss:0.6853756414625184\n",
      "train loss:0.8383580474384368\n",
      "train loss:0.7642468225357041\n",
      "train loss:0.9238706421473988\n",
      "train loss:0.9135381950903375\n",
      "train loss:0.9039916971184294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9197721430177016\n",
      "train loss:0.9914475832924551\n",
      "train loss:0.7672355796322367\n",
      "train loss:0.8518333765098858\n",
      "train loss:0.8495683852094921\n",
      "train loss:0.8468931145229491\n",
      "train loss:0.8008409416347504\n",
      "train loss:0.8215208410774649\n",
      "train loss:0.6480621038293738\n",
      "train loss:0.8526050993766959\n",
      "train loss:0.9746850061105958\n",
      "train loss:0.9012437572205418\n",
      "train loss:0.76270714400336\n",
      "train loss:0.875026891997864\n",
      "train loss:0.9853267724027781\n",
      "train loss:0.7771121852958962\n",
      "train loss:0.7938283900858187\n",
      "train loss:0.8254794589109556\n",
      "train loss:0.831525517576651\n",
      "train loss:0.8324929854349628\n",
      "train loss:0.9315045896005401\n",
      "train loss:0.9434131223310299\n",
      "train loss:0.920745861972369\n",
      "train loss:0.899112637999175\n",
      "train loss:0.8322565086463705\n",
      "train loss:0.815464871673036\n",
      "train loss:0.8104917565094758\n",
      "train loss:0.7458889203353791\n",
      "train loss:0.9839904573312112\n",
      "train loss:1.026458302837676\n",
      "train loss:0.8655111130333393\n",
      "train loss:0.8777562266734177\n",
      "train loss:0.9069119746931044\n",
      "train loss:0.8138751635927552\n",
      "train loss:0.8048966397166896\n",
      "train loss:0.846871339516406\n",
      "train loss:0.7347196088174754\n",
      "train loss:0.880117145698359\n",
      "train loss:0.9364628423609858\n",
      "train loss:0.761114810176198\n",
      "train loss:0.9243448188108664\n",
      "train loss:0.8558748521180626\n",
      "train loss:0.8881571881955562\n",
      "train loss:0.897729502632952\n",
      "train loss:1.0307469531918718\n",
      "train loss:0.9359385109357804\n",
      "train loss:0.7159555603028703\n",
      "train loss:0.8643253638574488\n",
      "train loss:0.8898719134000532\n",
      "train loss:0.7919186550903372\n",
      "train loss:0.9439490210828713\n",
      "train loss:0.8189816583603806\n",
      "train loss:0.871356612454235\n",
      "train loss:0.9106642451619206\n",
      "train loss:0.8331116475824781\n",
      "train loss:0.8485315047893868\n",
      "train loss:0.7393609376349972\n",
      "train loss:0.713222826147661\n",
      "train loss:1.0219483159372573\n",
      "train loss:0.8156905687383614\n",
      "train loss:0.8446267658008547\n",
      "train loss:0.9439802388522837\n",
      "train loss:0.8012244719218833\n",
      "train loss:0.9239760784224762\n",
      "train loss:0.7767970926855774\n",
      "train loss:0.8745273339823537\n",
      "train loss:0.9327595187177407\n",
      "train loss:0.8781667801884278\n",
      "train loss:1.0029956769146147\n",
      "train loss:0.8775774805243519\n",
      "train loss:0.8537151327567517\n",
      "train loss:0.8040445129240388\n",
      "train loss:0.9089661632851173\n",
      "train loss:0.7739985008765474\n",
      "train loss:0.7417865401377213\n",
      "train loss:0.8422410537013613\n",
      "train loss:0.7734545856558959\n",
      "train loss:0.957390949062141\n",
      "train loss:0.9456249413918889\n",
      "train loss:0.8899470435041502\n",
      "train loss:0.8642238594142866\n",
      "train loss:0.8616175422634192\n",
      "train loss:0.7435318970065898\n",
      "train loss:0.8185487529728648\n",
      "train loss:0.9220529485870576\n",
      "train loss:0.9260135504059192\n",
      "train loss:0.8113049218891634\n",
      "train loss:0.8978411915196728\n",
      "train loss:0.8012588575322296\n",
      "train loss:0.8543573684078324\n",
      "train loss:0.9015787001663418\n",
      "train loss:0.9140274347715863\n",
      "train loss:0.8460759153861294\n",
      "train loss:0.6609706143196823\n",
      "train loss:0.8234775459899129\n",
      "train loss:0.8057225027151719\n",
      "train loss:1.0171446614428215\n",
      "train loss:0.9036216210754078\n",
      "train loss:1.00220662743186\n",
      "train loss:0.8606097284789606\n",
      "train loss:0.7079731516317912\n",
      "train loss:0.6956223271140801\n",
      "train loss:0.8935206716421252\n",
      "train loss:0.8202628064044185\n",
      "train loss:0.9111470077121527\n",
      "train loss:0.8383577264517712\n",
      "train loss:0.9511452343044092\n",
      "train loss:1.0169204162776462\n",
      "train loss:0.8804412512466887\n",
      "train loss:0.960000137722984\n",
      "train loss:1.1542352862720047\n",
      "train loss:1.0869498743004287\n",
      "train loss:0.8310432005674702\n",
      "train loss:0.8382297189309359\n",
      "train loss:0.9587403877354501\n",
      "train loss:0.9303203766755179\n",
      "train loss:0.8943368964539499\n",
      "train loss:1.005318170964679\n",
      "train loss:0.762470418388329\n",
      "train loss:0.8518019738231021\n",
      "train loss:0.735008903331345\n",
      "train loss:0.816895114659649\n",
      "train loss:0.9965180823001443\n",
      "train loss:0.9409027820267951\n",
      "train loss:0.7909946578092459\n",
      "train loss:0.9047338735282117\n",
      "train loss:0.8753982479132587\n",
      "train loss:0.920390076882458\n",
      "train loss:0.6326333924177411\n",
      "train loss:0.9205718355810915\n",
      "train loss:0.934321779391519\n",
      "train loss:0.8942036136125406\n",
      "train loss:0.9015855329500879\n",
      "train loss:0.8392437482163386\n",
      "train loss:0.752445620277538\n",
      "train loss:0.9349602926177139\n",
      "train loss:0.7948216129079805\n",
      "train loss:0.9840331324668289\n",
      "train loss:0.8767491413093785\n",
      "train loss:0.8264933761778045\n",
      "train loss:0.9016129711781449\n",
      "train loss:1.0795962405237167\n",
      "train loss:0.7479703773339985\n",
      "train loss:0.904849484437852\n",
      "train loss:0.8082468312438037\n",
      "train loss:0.8636939648814854\n",
      "train loss:0.806541793046978\n",
      "train loss:0.8609496178877457\n",
      "train loss:0.9383803036191715\n",
      "train loss:0.8818420044523598\n",
      "train loss:0.8176637883664231\n",
      "train loss:0.8166353686751731\n",
      "train loss:0.9200977737696825\n",
      "train loss:0.9561566014539618\n",
      "train loss:0.9853077675276615\n",
      "train loss:0.8975968211032136\n",
      "train loss:0.9653113399348566\n",
      "train loss:0.7637515684783396\n",
      "train loss:0.8011009341161461\n",
      "train loss:0.7284296165733717\n",
      "train loss:0.8492652236992758\n",
      "train loss:0.9319818011472436\n",
      "train loss:0.8204477332065934\n",
      "train loss:0.8547802944608885\n",
      "train loss:0.8438733422671801\n",
      "train loss:0.9239946714790898\n",
      "train loss:0.9586290325293237\n",
      "train loss:1.058954609308111\n",
      "train loss:0.8757517622305562\n",
      "train loss:0.9316428658443712\n",
      "train loss:0.9981930242530852\n",
      "train loss:0.9963846622432513\n",
      "train loss:0.9086196898166442\n",
      "train loss:0.9116865896297357\n",
      "train loss:0.8878098664269579\n",
      "train loss:0.7925525198408768\n",
      "train loss:0.8495829915594225\n",
      "train loss:0.7996225721405594\n",
      "train loss:0.9176081122215137\n",
      "train loss:0.9351919683250058\n",
      "train loss:0.9721361105965614\n",
      "train loss:0.8184471944890944\n",
      "train loss:0.801109438424405\n",
      "train loss:0.6716992962111615\n",
      "train loss:0.9960221491426782\n",
      "train loss:0.8499262860813271\n",
      "train loss:0.7222427555126002\n",
      "train loss:0.9343437812859627\n",
      "train loss:0.8771538848208117\n",
      "train loss:0.8459504559959319\n",
      "train loss:0.8387833089706815\n",
      "train loss:0.9514439296172124\n",
      "train loss:0.9455141897186775\n",
      "train loss:0.7985424257106198\n",
      "train loss:0.7823769459979072\n",
      "train loss:0.7085698847175951\n",
      "train loss:0.8737229759259395\n",
      "train loss:0.8478081867621953\n",
      "train loss:0.9655313942458659\n",
      "train loss:0.8081071093811201\n",
      "train loss:0.9030012951027817\n",
      "train loss:0.8812409931941717\n",
      "train loss:0.7108160070041153\n",
      "train loss:0.9545218409595198\n",
      "train loss:0.7772155006198244\n",
      "train loss:0.8878457294286561\n",
      "train loss:0.7846185329307422\n",
      "train loss:0.9257072051671494\n",
      "train loss:0.8089894171695883\n",
      "train loss:0.7932078867798039\n",
      "train loss:0.7640161432416259\n",
      "train loss:1.0055275886158785\n",
      "train loss:0.8284590000854708\n",
      "train loss:1.004382462648339\n",
      "train loss:1.0200814752508074\n",
      "train loss:0.8790776144023026\n",
      "train loss:0.9596366068525061\n",
      "train loss:0.9025876457678607\n",
      "train loss:0.937302167572602\n",
      "train loss:0.8541722555533178\n",
      "train loss:0.8693782157275411\n",
      "train loss:0.8428545284016158\n",
      "train loss:0.8224748840089872\n",
      "train loss:0.8534877398985727\n",
      "train loss:0.9534527698871377\n",
      "train loss:0.787481857651188\n",
      "train loss:0.859740256948613\n",
      "train loss:0.9803926606888334\n",
      "train loss:0.873902610936719\n",
      "train loss:0.7564457486697757\n",
      "train loss:0.9392451835494535\n",
      "train loss:0.8836234779228406\n",
      "train loss:0.8842738996298671\n",
      "train loss:0.7652016565344577\n",
      "train loss:0.9020731427332206\n",
      "train loss:0.8650804201977849\n",
      "train loss:0.9901251667014591\n",
      "train loss:0.9369189789464974\n",
      "train loss:0.8438694435827199\n",
      "train loss:0.7867638571527636\n",
      "train loss:0.9624022529085966\n",
      "train loss:0.7666752977493339\n",
      "train loss:0.8689419176451777\n",
      "train loss:0.9806239443565581\n",
      "train loss:0.8301555956952933\n",
      "train loss:0.9243437174230874\n",
      "train loss:0.7315014738839544\n",
      "train loss:0.7926646538531995\n",
      "train loss:0.9869185100508657\n",
      "train loss:0.8117451956975756\n",
      "train loss:0.8203224711308592\n",
      "train loss:1.0137585313441817\n",
      "train loss:0.8626583237483342\n",
      "train loss:0.9176490473243172\n",
      "train loss:0.8186256385542937\n",
      "train loss:0.8242635864735687\n",
      "train loss:0.8635986966146103\n",
      "train loss:0.6927238781078497\n",
      "train loss:0.8721912518382863\n",
      "train loss:0.5986329774774187\n",
      "train loss:0.851485999796123\n",
      "train loss:0.9791030326933137\n",
      "train loss:0.9666226564128853\n",
      "train loss:0.7192589379180363\n",
      "train loss:0.9817752745945749\n",
      "train loss:0.8636359168443545\n",
      "train loss:0.9048766078939068\n",
      "train loss:0.7637880859236233\n",
      "train loss:1.007021807559588\n",
      "train loss:0.9361225731529775\n",
      "train loss:0.9200646439348064\n",
      "train loss:0.7851733489257655\n",
      "train loss:1.0098016101902199\n",
      "train loss:0.8747796316391326\n",
      "train loss:0.9430472551594726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8881092574189726\n",
      "train loss:0.7700511639591119\n",
      "train loss:0.7459685669362842\n",
      "train loss:0.9306651961249719\n",
      "train loss:0.9400182454289389\n",
      "train loss:0.8546727006262018\n",
      "train loss:0.6711199741507184\n",
      "train loss:0.9375618401204616\n",
      "train loss:0.8635461186818967\n",
      "train loss:0.9674039478127034\n",
      "train loss:0.719399709294148\n",
      "train loss:0.8077027807982461\n",
      "train loss:0.7876114428246227\n",
      "train loss:1.009747496627498\n",
      "train loss:0.9206850686713426\n",
      "train loss:0.8676279910112367\n",
      "train loss:0.8100371817077481\n",
      "train loss:0.8528469787230613\n",
      "train loss:0.8284348033246317\n",
      "train loss:0.8338778492369151\n",
      "train loss:0.8835611859355953\n",
      "train loss:0.8808240553790297\n",
      "train loss:0.6694323877980518\n",
      "train loss:0.8429719580557498\n",
      "train loss:0.9729161345269075\n",
      "train loss:0.8545584346905977\n",
      "train loss:0.8309574703844252\n",
      "train loss:0.8792236752780755\n",
      "train loss:0.9358632976850394\n",
      "train loss:0.8158510882794024\n",
      "train loss:0.6898242536885655\n",
      "train loss:0.9768379940508403\n",
      "train loss:0.9483211683913509\n",
      "train loss:0.6991134632950383\n",
      "train loss:0.9043599212536388\n",
      "train loss:0.9706837558497657\n",
      "train loss:0.8199998687048644\n",
      "train loss:0.9001262251565869\n",
      "train loss:1.0008080625111213\n",
      "train loss:0.8995947211678148\n",
      "train loss:0.8910345132762276\n",
      "train loss:0.8507792755366989\n",
      "train loss:0.939642730434078\n",
      "train loss:0.8654412847274798\n",
      "train loss:0.5681568688965479\n",
      "train loss:0.9394999458402302\n",
      "train loss:0.8346610504525532\n",
      "train loss:0.7784504159191505\n",
      "train loss:0.8502633938096118\n",
      "train loss:1.044220319695189\n",
      "train loss:0.9577114450969231\n",
      "train loss:0.8565510307409445\n",
      "train loss:0.8383365670113183\n",
      "train loss:0.7962022060240619\n",
      "train loss:1.0362548290340778\n",
      "train loss:0.9013583669676081\n",
      "train loss:0.7876068408152483\n",
      "train loss:0.9636386885764354\n",
      "train loss:0.792443948904386\n",
      "train loss:0.7285920742337195\n",
      "train loss:0.7547904251678829\n",
      "train loss:0.8171668489204825\n",
      "train loss:0.8849431476153825\n",
      "train loss:0.823634923890663\n",
      "train loss:0.8709700180611739\n",
      "train loss:0.7947649233961251\n",
      "train loss:0.9897060499656252\n",
      "train loss:0.981659233837359\n",
      "train loss:0.8486249479766066\n",
      "train loss:0.8769536744715306\n",
      "train loss:0.9318671800066789\n",
      "train loss:0.9574681155612254\n",
      "train loss:0.9089273903867336\n",
      "train loss:0.8412538837836883\n",
      "train loss:0.844991066530975\n",
      "train loss:0.8169748633089866\n",
      "train loss:0.8758593863607176\n",
      "train loss:0.9211825976121425\n",
      "train loss:1.0219293718490956\n",
      "train loss:0.8112735645310414\n",
      "train loss:0.7625432608349976\n",
      "train loss:0.9765855178436853\n",
      "train loss:0.8910350501432844\n",
      "train loss:0.7868563684324036\n",
      "train loss:0.8393634904422516\n",
      "train loss:0.8115585313494549\n",
      "train loss:0.9362116857610556\n",
      "train loss:0.8046253854968333\n",
      "train loss:0.7756101923511929\n",
      "train loss:0.9593100799497862\n",
      "train loss:0.7209819785783407\n",
      "train loss:0.8559802297295508\n",
      "train loss:0.8846590802158778\n",
      "train loss:0.8952476686503096\n",
      "train loss:1.028944568919901\n",
      "train loss:0.7924129204940109\n",
      "train loss:0.8058537429074923\n",
      "train loss:0.844581413438052\n",
      "train loss:0.9264187063359224\n",
      "train loss:0.9462868550196878\n",
      "train loss:1.1712385252336646\n",
      "train loss:0.9482754679175439\n",
      "train loss:0.9266249314706286\n",
      "train loss:0.9499387432423704\n",
      "train loss:0.9370984606468233\n",
      "train loss:0.6555499424697422\n",
      "=== epoch:19, train acc:1.0, test acc:0.991 ===\n",
      "train loss:0.8764744272429198\n",
      "train loss:0.9108137618387147\n",
      "train loss:0.8829934258018587\n",
      "train loss:0.7834238472601786\n",
      "train loss:0.817468111621658\n",
      "train loss:0.8850900563220196\n",
      "train loss:0.7246808008811318\n",
      "train loss:0.8954719677201843\n",
      "train loss:0.9273975611927666\n",
      "train loss:0.7856911533231664\n",
      "train loss:0.9259265519960066\n",
      "train loss:0.637338886187184\n",
      "train loss:0.9194849495769171\n",
      "train loss:0.9220882225460159\n",
      "train loss:0.9950045883664035\n",
      "train loss:0.9295369804173182\n",
      "train loss:0.7514856020784823\n",
      "train loss:0.7956402530133326\n",
      "train loss:0.858151778780703\n",
      "train loss:0.8498899672254248\n",
      "train loss:0.8367172681185343\n",
      "train loss:0.8419234158436778\n",
      "train loss:0.8196518515876116\n",
      "train loss:0.9443611967505656\n",
      "train loss:0.8178159016383139\n",
      "train loss:0.8375037312973462\n",
      "train loss:0.8605560357165126\n",
      "train loss:0.8927587497304996\n",
      "train loss:0.9691701766987144\n",
      "train loss:0.9607980091021295\n",
      "train loss:0.9098884943048947\n",
      "train loss:0.885914759540752\n",
      "train loss:0.8002857503474096\n",
      "train loss:0.7716190476697992\n",
      "train loss:1.045262656269122\n",
      "train loss:0.8441824923919526\n",
      "train loss:0.7722677494064842\n",
      "train loss:0.8173386958478269\n",
      "train loss:0.9849622805903964\n",
      "train loss:0.9601446577333844\n",
      "train loss:0.7649463129458103\n",
      "train loss:0.8585191188897514\n",
      "train loss:0.9491824979678417\n",
      "train loss:0.9548661980970963\n",
      "train loss:0.8565228680070786\n",
      "train loss:0.7824810143760489\n",
      "train loss:0.9412209972906623\n",
      "train loss:0.9672293298844026\n",
      "train loss:0.8549993643511088\n",
      "train loss:0.9849104701870074\n",
      "train loss:0.837188277812285\n",
      "train loss:0.899687313258928\n",
      "train loss:0.747888605319321\n",
      "train loss:0.950483476127258\n",
      "train loss:0.7842633589440875\n",
      "train loss:0.8839517553852458\n",
      "train loss:0.8495860904238112\n",
      "train loss:0.927724469845009\n",
      "train loss:0.7271825989065284\n",
      "train loss:0.8019846212371882\n",
      "train loss:0.9560848349843252\n",
      "train loss:0.9209734959523905\n",
      "train loss:0.8453503866292312\n",
      "train loss:0.7697692460061711\n",
      "train loss:0.7708924143371415\n",
      "train loss:0.8783065667761774\n",
      "train loss:0.9587786812777864\n",
      "train loss:0.8971490845854488\n",
      "train loss:0.8832318941527697\n",
      "train loss:0.8948634526087536\n",
      "train loss:0.8461102159029816\n",
      "train loss:0.8539210986041368\n",
      "train loss:0.8174029069475683\n",
      "train loss:0.8936614494416878\n",
      "train loss:0.921634083745962\n",
      "train loss:0.8068049098189389\n",
      "train loss:0.9104966592860768\n",
      "train loss:0.6730011228114128\n",
      "train loss:0.8635014767669609\n",
      "train loss:0.79192974059077\n",
      "train loss:0.9310010552258542\n",
      "train loss:0.8187029507891812\n",
      "train loss:0.8341320095875746\n",
      "train loss:0.8549521237724405\n",
      "train loss:0.8301136795598487\n",
      "train loss:0.8081561766922307\n",
      "train loss:0.8889829929048445\n",
      "train loss:0.8011000172165059\n",
      "train loss:0.9131289643750329\n",
      "train loss:0.7030394480343222\n",
      "train loss:0.6823002897443575\n",
      "train loss:0.7068237875523482\n",
      "train loss:0.8582350764623938\n",
      "train loss:0.9337448242468773\n",
      "train loss:0.786900422660619\n",
      "train loss:0.9670184183115232\n",
      "train loss:0.8849948721848518\n",
      "train loss:0.9877462174640783\n",
      "train loss:0.9447473461251676\n",
      "train loss:0.676801152029661\n",
      "train loss:0.7597140453025056\n",
      "train loss:0.7482673035964542\n",
      "train loss:0.8818585547855728\n",
      "train loss:0.9107193904049631\n",
      "train loss:0.7017168467783411\n",
      "train loss:0.8631805819253031\n",
      "train loss:0.8724398935324967\n",
      "train loss:0.747764431874003\n",
      "train loss:0.871294160237407\n",
      "train loss:0.7817295481739873\n",
      "train loss:0.921248543310877\n",
      "train loss:0.7435088501151509\n",
      "train loss:0.85918628863597\n",
      "train loss:0.8413061303172493\n",
      "train loss:0.8061213788401216\n",
      "train loss:0.7743134656335009\n",
      "train loss:0.9116193822808321\n",
      "train loss:0.9707224694494896\n",
      "train loss:0.7454405605935953\n",
      "train loss:0.8310870195284191\n",
      "train loss:0.6823442501367425\n",
      "train loss:0.7089202217316506\n",
      "train loss:0.9855610215804798\n",
      "train loss:0.8756448357457133\n",
      "train loss:0.8881596158947143\n",
      "train loss:0.8710583339172189\n",
      "train loss:0.8597485655613464\n",
      "train loss:0.8654545981594893\n",
      "train loss:0.918126461169686\n",
      "train loss:0.8990366695939016\n",
      "train loss:0.6436869378572077\n",
      "train loss:0.7596268838317787\n",
      "train loss:0.7881442136545265\n",
      "train loss:0.8101806151891053\n",
      "train loss:0.7623932453674123\n",
      "train loss:0.9819726924434646\n",
      "train loss:0.9754596549169124\n",
      "train loss:0.8595938884431901\n",
      "train loss:0.8484864246032011\n",
      "train loss:0.80764276533865\n",
      "train loss:0.8539069248312212\n",
      "train loss:0.8151243378159971\n",
      "train loss:0.8453267865150126\n",
      "train loss:0.8156370038925317\n",
      "train loss:0.8253980128479154\n",
      "train loss:0.8873898298404831\n",
      "train loss:0.8376050228892269\n",
      "train loss:0.8697810012196101\n",
      "train loss:0.8685960269080222\n",
      "train loss:0.8381897115257023\n",
      "train loss:0.8232497045304235\n",
      "train loss:0.8739893551711536\n",
      "train loss:0.8722481087624715\n",
      "train loss:0.9207237209212151\n",
      "train loss:0.8914031588043099\n",
      "train loss:0.7668745891506188\n",
      "train loss:0.77328599617409\n",
      "train loss:0.9308358111964244\n",
      "train loss:0.8768871587739338\n",
      "train loss:0.740244466430013\n",
      "train loss:0.9308129780814943\n",
      "train loss:0.8233216726951197\n",
      "train loss:0.70643547710348\n",
      "train loss:0.9288149835531722\n",
      "train loss:0.9593379767960168\n",
      "train loss:0.8933057481319849\n",
      "train loss:0.847468330342241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8184351606686545\n",
      "train loss:0.9836275298390059\n",
      "train loss:0.8951320923771084\n",
      "train loss:0.8453612533588176\n",
      "train loss:0.9523314332752665\n",
      "train loss:0.923319504479902\n",
      "train loss:0.8513850687706613\n",
      "train loss:0.9484856706379139\n",
      "train loss:0.8462908974268529\n",
      "train loss:0.8313167594534585\n",
      "train loss:0.7917390678309486\n",
      "train loss:0.7981230385403925\n",
      "train loss:0.9570125623617051\n",
      "train loss:0.896352446148847\n",
      "train loss:0.7970501611906161\n",
      "train loss:0.9112494995996595\n",
      "train loss:0.7403867643821295\n",
      "train loss:0.7752587767707262\n",
      "train loss:0.8465481110229064\n",
      "train loss:0.8894779004545912\n",
      "train loss:0.9340052453997333\n",
      "train loss:0.9708507488755093\n",
      "train loss:0.9377367150674212\n",
      "train loss:0.8369748970296758\n",
      "train loss:0.9699479985308459\n",
      "train loss:0.849476640782164\n",
      "train loss:0.9255189225630542\n",
      "train loss:0.7691650933737364\n",
      "train loss:0.8931397314250333\n",
      "train loss:0.8040623954351885\n",
      "train loss:0.8742446562867427\n",
      "train loss:1.0485037054453714\n",
      "train loss:0.8952685074539395\n",
      "train loss:0.8120864459656488\n",
      "train loss:0.8629766615777262\n",
      "train loss:0.9042636417941712\n",
      "train loss:0.8579578978290741\n",
      "train loss:0.7918871033782292\n",
      "train loss:0.9046062625359768\n",
      "train loss:1.0555580696921867\n",
      "train loss:0.924787554591662\n",
      "train loss:0.8423410747474196\n",
      "train loss:0.7218063961804505\n",
      "train loss:0.7968964992321332\n",
      "train loss:0.8296129388234784\n",
      "train loss:0.7666478133450894\n",
      "train loss:0.9015245530117422\n",
      "train loss:0.8912152211406373\n",
      "train loss:0.8146984009584642\n",
      "train loss:0.7359793227981425\n",
      "train loss:0.8809529091375913\n",
      "train loss:0.9322113626328432\n",
      "train loss:0.9117752351248011\n",
      "train loss:0.8867637504087795\n",
      "train loss:0.8971825905834727\n",
      "train loss:0.9633061769841106\n",
      "train loss:0.8732947402271924\n",
      "train loss:0.707422459984508\n",
      "train loss:0.9223372821843896\n",
      "train loss:0.7265585138570312\n",
      "train loss:0.8215573080991192\n",
      "train loss:1.0661051684722793\n",
      "train loss:0.8720071266945051\n",
      "train loss:0.8812387250446362\n",
      "train loss:0.801399793499332\n",
      "train loss:0.9050081304763373\n",
      "train loss:0.9603823208913143\n",
      "train loss:0.8769346695323285\n",
      "train loss:0.8224146740737184\n",
      "train loss:0.7951388886855697\n",
      "train loss:0.8626616610446401\n",
      "train loss:0.7794472040478682\n",
      "train loss:0.9306878022399593\n",
      "train loss:0.7894537203299532\n",
      "train loss:0.9724289837835781\n",
      "train loss:0.8843025296646025\n",
      "train loss:0.7291759403995413\n",
      "train loss:0.9551609450883877\n",
      "train loss:0.8745924273230686\n",
      "train loss:0.8931018883170269\n",
      "train loss:0.8611404665674924\n",
      "train loss:0.8139417687682372\n",
      "train loss:0.6891938143934745\n",
      "train loss:0.9414158399391332\n",
      "train loss:0.9064106212541642\n",
      "train loss:1.0118966621041054\n",
      "train loss:0.8413833381305398\n",
      "train loss:0.9058122996026968\n",
      "train loss:0.8900461514747586\n",
      "train loss:1.0261983918712054\n",
      "train loss:0.7370188818119643\n",
      "train loss:1.0305552781062\n",
      "train loss:1.1045737981909114\n",
      "train loss:1.0808096348072107\n",
      "train loss:0.6766313878885761\n",
      "train loss:0.9570122188578586\n",
      "train loss:0.8736444498398764\n",
      "train loss:1.011698105530958\n",
      "train loss:0.7927661362518594\n",
      "train loss:0.9355472372232373\n",
      "train loss:0.9099817046540788\n",
      "train loss:0.6759613190445024\n",
      "train loss:0.8914011764566692\n",
      "train loss:0.8572590268301584\n",
      "train loss:0.9178541046556642\n",
      "train loss:1.0269869054243541\n",
      "train loss:0.9557910039524137\n",
      "train loss:0.8710620479518973\n",
      "train loss:0.7849341858441317\n",
      "train loss:0.9576416877419359\n",
      "train loss:0.8426912894507567\n",
      "train loss:0.8928794271506194\n",
      "train loss:0.899198828397922\n",
      "train loss:0.8197921196208733\n",
      "train loss:0.7860214576774506\n",
      "train loss:0.9418758846731617\n",
      "train loss:0.8260955993337197\n",
      "train loss:0.892692060811711\n",
      "train loss:0.8663369776120662\n",
      "train loss:1.0606624244196228\n",
      "train loss:0.8456885640675713\n",
      "train loss:0.8567483630210572\n",
      "train loss:0.8403436504919702\n",
      "train loss:0.8750505097811535\n",
      "train loss:0.9750829732095155\n",
      "train loss:0.7197971761301604\n",
      "train loss:0.8891946396941474\n",
      "train loss:0.7870288700744557\n",
      "train loss:0.9885691598407292\n",
      "train loss:0.8528120602809374\n",
      "train loss:0.8353063875630451\n",
      "train loss:0.8381260015332717\n",
      "train loss:0.7586327290888727\n",
      "train loss:0.8749959298078045\n",
      "train loss:0.9095041064298666\n",
      "train loss:0.7574490827892969\n",
      "train loss:0.8009819912897396\n",
      "train loss:0.66771561992623\n",
      "train loss:1.03871374550044\n",
      "train loss:0.8271825118391771\n",
      "train loss:0.7009613995418564\n",
      "train loss:0.8136615890727522\n",
      "train loss:0.8002298837370551\n",
      "train loss:0.9435545309765907\n",
      "train loss:0.6910650163536155\n",
      "train loss:1.0346410647725985\n",
      "train loss:0.8808998522663818\n",
      "train loss:0.753936260898118\n",
      "train loss:0.9542602020491004\n",
      "train loss:0.854482097536299\n",
      "train loss:0.9302116114024295\n",
      "train loss:0.8078414996817312\n",
      "train loss:0.8954596938929381\n",
      "train loss:0.812364353577932\n",
      "train loss:0.9082241834775826\n",
      "train loss:0.819286058689037\n",
      "train loss:0.8204923185096178\n",
      "train loss:0.8144788779866105\n",
      "train loss:0.8737047328048431\n",
      "train loss:0.9585084140960473\n",
      "train loss:0.7689620546121254\n",
      "train loss:0.8511756612624461\n",
      "train loss:0.8162255414075781\n",
      "train loss:0.8590790091547079\n",
      "train loss:0.8205814407459431\n",
      "train loss:0.8694259069625504\n",
      "train loss:1.0542896792655962\n",
      "train loss:1.0246989686616421\n",
      "train loss:0.9578491784966232\n",
      "train loss:0.8662184552702135\n",
      "train loss:0.7558438358623873\n",
      "train loss:0.8435579289544306\n",
      "train loss:0.9217614132553982\n",
      "train loss:0.9493274173218841\n",
      "train loss:0.9920896849749272\n",
      "train loss:0.8637188838325252\n",
      "train loss:0.8949923664559608\n",
      "train loss:0.7717562508131518\n",
      "train loss:0.908584807185913\n",
      "train loss:0.8350404180992617\n",
      "train loss:0.803738406105394\n",
      "train loss:0.900256881552683\n",
      "train loss:0.8908058356168068\n",
      "train loss:0.8143908131285587\n",
      "train loss:0.9056071142513075\n",
      "train loss:1.0278382879893377\n",
      "train loss:0.7436670099445161\n",
      "train loss:0.8638233368707273\n",
      "train loss:0.8969531771243008\n",
      "train loss:0.9922130967739622\n",
      "train loss:0.9026610649336814\n",
      "train loss:0.9332895351928783\n",
      "train loss:0.7685577857758044\n",
      "train loss:0.893211379374306\n",
      "train loss:1.0343342263329147\n",
      "train loss:0.8564955883634576\n",
      "train loss:0.9253513241961697\n",
      "train loss:0.7984052847543951\n",
      "train loss:0.6848166280951117\n",
      "train loss:0.7970132371611348\n",
      "train loss:0.893599925336733\n",
      "train loss:0.7873069742606441\n",
      "train loss:0.9376049507778306\n",
      "train loss:0.9136291834883136\n",
      "train loss:0.793820585206323\n",
      "train loss:0.8536147647677004\n",
      "train loss:0.8636936324227072\n",
      "train loss:0.753976066421984\n",
      "train loss:0.9094087373033617\n",
      "train loss:0.6842261172403948\n",
      "train loss:0.67851816022589\n",
      "train loss:0.6824284657499099\n",
      "train loss:0.9112295679904898\n",
      "train loss:0.8841080055178072\n",
      "train loss:1.0430311518671527\n",
      "train loss:0.8076517083196584\n",
      "train loss:0.8754966077175385\n",
      "train loss:0.9499208137818397\n",
      "train loss:0.9520401037421459\n",
      "train loss:0.8529323660083955\n",
      "train loss:0.7626111538490022\n",
      "train loss:0.7065615595159447\n",
      "train loss:0.7555594795050393\n",
      "train loss:0.7954897744851113\n",
      "train loss:0.8785820442581295\n",
      "train loss:0.9496579138222291\n",
      "train loss:0.9979107781604556\n",
      "train loss:0.9382278903208084\n",
      "train loss:0.9681513914899934\n",
      "train loss:0.8930835153732096\n",
      "train loss:0.7500895406512049\n",
      "train loss:0.7047331620200203\n",
      "train loss:0.86086313154206\n",
      "train loss:0.851978325649095\n",
      "train loss:0.7082460015122172\n",
      "train loss:0.8806474027575202\n",
      "train loss:0.7566635298330776\n",
      "train loss:0.8018356474217536\n",
      "train loss:0.9191299481678502\n",
      "train loss:0.9118708685827542\n",
      "train loss:0.8173028952210811\n",
      "train loss:0.7161235570352836\n",
      "train loss:0.8041739990260106\n",
      "train loss:0.7848623326220202\n",
      "train loss:0.7331320424691857\n",
      "train loss:0.7766441277001427\n",
      "train loss:1.0003402213630015\n",
      "train loss:0.9643825085753953\n",
      "train loss:0.9094839149768289\n",
      "train loss:0.9402685938982646\n",
      "train loss:0.9745339822317329\n",
      "train loss:0.8424841439806986\n",
      "train loss:0.720735726673194\n",
      "train loss:0.7462469892108645\n",
      "train loss:0.7847290398483099\n",
      "train loss:0.7496311867577856\n",
      "train loss:0.9045887793808811\n",
      "train loss:0.9342616570893573\n",
      "train loss:1.0189552379538815\n",
      "train loss:0.7896042876297044\n",
      "train loss:0.9709210476179696\n",
      "train loss:0.8475201112893517\n",
      "train loss:0.7816289944738712\n",
      "train loss:1.0631239128463374\n",
      "train loss:0.8666151437576033\n",
      "train loss:0.7002956138140778\n",
      "train loss:0.7472534617261607\n",
      "train loss:1.045113869671664\n",
      "train loss:0.9762889548186934\n",
      "train loss:0.8410412458095251\n",
      "train loss:0.8837515517768466\n",
      "train loss:0.9114463644216388\n",
      "train loss:0.8825405547417818\n",
      "train loss:0.812248654685136\n",
      "train loss:0.8976380794410117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7944287128954065\n",
      "train loss:0.9623664751178623\n",
      "train loss:1.0082129663674617\n",
      "train loss:0.8804064570385363\n",
      "train loss:0.8534039280896412\n",
      "train loss:0.797700246986009\n",
      "train loss:0.9569717953043946\n",
      "train loss:0.6945554010791678\n",
      "train loss:0.7843447210472143\n",
      "train loss:0.8636688344998927\n",
      "train loss:0.8165891112661634\n",
      "train loss:0.8810980545452441\n",
      "train loss:0.8659233199929399\n",
      "train loss:0.6682212079677128\n",
      "train loss:0.8513250083094499\n",
      "train loss:0.8033342131717993\n",
      "train loss:0.8434290268287774\n",
      "train loss:0.7559387872930989\n",
      "train loss:0.8053107277675715\n",
      "train loss:0.8118610987825288\n",
      "train loss:0.7418246616605434\n",
      "train loss:0.7569337919368576\n",
      "train loss:0.8117869458035272\n",
      "train loss:0.6436478872748279\n",
      "train loss:0.9316106017725843\n",
      "train loss:0.726744678371168\n",
      "train loss:1.0078899427143255\n",
      "train loss:0.9935825434637993\n",
      "train loss:0.8909955049171255\n",
      "train loss:0.8467577787520303\n",
      "train loss:0.7462891536829127\n",
      "train loss:0.9038632349418233\n",
      "train loss:0.8701626428611895\n",
      "train loss:0.8298215467532023\n",
      "train loss:0.8183688016865269\n",
      "train loss:0.9139334049573251\n",
      "train loss:0.837510307690731\n",
      "train loss:0.7117064568095722\n",
      "train loss:0.9499411439593993\n",
      "train loss:0.854208284213501\n",
      "train loss:0.7945785434185096\n",
      "train loss:0.8352774281568237\n",
      "train loss:0.9151216741896385\n",
      "train loss:0.8457334028438929\n",
      "train loss:0.9425918692491985\n",
      "train loss:0.8494153793171\n",
      "train loss:0.6693652326247771\n",
      "train loss:0.8723246770748311\n",
      "train loss:0.7557662481282642\n",
      "train loss:0.8780194567981406\n",
      "train loss:0.8502637119653546\n",
      "train loss:1.0298334147223733\n",
      "train loss:0.9255589723990362\n",
      "train loss:1.0935936560635684\n",
      "train loss:0.9139727160327902\n",
      "train loss:0.8682659507462945\n",
      "train loss:1.031181149370763\n",
      "train loss:0.7318778686101658\n",
      "train loss:0.7992784745360377\n",
      "train loss:0.8365603216056854\n",
      "train loss:1.1420616564496455\n",
      "train loss:0.8437004648970542\n",
      "train loss:0.8776413648668767\n",
      "train loss:0.7356646867568163\n",
      "train loss:0.667524453257792\n",
      "train loss:0.7517629006223356\n",
      "train loss:0.9342384139634268\n",
      "train loss:0.9060358027528127\n",
      "train loss:0.9541055378585317\n",
      "train loss:0.8423339603955121\n",
      "train loss:0.8708398022069117\n",
      "train loss:0.926066444852061\n",
      "train loss:0.6866060145845286\n",
      "train loss:0.8812641565342996\n",
      "train loss:0.6919271187223863\n",
      "train loss:0.7273892128714421\n",
      "train loss:0.8068524207987697\n",
      "train loss:0.920317522475418\n",
      "train loss:0.9520900689962957\n",
      "train loss:0.6942144699582758\n",
      "train loss:0.8008613678827626\n",
      "train loss:0.9338206872704528\n",
      "train loss:0.9573941585192781\n",
      "train loss:0.8701633983133138\n",
      "train loss:0.8583599748355276\n",
      "train loss:0.9501175889163663\n",
      "train loss:0.8623908755142439\n",
      "train loss:0.8235122564304812\n",
      "train loss:0.9846428947711575\n",
      "train loss:0.8900821229159088\n",
      "train loss:0.6919222516411782\n",
      "train loss:0.594989212368564\n",
      "train loss:0.847867036566042\n",
      "train loss:0.8687821128831572\n",
      "train loss:0.7844070474891807\n",
      "train loss:0.9858842135351843\n",
      "train loss:0.9990601977146012\n",
      "train loss:0.8705823879229371\n",
      "train loss:0.9326367604935141\n",
      "train loss:0.8721358123601641\n",
      "train loss:0.8037095032673566\n",
      "train loss:1.0384446951774637\n",
      "train loss:0.8548074758598853\n",
      "train loss:0.9740178599907122\n",
      "train loss:0.7279950673482405\n",
      "train loss:0.8118631740284401\n",
      "train loss:0.9501178367542448\n",
      "train loss:0.8981476460071707\n",
      "train loss:0.7791622647913341\n",
      "train loss:0.9250616954316498\n",
      "train loss:0.9500507699561049\n",
      "train loss:0.8436424801011263\n",
      "train loss:0.8078657681563476\n",
      "train loss:0.8812933987154696\n",
      "train loss:0.9309559781587167\n",
      "train loss:0.9429171722403075\n",
      "train loss:0.7927696047035796\n",
      "train loss:0.7923651238105345\n",
      "train loss:0.8991173153809641\n",
      "train loss:0.8893196502231063\n",
      "train loss:0.6276326191071995\n",
      "train loss:1.0510895600554848\n",
      "train loss:0.9698333100390951\n",
      "train loss:0.9002345926219211\n",
      "train loss:0.7032410646649379\n",
      "train loss:0.8745706946598112\n",
      "train loss:0.8177286578700307\n",
      "train loss:0.9893234593367992\n",
      "train loss:0.9612144878184365\n",
      "train loss:0.8996843793051217\n",
      "train loss:0.7739969348862324\n",
      "train loss:0.8083310080254071\n",
      "train loss:0.9066285814274424\n",
      "train loss:0.9352527147985278\n",
      "train loss:0.8688350665320519\n",
      "train loss:0.9935805784300894\n",
      "train loss:0.8164652979155244\n",
      "train loss:0.7622546661493799\n",
      "train loss:0.9282907527154437\n",
      "train loss:0.9360803384370309\n",
      "train loss:0.9205874271244013\n",
      "train loss:0.9352863628952963\n",
      "train loss:0.7420778442278716\n",
      "train loss:1.034797457746014\n",
      "train loss:0.8256536175068213\n",
      "train loss:0.9472540903105657\n",
      "train loss:0.9243489829614683\n",
      "train loss:0.7680898412932161\n",
      "train loss:0.959221202341359\n",
      "train loss:0.7760162410330272\n",
      "train loss:0.7756587193335441\n",
      "train loss:0.8338589268205711\n",
      "train loss:0.8867443489321647\n",
      "train loss:0.8667135901290222\n",
      "train loss:0.888321633332273\n",
      "train loss:0.9171318011513436\n",
      "train loss:0.8745083646205775\n",
      "train loss:0.9085418372696794\n",
      "=== epoch:20, train acc:0.998, test acc:0.994 ===\n",
      "train loss:0.808391346416751\n",
      "train loss:0.8175691175710965\n",
      "train loss:0.8069968850419069\n",
      "train loss:0.9235827791892949\n",
      "train loss:0.8494666554494489\n",
      "train loss:0.9005470462560972\n",
      "train loss:0.811115347747379\n",
      "train loss:0.9157971790340395\n",
      "train loss:0.7290779950626566\n",
      "train loss:0.916954463252797\n",
      "train loss:0.823452693642446\n",
      "train loss:0.7696937971412655\n",
      "train loss:0.9256564812540131\n",
      "train loss:0.9764625442964596\n",
      "train loss:0.9473899645834578\n",
      "train loss:0.8185745334844559\n",
      "train loss:0.7531760906962977\n",
      "train loss:0.8856425761104585\n",
      "train loss:0.8925930544606157\n",
      "train loss:0.8529543190437551\n",
      "train loss:0.8289109714975632\n",
      "train loss:0.860327257859377\n",
      "train loss:1.0031705149870798\n",
      "train loss:0.9973354005445425\n",
      "train loss:0.7036448683397413\n",
      "train loss:0.8056012879673417\n",
      "train loss:0.8673243513790624\n",
      "train loss:0.7320266811206464\n",
      "train loss:0.9188859702016902\n",
      "train loss:1.0251497319102687\n",
      "train loss:0.7371462193788694\n",
      "train loss:0.8993177355598776\n",
      "train loss:1.022932794345126\n",
      "train loss:0.9543841463411498\n",
      "train loss:0.7970439065472317\n",
      "train loss:0.9421273385943176\n",
      "train loss:0.8850186631994904\n",
      "train loss:0.8647043848683166\n",
      "train loss:1.0583866366223929\n",
      "train loss:0.8855604271106735\n",
      "train loss:0.8241769594515195\n",
      "train loss:0.8793217597325923\n",
      "train loss:0.8576071409912419\n",
      "train loss:0.7909000528862796\n",
      "train loss:0.8836966156780705\n",
      "train loss:0.9712954111384868\n",
      "train loss:1.000762491829309\n",
      "train loss:0.98367725286281\n",
      "train loss:0.9106007029608756\n",
      "train loss:0.9188790050872229\n",
      "train loss:0.8485544169824092\n",
      "train loss:0.8218226716294846\n",
      "train loss:0.8402551985363764\n",
      "train loss:0.9451784386971924\n",
      "train loss:0.9637301655450488\n",
      "train loss:0.9475132166158207\n",
      "train loss:0.9535363162295778\n",
      "train loss:0.6878890980021601\n",
      "train loss:0.7606167198085267\n",
      "train loss:0.8072577310709694\n",
      "train loss:0.8269124660624219\n",
      "train loss:0.8862848372141653\n",
      "train loss:0.8641929007704567\n",
      "train loss:0.9635373966674741\n",
      "train loss:0.6385391578135383\n",
      "train loss:0.8516228928657358\n",
      "train loss:0.7166857821695626\n",
      "train loss:0.9117022797662458\n",
      "train loss:0.8699203969225325\n",
      "train loss:0.6407643435263359\n",
      "train loss:0.8971432944872549\n",
      "train loss:0.9373206856050759\n",
      "train loss:0.7164034519946597\n",
      "train loss:0.9200774080446769\n",
      "train loss:0.7213146566755847\n",
      "train loss:0.7187559251034787\n",
      "train loss:0.9140466290082098\n",
      "train loss:0.7690565633542913\n",
      "train loss:0.8345311940383556\n",
      "train loss:0.8340950083728796\n",
      "train loss:0.8900419392161154\n",
      "train loss:1.0899456803986414\n",
      "train loss:0.8918072447898545\n",
      "train loss:0.8722217659475265\n",
      "train loss:0.9195875415179366\n",
      "train loss:0.8678580732136946\n",
      "train loss:0.8697326077813021\n",
      "train loss:0.8177935707284953\n",
      "train loss:1.0578383044625195\n",
      "train loss:1.0183604679412417\n",
      "train loss:0.8654686708698979\n",
      "train loss:0.9607595317808353\n",
      "train loss:0.8971775702111318\n",
      "train loss:0.7680932126022203\n",
      "train loss:0.8056419454794068\n",
      "train loss:0.8879045574946016\n",
      "train loss:0.8708201520827488\n",
      "train loss:0.8547163159605052\n",
      "train loss:0.8540400665231411\n",
      "train loss:0.7266431581393347\n",
      "train loss:0.8865416273223397\n",
      "train loss:0.817827419689317\n",
      "train loss:0.7913568122897652\n",
      "train loss:0.9009502929131454\n",
      "train loss:0.9686709388044874\n",
      "train loss:0.9991067407633498\n",
      "train loss:0.8184629760349144\n",
      "train loss:0.8498672589248869\n",
      "train loss:1.0328772906836114\n",
      "train loss:0.7924071219304963\n",
      "train loss:0.7170271768249776\n",
      "train loss:0.8108660191209026\n",
      "train loss:0.942711409085964\n",
      "train loss:0.7657157844566953\n",
      "train loss:0.7362022937841189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8959486591528426\n",
      "train loss:0.9157153547561488\n",
      "train loss:0.8054227515102199\n",
      "train loss:0.8762763506621826\n",
      "train loss:0.7754318710428578\n",
      "train loss:0.8336150578366905\n",
      "train loss:1.037354429422949\n",
      "train loss:1.0406648516138963\n",
      "train loss:0.9691157975566977\n",
      "train loss:0.8734680596959619\n",
      "train loss:1.0824963772682985\n",
      "train loss:0.8944850419279582\n",
      "train loss:0.761879473633975\n",
      "train loss:0.8153112527542461\n",
      "train loss:0.9668384725337026\n",
      "train loss:0.8972936572966994\n",
      "train loss:0.8722510520576334\n",
      "train loss:0.8252927944383712\n",
      "train loss:0.8363788360361423\n",
      "train loss:0.6982309351820136\n",
      "train loss:0.8917379577224688\n",
      "train loss:0.8902467999396427\n",
      "train loss:0.7599114014029549\n",
      "train loss:0.9092282166169212\n",
      "train loss:0.8692871739289165\n",
      "train loss:0.8556555466400592\n",
      "train loss:0.9260180045519091\n",
      "train loss:1.0236154829424946\n",
      "train loss:0.8475475335575767\n",
      "train loss:1.03528449165442\n",
      "train loss:0.7763688427350951\n",
      "train loss:0.8462524625605529\n",
      "train loss:0.9001707991683777\n",
      "train loss:0.9921426526488861\n",
      "train loss:0.8721603771136961\n",
      "train loss:0.9361793940411984\n",
      "train loss:1.0056014729230944\n",
      "train loss:0.9833729433937474\n",
      "train loss:0.8346850331925237\n",
      "train loss:0.8850596775577693\n",
      "train loss:0.7257250251939575\n",
      "train loss:0.7931413530802754\n",
      "train loss:0.7526887982378533\n",
      "train loss:0.9396914812692659\n",
      "train loss:0.8764835003987502\n",
      "train loss:0.9059590607018021\n",
      "train loss:0.7482727364669405\n",
      "train loss:0.8425906187468353\n",
      "train loss:0.8224636163435812\n",
      "train loss:0.9244352411826811\n",
      "train loss:0.810114729523573\n",
      "train loss:0.845042257548404\n",
      "train loss:0.7808864279943846\n",
      "train loss:0.8231328884870925\n",
      "train loss:0.6713863341866593\n",
      "train loss:0.7432038994192345\n",
      "train loss:0.9639405555995524\n",
      "train loss:0.8367103102246908\n",
      "train loss:0.8824298263812098\n",
      "train loss:0.7809001048632384\n",
      "train loss:0.8074292109879767\n",
      "train loss:0.9643003963920772\n",
      "train loss:0.8818823229941276\n",
      "train loss:0.8398210622608177\n",
      "train loss:0.839723309235469\n",
      "train loss:0.9084522424249034\n",
      "train loss:0.9689459015852816\n",
      "train loss:0.8449291807114798\n",
      "train loss:0.9014283439599068\n",
      "train loss:0.691192310821434\n",
      "train loss:0.7124127427284885\n",
      "train loss:0.8193446690915343\n",
      "train loss:0.9222557329956057\n",
      "train loss:0.8697528473177575\n",
      "train loss:0.8946762455016263\n",
      "train loss:0.8635438208682795\n",
      "train loss:0.9062421820457779\n",
      "train loss:0.9155633306492821\n",
      "train loss:0.9108110806678467\n",
      "train loss:0.7911825442452188\n",
      "train loss:0.99147727457072\n",
      "train loss:0.7450256272894051\n",
      "train loss:0.9464289907301846\n",
      "train loss:1.0168189723081227\n",
      "train loss:0.7542976967799059\n",
      "train loss:0.7688379504725724\n",
      "train loss:0.7515291132975217\n",
      "train loss:0.8907864156097347\n",
      "train loss:0.8657041454326834\n",
      "train loss:0.9057590482494752\n",
      "train loss:0.8660235416978486\n",
      "train loss:0.7719953119106856\n",
      "train loss:0.7508049629914015\n",
      "train loss:0.875382082166931\n",
      "train loss:0.9236095881794901\n",
      "train loss:0.9449842990134293\n",
      "train loss:0.9204004262395344\n",
      "train loss:0.844061473271057\n",
      "train loss:0.9750120769909744\n",
      "train loss:0.8013450674406968\n",
      "train loss:0.8559488914479718\n",
      "train loss:0.8430685317005839\n",
      "train loss:0.7338183425761735\n",
      "train loss:0.9066691119289658\n",
      "train loss:0.9529219155457314\n",
      "train loss:0.9967958715701196\n",
      "train loss:0.9749276722200116\n",
      "train loss:0.8685434610242391\n",
      "train loss:0.726285398709349\n",
      "train loss:0.9394163586289325\n",
      "train loss:0.911441084176503\n",
      "train loss:0.947858841961526\n",
      "train loss:0.9733185760108058\n",
      "train loss:0.8452827291680349\n",
      "train loss:0.9931809346619663\n",
      "train loss:0.7115962531478626\n",
      "train loss:0.939113219857783\n",
      "train loss:0.80197542586234\n",
      "train loss:0.9298577255080671\n",
      "train loss:0.9212136887157376\n",
      "train loss:1.0325161019870697\n",
      "train loss:0.8380974271071365\n",
      "train loss:0.8860605233613127\n",
      "train loss:0.9002408966799809\n",
      "train loss:0.7370765880245692\n",
      "train loss:0.8920370383795994\n",
      "train loss:0.82812526807849\n",
      "train loss:0.9271941267898979\n",
      "train loss:0.7863419945429412\n",
      "train loss:0.9331370213065067\n",
      "train loss:0.8361564811425554\n",
      "train loss:1.0014330438251884\n",
      "train loss:0.9036173239938929\n",
      "train loss:0.845720998785376\n",
      "train loss:0.7570077397914154\n",
      "train loss:1.0198485468345184\n",
      "train loss:1.0009222488081628\n",
      "train loss:0.8014668500011121\n",
      "train loss:0.8887816664755558\n",
      "train loss:0.8353682076044606\n",
      "train loss:0.873558921638475\n",
      "train loss:0.792872909099883\n",
      "train loss:0.6717672196771141\n",
      "train loss:0.8894115362554368\n",
      "train loss:0.5793626823242404\n",
      "train loss:0.9003781757021607\n",
      "train loss:0.8660485904126679\n",
      "train loss:0.8646606556218009\n",
      "train loss:0.995402149097867\n",
      "train loss:0.8339449037382494\n",
      "train loss:0.7232075902672735\n",
      "train loss:0.9091416545351252\n",
      "train loss:0.8330807214794055\n",
      "train loss:1.1022770410174676\n",
      "train loss:0.9266607556625943\n",
      "train loss:0.7921993292215725\n",
      "train loss:0.8255156269605685\n",
      "train loss:0.8449198432051233\n",
      "train loss:0.7139840994925919\n",
      "train loss:0.9008001964005545\n",
      "train loss:0.8870363616982715\n",
      "train loss:0.8171739495607381\n",
      "train loss:0.7889368897334514\n",
      "train loss:0.89181953827144\n",
      "train loss:0.8257371759878626\n",
      "train loss:0.8402989522040641\n",
      "train loss:0.8585458834773876\n",
      "train loss:0.8017628492245619\n",
      "train loss:0.8992436249548602\n",
      "train loss:0.8023237308872999\n",
      "train loss:0.883893772764675\n",
      "train loss:0.8395646095194101\n",
      "train loss:0.9438270528507827\n",
      "train loss:0.9518132873740535\n",
      "train loss:0.8624200209018095\n",
      "train loss:0.8710508228635699\n",
      "train loss:0.668912836047753\n",
      "train loss:0.8365460163769471\n",
      "train loss:0.7925991742244206\n",
      "train loss:0.8744903698312811\n",
      "train loss:0.8452975226003687\n",
      "train loss:0.9046072862423397\n",
      "train loss:0.9009043241871056\n",
      "train loss:0.9690916670610983\n",
      "train loss:0.9908361230533618\n",
      "train loss:0.9052024389932046\n",
      "train loss:0.9428443107625936\n",
      "train loss:0.8706992977298442\n",
      "train loss:0.9195474458752793\n",
      "train loss:1.041576710483218\n",
      "train loss:0.8258380730256573\n",
      "train loss:0.8908045515239945\n",
      "train loss:0.8982215030758484\n",
      "train loss:0.8447743905688686\n",
      "train loss:0.8961635078930804\n",
      "train loss:0.6554092381002792\n",
      "train loss:0.7938114305513113\n",
      "train loss:0.8463744425066838\n",
      "train loss:0.9437987144003178\n",
      "train loss:0.7737199227648444\n",
      "train loss:0.8871693027586453\n",
      "train loss:0.8208979358803288\n",
      "train loss:0.8175770581188941\n",
      "train loss:1.067824355056118\n",
      "train loss:0.8907269057553031\n",
      "train loss:0.8191193731432094\n",
      "train loss:0.9401633495023273\n",
      "train loss:0.7513300036138655\n",
      "train loss:0.9096082581258058\n",
      "train loss:0.8843222755496809\n",
      "train loss:0.8958160872290597\n",
      "train loss:0.8172925650322767\n",
      "train loss:0.9016144618307226\n",
      "train loss:0.9016310932917722\n",
      "train loss:0.9040012313951206\n",
      "train loss:0.9565279441908112\n",
      "train loss:0.9078649333301599\n",
      "train loss:0.8237803078567366\n",
      "train loss:0.865471795082201\n",
      "train loss:0.8680262500305033\n",
      "train loss:0.8365342933614858\n",
      "train loss:1.0411137250223492\n",
      "train loss:0.9423032306417799\n",
      "train loss:0.8275605150776597\n",
      "train loss:0.8439232710753753\n",
      "train loss:0.8506837560118855\n",
      "train loss:0.9895860053974403\n",
      "train loss:0.9410112609220705\n",
      "train loss:0.8799999018685873\n",
      "train loss:0.8463381694912344\n",
      "train loss:0.7514807074068114\n",
      "train loss:0.7718969387721474\n",
      "train loss:0.8809858172368125\n",
      "train loss:0.869665803450162\n",
      "train loss:0.816231399796152\n",
      "train loss:0.815288677274124\n",
      "train loss:0.9196750784143894\n",
      "train loss:0.9966436285357514\n",
      "train loss:0.7823676931925069\n",
      "train loss:0.8412361653058755\n",
      "train loss:0.9474587951610067\n",
      "train loss:0.8015857087303196\n",
      "train loss:0.8757374516243412\n",
      "train loss:0.8917553331300243\n",
      "train loss:0.9014134668821667\n",
      "train loss:0.8093540496395751\n",
      "train loss:0.8857407126811647\n",
      "train loss:0.936659683358272\n",
      "train loss:0.8344032880674084\n",
      "train loss:0.9251148490412977\n",
      "train loss:0.8952997929004163\n",
      "train loss:0.7913664463765684\n",
      "train loss:0.7626524009056783\n",
      "train loss:0.8525107424006076\n",
      "train loss:0.7269257839537494\n",
      "train loss:0.8102057631372559\n",
      "train loss:0.8469039591619608\n",
      "train loss:0.9466152111357674\n",
      "train loss:0.8754370670639122\n",
      "train loss:0.812957103931144\n",
      "train loss:0.7963706530087654\n",
      "train loss:0.9040463889730386\n",
      "train loss:0.8823960740515513\n",
      "train loss:0.8228700204749163\n",
      "train loss:0.8244498094439048\n",
      "train loss:0.9933634176402283\n",
      "train loss:0.6461898318055083\n",
      "train loss:0.8289247722895493\n",
      "train loss:0.8508184101721272\n",
      "train loss:0.6916652686957094\n",
      "train loss:1.0399965184077349\n",
      "train loss:0.8492335112311374\n",
      "train loss:0.837232267979434\n",
      "train loss:0.7580894782430078\n",
      "train loss:0.745705051109585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8968600673575431\n",
      "train loss:0.753108319701977\n",
      "train loss:0.8121582572663505\n",
      "train loss:0.9815604303805026\n",
      "train loss:0.8301370184297288\n",
      "train loss:0.9436806959367113\n",
      "train loss:1.023011961402098\n",
      "train loss:0.8647596895967398\n",
      "train loss:0.9984442320123716\n",
      "train loss:0.8240758753261366\n",
      "train loss:0.9879109022614684\n",
      "train loss:0.8628185892909545\n",
      "train loss:0.7170392870227333\n",
      "train loss:0.7741539619140672\n",
      "train loss:0.7678087305182073\n",
      "train loss:0.8383093757349649\n",
      "train loss:0.7829262888315993\n",
      "train loss:0.8080783031199468\n",
      "train loss:0.9193532438437612\n",
      "train loss:0.8405905943196622\n",
      "train loss:1.0050952489320697\n",
      "train loss:0.908347009365912\n",
      "train loss:0.7918793878071262\n",
      "train loss:0.9985171959740045\n",
      "train loss:0.7466929469444693\n",
      "train loss:0.9423663967416886\n",
      "train loss:0.8327774394738983\n",
      "train loss:0.9758175508323825\n",
      "train loss:0.9346014598067738\n",
      "train loss:0.8289871925913533\n",
      "train loss:0.779703332952293\n",
      "train loss:0.8209728479512174\n",
      "train loss:0.9396864501703597\n",
      "train loss:0.8363352069972823\n",
      "train loss:0.8822895581357738\n",
      "train loss:0.9366626116021725\n",
      "train loss:0.717071337957017\n",
      "train loss:0.6751165894568295\n",
      "train loss:1.060238442748007\n",
      "train loss:1.1183074527544508\n",
      "train loss:0.7818360842937896\n",
      "train loss:0.8912386490002174\n",
      "train loss:0.9512364374026225\n",
      "train loss:0.6997418631558442\n",
      "train loss:0.9623599753047669\n",
      "train loss:1.0990609802100584\n",
      "train loss:0.7196946838822643\n",
      "train loss:0.8556526894207848\n",
      "train loss:0.944155326204147\n",
      "train loss:0.8349676331810412\n",
      "train loss:0.7554255150474707\n",
      "train loss:0.8131986003178345\n",
      "train loss:0.9539569792049676\n",
      "train loss:0.8527590579406439\n",
      "train loss:0.7888727534487802\n",
      "train loss:0.8308998240431004\n",
      "train loss:0.8088731440775702\n",
      "train loss:0.8227660836800114\n",
      "train loss:0.9869741445193182\n",
      "train loss:0.9956043812103481\n",
      "train loss:0.985186243923602\n",
      "train loss:0.6115364755694206\n",
      "train loss:0.7013770940696467\n",
      "train loss:0.909333395072399\n",
      "train loss:0.6842513957830136\n",
      "train loss:0.8555475291789655\n",
      "train loss:0.8712657539315204\n",
      "train loss:0.981094686559747\n",
      "train loss:0.7941192366941601\n",
      "train loss:1.1200320051067063\n",
      "train loss:1.0608722692642498\n",
      "train loss:0.815745905342919\n",
      "train loss:0.90210688873099\n",
      "train loss:0.8514515770926485\n",
      "train loss:0.9531847264703707\n",
      "train loss:0.9294623407389537\n",
      "train loss:0.7944363442911783\n",
      "train loss:0.7460400881525725\n",
      "train loss:0.804959688328629\n",
      "train loss:0.6993940862410389\n",
      "train loss:0.7836851839426687\n",
      "train loss:0.7976411306794816\n",
      "train loss:0.9850143503665094\n",
      "train loss:0.8118383427864884\n",
      "train loss:0.8229505616573017\n",
      "train loss:0.8499667110299519\n",
      "train loss:1.0262741336439132\n",
      "train loss:0.8300934501017844\n",
      "train loss:0.8474260667529296\n",
      "train loss:0.7626710161144081\n",
      "train loss:0.7888426591601142\n",
      "train loss:0.916525627422027\n",
      "train loss:0.8843971652226642\n",
      "train loss:0.8696770354725001\n",
      "train loss:0.9779898442213469\n",
      "train loss:1.0388922323890986\n",
      "train loss:0.7774254112319292\n",
      "train loss:0.9924603890236336\n",
      "train loss:1.0325547562251345\n",
      "train loss:0.7628828898544695\n",
      "train loss:0.8240232527003866\n",
      "train loss:0.8269238792050497\n",
      "train loss:0.8350383635106656\n",
      "train loss:0.8128676740567478\n",
      "train loss:0.9783847791584914\n",
      "train loss:0.8377619984955725\n",
      "train loss:0.8012208758102412\n",
      "train loss:0.8312751456996007\n",
      "train loss:0.8265970615185918\n",
      "train loss:0.8651850041392612\n",
      "train loss:0.9677619388842317\n",
      "train loss:0.923237830486417\n",
      "train loss:0.6786053619022918\n",
      "train loss:0.6578079397742207\n",
      "train loss:0.6549547069158453\n",
      "train loss:0.8309746122780531\n",
      "train loss:0.9473403141389138\n",
      "train loss:0.7753313043186851\n",
      "train loss:0.8849596425606443\n",
      "train loss:0.851494269352228\n",
      "train loss:0.8736619732323576\n",
      "train loss:1.0210302916510765\n",
      "train loss:0.8289233668535648\n",
      "train loss:0.8221000214718067\n",
      "train loss:0.8716219590946119\n",
      "train loss:0.8509668126854265\n",
      "train loss:0.8049976995168657\n",
      "train loss:1.0181021467593545\n",
      "train loss:0.9172864567476512\n",
      "train loss:0.9643966799464297\n",
      "train loss:0.7895769167906715\n",
      "train loss:0.8476638506290903\n",
      "train loss:0.7136259186200554\n",
      "train loss:0.8355731349332561\n",
      "train loss:1.0519815995345434\n",
      "train loss:0.8760024663345954\n",
      "train loss:0.9729594346177308\n",
      "train loss:0.8501943555477517\n",
      "train loss:0.7147678169623553\n",
      "train loss:0.8195371644465845\n",
      "train loss:0.8350413429016309\n",
      "train loss:0.8197447123457527\n",
      "train loss:0.8349605588188185\n",
      "train loss:0.7856178710349624\n",
      "train loss:0.9117740704848615\n",
      "train loss:0.9202946998881225\n",
      "train loss:0.8004101943684947\n",
      "train loss:0.860015950098314\n",
      "train loss:0.889467071763166\n",
      "train loss:0.870801686988138\n",
      "train loss:0.7914215721858457\n",
      "train loss:0.9240480469039005\n",
      "train loss:1.038782007927027\n",
      "train loss:0.6870613820044593\n",
      "train loss:0.9205865511883112\n",
      "train loss:0.8386296679667933\n",
      "train loss:0.7976813578273837\n",
      "train loss:0.9515568598356633\n",
      "train loss:0.8187839111179797\n",
      "train loss:0.9242028388761376\n",
      "train loss:0.7888757950385592\n",
      "train loss:0.8091627341369079\n",
      "train loss:0.748438860372591\n",
      "train loss:0.9645910863304401\n",
      "train loss:0.8349191951815439\n",
      "train loss:0.9751437179733874\n",
      "train loss:0.7019024056528136\n",
      "train loss:0.8738317196216652\n",
      "train loss:0.8239593985749609\n",
      "train loss:0.7705388785447752\n",
      "train loss:0.9038478026247069\n",
      "train loss:0.5922254855293622\n",
      "train loss:0.8552099914713626\n",
      "train loss:0.9330723288727019\n",
      "train loss:0.8864716097546929\n",
      "train loss:0.8247119308406334\n",
      "train loss:0.8760366134370231\n",
      "train loss:0.9895480892789276\n",
      "train loss:0.9515310246783855\n",
      "train loss:0.7344079839251109\n",
      "train loss:0.8050333091570542\n",
      "train loss:0.706857474062955\n",
      "train loss:0.9145478319863173\n",
      "train loss:0.781276728137192\n",
      "train loss:0.9059029005192685\n",
      "train loss:0.8281303925815616\n",
      "train loss:0.9418653467505911\n",
      "train loss:0.8482133596688162\n",
      "train loss:0.801667287060021\n",
      "train loss:0.9567291828592045\n",
      "train loss:0.8582246624806282\n",
      "train loss:0.7280817787721603\n",
      "train loss:0.8867398544850721\n",
      "train loss:0.8001677639031144\n",
      "train loss:0.652003851765148\n",
      "train loss:0.7850564838212338\n",
      "train loss:0.73376662794666\n",
      "train loss:0.937012805073783\n",
      "train loss:0.8330868081930458\n",
      "train loss:0.7618869103017616\n",
      "train loss:0.8521759409891568\n",
      "train loss:0.7929468139962114\n",
      "train loss:0.9270750372507883\n",
      "train loss:0.9411806592439516\n",
      "train loss:0.8548446295299473\n",
      "train loss:0.8008173208858106\n",
      "train loss:0.8755518891111254\n",
      "train loss:0.9000246529896146\n",
      "train loss:1.0254157760673182\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9938\n",
      "Saved Network Parameters!\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()  \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=20, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr':0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보관\n",
    "network.save_params(\"deep_convnet_params.pkl\")\n",
    "print(\"Saved Network Parameters!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1.1 더 깊은 신경망으로\n",
    "- 이번 장에서 구현한 신경망이 인식에 실패한 손글씨 이미지들을 화면에 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating test accuracy ... \n",
      "test accuracy:0.9938\n",
      "======= misclassified result =======\n",
      "{view index: (label, inference), ...}\n",
      "{1: (6, 0), 2: (3, 5), 3: (8, 2), 4: (2, 1), 5: (1, 7), 6: (4, 9), 7: (4, 2), 8: (3, 5), 9: (8, 9), 10: (6, 5), 11: (7, 2), 12: (9, 4), 13: (7, 2), 14: (9, 4), 15: (1, 2), 16: (5, 3), 17: (6, 0), 18: (4, 9), 19: (9, 8), 20: (9, 4)}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()\n",
    "network.load_params(\"deep_convnet_params.pkl\")\n",
    "\n",
    "print(\"calculating test accuracy ... \")\n",
    "#sampled = 1000\n",
    "#x_test = x_test[:sampled]\n",
    "#t_test = t_test[:sampled]\n",
    "\n",
    "classified_ids = []\n",
    "\n",
    "acc = 0.0\n",
    "batch_size = 100\n",
    "\n",
    "for i in range(int(x_test.shape[0] / batch_size)):\n",
    "    tx = x_test[i*batch_size:(i+1)*batch_size]\n",
    "    tt = t_test[i*batch_size:(i+1)*batch_size]\n",
    "    y = network.predict(tx, train_flg=False)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    classified_ids.append(y)\n",
    "    acc += np.sum(y == tt)\n",
    "    \n",
    "acc = acc / x_test.shape[0]\n",
    "print(\"test accuracy:\" + str(acc))\n",
    "\n",
    "classified_ids = np.array(classified_ids)\n",
    "classified_ids = classified_ids.flatten()\n",
    " \n",
    "max_view = 20\n",
    "current_view = 1\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.2, wspace=0.2)\n",
    "\n",
    "mis_pairs = {}\n",
    "for i, val in enumerate(classified_ids == t_test):\n",
    "    if not val:\n",
    "        ax = fig.add_subplot(4, 5, current_view, xticks=[], yticks=[])\n",
    "        ax.imshow(x_test[i].reshape(28, 28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        mis_pairs[current_view] = (t_test[i], classified_ids[i])\n",
    "            \n",
    "        current_view += 1\n",
    "        if current_view > max_view:\n",
    "            break\n",
    "\n",
    "print(\"======= misclassified result =======\")\n",
    "print(\"{view index: (label, inference), ...}\")\n",
    "print(mis_pairs)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3.4 연산 정밀도와 비트 줄이기\n",
    "- 수치 정밀도를 반정밀도(16비트)로 낮춰 계산하여 배정밀도(64비트)일 때와 정확도를 비교해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caluculate accuracy (float64) ... \n",
      "0.9938\n",
      "caluculate accuracy (float16) ... \n",
      "0.9938\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()\n",
    "network.load_params(\"deep_convnet_params.pkl\")\n",
    "\n",
    "sampled = 10000 # 고속화를 위한 표본추출\n",
    "x_test = x_test[:sampled]\n",
    "t_test = t_test[:sampled]\n",
    "\n",
    "print(\"caluculate accuracy (float64) ... \")\n",
    "print(network.accuracy(x_test, t_test))\n",
    "\n",
    "# float16(반정밀도)로 형변환\n",
    "x_test = x_test.astype(np.float16)\n",
    "for param in network.params.values():\n",
    "    param[...] = param.astype(np.float16)\n",
    "\n",
    "print(\"caluculate accuracy (float16) ... \")\n",
    "print(network.accuracy(x_test, t_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 요약 정리 최종\n",
    "\n",
    "- 수많은 문제에서 신경망을 더 깊게 하여 성능을 개선할 수 있다.\n",
    "- ILSVRC에서는 2012년 이후 딥러닝 기반 기법이 상위권을 독점하고 있으며, 그 깊이가 깊어지는 추세이다. -> VGG, GoogleLeNet, ResNet\n",
    "- GPU와 분산 학습, 비트 정밀도 감소 등으로 딥러닝을 고속화 할 수 있다.\n",
    "- 딥러닝은 사물 인식, 사물 검출, 분할에 활용된다.\n",
    "- 딥러닝의 응용 분야로는 사진의 캡션 생성(with 자연어처리), 이미지 생성(GAN), 강화학습 등이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
